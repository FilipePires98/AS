[2020-04-04 18:04:18,194] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:04:18,267] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:04:18,270] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:04:18,271] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:04:18,285] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:04:18,286] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:04:18,289] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:04:18,289] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:04:18,289] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:04:18,289] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:04:18,292] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:04:18,334] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:04:18,352] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:04:18,352] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:04:18,352] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:04:18,352] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:04:18,352] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:04:18,353] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:04:18,357] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:04:18,386] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,387] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,387] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,387] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,387] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,387] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,388] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,388] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,389] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,389] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,389] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,389] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,389] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,389] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,389] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,389] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,389] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,389] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,391] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,392] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,394] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:04:18,409] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:04:18,418] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:04:18,424] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:04:18,459] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:04:18,469] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:04:18,473] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:04:18,560] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:04:19,391] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:04:19,393] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:04:19,396] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:04:19,457] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:04:19,471] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,471] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,471] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,471] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,471] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,471] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,472] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,473] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,473] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,473] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,473] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,473] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,473] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,473] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,473] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,473] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,473] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,473] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,481] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,491] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:04:19,504] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:04:19,574] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:04:19,581] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:04:19,589] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:04:19,595] INFO Socket connection established, initiating session, client: /127.0.0.1:33716, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:04:19,601] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:04:19,602] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:04:19,604] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:04:19,635] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:04:19,645] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:04:19,659] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,659] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,659] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,659] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,659] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,659] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,662] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,663] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,663] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,663] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,663] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,663] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,663] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,663] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,663] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,663] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,663] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,663] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,673] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:04:19,677] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000cce6fc0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:04:19,686] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:04:19,691] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:04:19,702] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:04:19,724] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:04:19,733] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:04:19,734] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:04:19,739] INFO Socket connection established, initiating session, client: /127.0.0.1:33722, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:04:19,753] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000cce6fc0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:04:19,757] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:04:20,118] INFO Cluster ID = CLbjXtbtRKyKBC4oC-lX2w (kafka.server.KafkaServer)
[2020-04-04 18:04:20,129] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:04:20,195] INFO Cluster ID = CLbjXtbtRKyKBC4oC-lX2w (kafka.server.KafkaServer)
[2020-04-04 18:04:20,200] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:04:20,222] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:04:20,240] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:04:20,292] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:04:20,294] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:04:20,297] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:04:20,303] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:04:20,313] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:04:20,337] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:04:20,349] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:04:20,358] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-04 18:04:20,364] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:04:20,364] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:04:20,365] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:04:20,381] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:04:20,385] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:04:20,403] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:04:20,413] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:04:20,423] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-04 18:04:20,446] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:04:20,456] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:04:21,698] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:04:21,903] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:04:21,908] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:04:22,012] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:04:22,013] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,018] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,023] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,027] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,099] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:04:22,146] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:04:22,150] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:04:22,177] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:04:22,219] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,223] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,225] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,227] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,251] INFO Stat of the created znode at /brokers/ids/1 is: 60,60,1586019862224,1586019862224,1,0,0,72058474086531072,174,0,60
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:04:22,253] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 60 (kafka.zk.KafkaZkClient)
[2020-04-04 18:04:22,276] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:04:22,447] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:04:22,501] INFO Stat of the created znode at /brokers/ids/0 is: 62,62,1586019862474,1586019862474,1,0,0,72058474086531074,174,0,62
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:04:22,506] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 62 (kafka.zk.KafkaZkClient)
[2020-04-04 18:04:22,508] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,528] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:04:22,563] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,563] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,764] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:04:22,774] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:04:22,832] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 50 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:04:22,850] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:04:22,980] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:22,993] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:04:23,009] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:23,009] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:23,052] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:04:23,076] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:04:23,187] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:04:23,204] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:04:23,270] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 59 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:04:23,292] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:04:23,312] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:23,417] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:04:23,476] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:04:23,496] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:04:23,605] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:04:23,759] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:04:23,843] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:04:23,864] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:04:23,865] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:04:23,865] INFO Kafka startTimeMs: 1586019863845 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:04:23,897] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:04:24,021] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:04:24,162] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:04:24,177] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:04:24,177] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:04:24,178] INFO Kafka startTimeMs: 1586019864163 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:04:24,183] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:04:25,054] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 1, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:04:25,600] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:04:25,621] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 100 ms (kafka.log.Log)
[2020-04-04 18:04:25,627] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:04:25,630] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:04:25,632] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:04:25,636] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:04:25,683] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:04:25,695] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:04:25,768] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:04:25,786] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 222 ms (kafka.log.Log)
[2020-04-04 18:04:25,793] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:04:25,795] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:04:25,797] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:04:25,809] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:04:25,864] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:04:25,874] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:04:26,712] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:04:26,719] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:04:26,882] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:04:26,887] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:04:28,302] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 2, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:04:28,336] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:04:28,339] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:04:28,340] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:04:28,344] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:04:28,345] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:04:28,347] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:04:28,347] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:04:28,348] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:04:28,348] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:04:28,348] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:04:28,349] INFO [Partition ReportTopic-0 broker=1] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:04:28,349] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:04:28,350] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:04:28,360] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:04:28,360] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:04:28,361] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:04:28,361] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:04:28,391] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition ReportTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:04:30,447] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:04:30,486] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:04:30,492] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:04:30,492] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:04:30,492] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:04:30,493] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:04:30,493] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:04:30,494] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:04:30,494] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:04:30,494] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:04:30,494] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:04:30,495] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:04:30,495] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:04:30,495] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:04:30,496] INFO [Partition AlarmTopic-0 broker=1] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:04:30,923] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:04:30,924] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:11:33,377] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:11:33,380] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:11:33,414] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:11:33,416] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:11:33,416] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:11:33,422] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:11:33,423] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:11:33,425] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:11:33,425] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:11:33,425] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:11:33,425] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:11:33,427] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:11:33,437] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:11:33,447] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:11:33,447] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:11:33,447] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:11:33,447] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:11:33,447] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:11:33,448] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:11:33,450] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:11:33,467] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,467] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,467] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,467] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,467] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,467] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,468] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,468] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,468] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,468] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,468] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,469] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,469] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,469] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,469] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,469] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,469] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,469] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,470] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,470] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,471] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:33,479] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:11:33,482] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:11:33,486] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:11:33,487] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:220)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:85)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:78)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2020-04-04 18:11:34,067] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:11:34,068] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:11:34,069] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:11:34,112] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:11:34,112] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:11:34,114] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:11:34,117] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,129] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,129] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,129] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,129] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,129] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,129] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,130] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,131] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,131] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,131] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,131] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,131] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,131] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,131] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,131] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,131] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,131] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,131] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,135] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,139] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:11:34,142] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:11:34,144] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:11:34,145] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:11:34,147] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:11:34,149] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,158] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,158] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,158] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,159] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,159] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,159] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,160] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,160] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,160] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,160] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,160] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,161] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,161] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,161] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,161] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,161] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,161] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,161] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,166] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,173] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:11:34,178] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,179] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:11:34,180] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,181] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,189] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,189] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,189] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,189] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,189] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,190] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,189] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,190] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,190] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,190] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,190] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,190] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,190] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,191] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,191] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,191] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,191] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,191] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,191] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,193] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,197] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,200] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:11:34,196] INFO Socket connection established, initiating session, client: /127.0.0.1:33810, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,203] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,204] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,207] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:11:34,209] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000cce6fc0003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,213] INFO Socket connection established, initiating session, client: /127.0.0.1:33812, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,214] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,219] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000cce6fc0004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,230] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,247] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,250] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,254] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,264] INFO Socket connection established, initiating session, client: /127.0.0.1:33814, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,271] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000cce6fc0005, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,276] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,540] INFO Cluster ID = CLbjXtbtRKyKBC4oC-lX2w (kafka.server.KafkaServer)
[2020-04-04 18:11:34,575] INFO Cluster ID = CLbjXtbtRKyKBC4oC-lX2w (kafka.server.KafkaServer)
[2020-04-04 18:11:34,602] INFO Cluster ID = CLbjXtbtRKyKBC4oC-lX2w (kafka.server.KafkaServer)
[2020-04-04 18:11:34,641] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:11:34,653] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:11:34,664] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:11:34,675] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:11:34,685] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:34,687] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:34,688] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:34,693] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:11:34,707] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:34,707] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:11:34,712] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:34,714] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:34,734] ERROR [KafkaServer id=2] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:249)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:245)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:244)
	at kafka.log.LogManager.<init>(LogManager.scala:105)
	at kafka.log.LogManager$.apply(LogManager.scala:1093)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:250)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2020-04-04 18:11:34,737] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2020-04-04 18:11:34,741] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:34,742] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:34,742] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,743] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:34,758] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:249)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:245)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:244)
	at kafka.log.LogManager.<init>(LogManager.scala:105)
	at kafka.log.LogManager$.apply(LogManager.scala:1093)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:250)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2020-04-04 18:11:34,761] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2020-04-04 18:11:34,764] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,783] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:249)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:245)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:244)
	at kafka.log.LogManager.<init>(LogManager.scala:105)
	at kafka.log.LogManager$.apply(LogManager.scala:1093)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:250)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2020-04-04 18:11:34,786] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2020-04-04 18:11:34,789] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,846] INFO Session: 0x10000cce6fc0004 closed (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,847] INFO EventThread shut down for session: 0x10000cce6fc0004 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,849] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,850] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:34,868] INFO Session: 0x10000cce6fc0003 closed (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,868] INFO EventThread shut down for session: 0x10000cce6fc0003 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,871] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,872] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:34,893] INFO Session: 0x10000cce6fc0005 closed (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:11:34,893] INFO EventThread shut down for session: 0x10000cce6fc0005 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:11:34,894] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:11:34,895] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,686] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,686] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,686] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,687] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,687] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,687] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,688] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,688] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,699] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2020-04-04 18:11:35,700] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2020-04-04 18:11:35,703] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2020-04-04 18:11:35,708] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,708] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,709] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,712] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,712] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,713] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,714] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,714] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,725] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2020-04-04 18:11:35,726] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2020-04-04 18:11:35,728] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2020-04-04 18:11:35,742] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,742] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:35,742] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:36,742] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:36,742] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:36,743] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:37,743] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:37,743] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:11:37,750] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2020-04-04 18:11:37,751] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2020-04-04 18:11:37,754] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2020-04-04 18:11:50,395] ERROR Error while writing to checkpoint file /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/log-start-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.io.FileNotFoundException: /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/log-start-offset-checkpoint.tmp (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:52)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$2(LogManager.scala:634)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$2$adapted(LogManager.scala:628)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$1(LogManager.scala:628)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$1$adapted(LogManager.scala:627)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.checkpointLogStartOffsetsInDir(LogManager.scala:627)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsets$1(LogManager.scala:592)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsets$1$adapted(LogManager.scala:592)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.log.LogManager.checkpointLogStartOffsets(LogManager.scala:592)
	at kafka.log.LogManager.$anonfun$startup$6(LogManager.scala:419)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-04-04 18:11:50,395] ERROR Error while writing to checkpoint file /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/recovery-point-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.io.FileNotFoundException: /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/recovery-point-offset-checkpoint.tmp (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:52)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$2(LogManager.scala:618)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$2$adapted(LogManager.scala:616)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$1(LogManager.scala:616)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$1$adapted(LogManager.scala:615)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.checkpointLogRecoveryOffsetsInDir(LogManager.scala:615)
	at kafka.log.LogManager.checkpointRecoveryOffsetsAndCleanSnapshot(LogManager.scala:604)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$3(LogManager.scala:582)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$3$adapted(LogManager.scala:581)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$1(LogManager.scala:581)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$1$adapted(LogManager.scala:580)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:128)
	at kafka.log.LogManager.checkpointLogRecoveryOffsets(LogManager.scala:580)
	at kafka.log.LogManager.$anonfun$startup$5(LogManager.scala:414)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-04-04 18:11:50,405] INFO [ReplicaManager broker=1] Stopping serving replicas in dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 (kafka.server.ReplicaManager)
[2020-04-04 18:11:50,406] ERROR Uncaught exception in scheduled task 'kafka-log-start-offset-checkpoint' (kafka.utils.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/log-start-offset-checkpoint
Caused by: java.io.FileNotFoundException: /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/log-start-offset-checkpoint.tmp (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:52)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$2(LogManager.scala:634)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$2$adapted(LogManager.scala:628)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$1(LogManager.scala:628)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$1$adapted(LogManager.scala:627)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.checkpointLogStartOffsetsInDir(LogManager.scala:627)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsets$1(LogManager.scala:592)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsets$1$adapted(LogManager.scala:592)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.log.LogManager.checkpointLogStartOffsets(LogManager.scala:592)
	at kafka.log.LogManager.$anonfun$startup$6(LogManager.scala:419)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-04-04 18:11:50,406] ERROR Uncaught exception in scheduled task 'kafka-recovery-point-checkpoint' (kafka.utils.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/recovery-point-offset-checkpoint
Caused by: java.io.FileNotFoundException: /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/recovery-point-offset-checkpoint.tmp (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:52)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$2(LogManager.scala:618)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$2$adapted(LogManager.scala:616)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$1(LogManager.scala:616)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$1$adapted(LogManager.scala:615)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.checkpointLogRecoveryOffsetsInDir(LogManager.scala:615)
	at kafka.log.LogManager.checkpointRecoveryOffsetsAndCleanSnapshot(LogManager.scala:604)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$3(LogManager.scala:582)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$3$adapted(LogManager.scala:581)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$1(LogManager.scala:581)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$1$adapted(LogManager.scala:580)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:128)
	at kafka.log.LogManager.checkpointLogRecoveryOffsets(LogManager.scala:580)
	at kafka.log.LogManager.$anonfun$startup$5(LogManager.scala:414)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-04-04 18:11:50,412] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0, BatchTopic-0, AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:11:50,413] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0, BatchTopic-0, AlarmTopic-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-04-04 18:11:50,423] INFO [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions ReportTopic-0,BatchTopic-0,AlarmTopic-0 and stopped moving logs for partitions  because they are in the failed log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2. (kafka.server.ReplicaManager)
[2020-04-04 18:11:50,423] INFO Stopping serving logs in dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 (kafka.log.LogManager)
[2020-04-04 18:11:50,427] ERROR Shutdown broker because all log dirs in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 have failed (kafka.log.LogManager)
[2020-04-04 18:11:50,462] ERROR Error while writing to checkpoint file /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/log-start-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.io.FileNotFoundException: /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/log-start-offset-checkpoint.tmp (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:52)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$2(LogManager.scala:634)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$2$adapted(LogManager.scala:628)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$1(LogManager.scala:628)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$1$adapted(LogManager.scala:627)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.checkpointLogStartOffsetsInDir(LogManager.scala:627)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsets$1(LogManager.scala:592)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsets$1$adapted(LogManager.scala:592)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.log.LogManager.checkpointLogStartOffsets(LogManager.scala:592)
	at kafka.log.LogManager.$anonfun$startup$6(LogManager.scala:419)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-04-04 18:11:50,462] ERROR Error while writing to checkpoint file /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/recovery-point-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.io.FileNotFoundException: /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/recovery-point-offset-checkpoint.tmp (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:52)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$2(LogManager.scala:618)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$2$adapted(LogManager.scala:616)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$1(LogManager.scala:616)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$1$adapted(LogManager.scala:615)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.checkpointLogRecoveryOffsetsInDir(LogManager.scala:615)
	at kafka.log.LogManager.checkpointRecoveryOffsetsAndCleanSnapshot(LogManager.scala:604)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$3(LogManager.scala:582)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$3$adapted(LogManager.scala:581)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$1(LogManager.scala:581)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$1$adapted(LogManager.scala:580)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:128)
	at kafka.log.LogManager.checkpointLogRecoveryOffsets(LogManager.scala:580)
	at kafka.log.LogManager.$anonfun$startup$5(LogManager.scala:414)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-04-04 18:11:50,464] INFO [ReplicaManager broker=0] Stopping serving replicas in dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 (kafka.server.ReplicaManager)
[2020-04-04 18:11:50,464] ERROR Uncaught exception in scheduled task 'kafka-log-start-offset-checkpoint' (kafka.utils.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/log-start-offset-checkpoint
Caused by: java.io.FileNotFoundException: /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/log-start-offset-checkpoint.tmp (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:52)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$2(LogManager.scala:634)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$2$adapted(LogManager.scala:628)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$1(LogManager.scala:628)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsetsInDir$1$adapted(LogManager.scala:627)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.checkpointLogStartOffsetsInDir(LogManager.scala:627)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsets$1(LogManager.scala:592)
	at kafka.log.LogManager.$anonfun$checkpointLogStartOffsets$1$adapted(LogManager.scala:592)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.log.LogManager.checkpointLogStartOffsets(LogManager.scala:592)
	at kafka.log.LogManager.$anonfun$startup$6(LogManager.scala:419)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-04-04 18:11:50,464] ERROR Uncaught exception in scheduled task 'kafka-recovery-point-checkpoint' (kafka.utils.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/recovery-point-offset-checkpoint
Caused by: java.io.FileNotFoundException: /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/recovery-point-offset-checkpoint.tmp (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:52)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$2(LogManager.scala:618)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$2$adapted(LogManager.scala:616)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$1(LogManager.scala:616)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsetsInDir$1$adapted(LogManager.scala:615)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.checkpointLogRecoveryOffsetsInDir(LogManager.scala:615)
	at kafka.log.LogManager.checkpointRecoveryOffsetsAndCleanSnapshot(LogManager.scala:604)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$3(LogManager.scala:582)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$3$adapted(LogManager.scala:581)
	at scala.Option.foreach(Option.scala:407)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$1(LogManager.scala:581)
	at kafka.log.LogManager.$anonfun$checkpointLogRecoveryOffsets$1$adapted(LogManager.scala:580)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:128)
	at kafka.log.LogManager.checkpointLogRecoveryOffsets(LogManager.scala:580)
	at kafka.log.LogManager.$anonfun$startup$5(LogManager.scala:414)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-04-04 18:11:50,466] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0, BatchTopic-0, AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:11:50,467] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0, BatchTopic-0, AlarmTopic-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-04-04 18:11:50,473] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions ReportTopic-0,BatchTopic-0,AlarmTopic-0 and stopped moving logs for partitions  because they are in the failed log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1. (kafka.server.ReplicaManager)
[2020-04-04 18:11:50,473] INFO Stopping serving logs in dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 (kafka.log.LogManager)
[2020-04-04 18:11:50,476] ERROR Shutdown broker because all log dirs in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 have failed (kafka.log.LogManager)
[2020-04-04 18:11:50,781] WARN Unable to read additional data from client sessionid 0x10000cce6fc0000, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2020-04-04 18:11:50,792] WARN Unable to read additional data from client sessionid 0x10000cce6fc0001, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2020-04-04 18:11:50,810] WARN Unable to read additional data from client sessionid 0x10000cce6fc0002, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2020-04-04 18:11:57,003] INFO Expiring session 0x10000cce6fc0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:57,004] INFO Expiring session 0x10000cce6fc0001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:11:57,005] INFO Expiring session 0x10000cce6fc0002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,464] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:13:11,466] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:13:11,466] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:13:11,482] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:13:11,482] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:13:11,484] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:13:11,485] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:13:11,485] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:13:11,485] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:13:11,486] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:13:11,528] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:13:11,528] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:13:11,528] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:13:11,528] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:13:11,528] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:13:11,528] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:13:11,534] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:13:11,537] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:13:11,541] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:13:11,552] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,552] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,552] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,552] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,552] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,552] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,553] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,554] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,554] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,554] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,554] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,554] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,554] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,554] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,554] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,554] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,554] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,554] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,556] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,556] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,558] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:13:11,568] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:13:11,569] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:13:11,572] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:13:11,578] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:13:11,599] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:13:11,603] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:13:11,606] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:13:11,629] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:13:12,204] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:13:12,205] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:13:12,207] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:13:12,216] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:13:12,217] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:13:12,218] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:13:12,250] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:13:12,250] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:13:12,251] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:13:12,252] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:13:12,258] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:13:12,260] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,260] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,260] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,260] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,260] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,260] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,261] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,264] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,269] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,269] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,269] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,269] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,269] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,269] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,271] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,271] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,271] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,271] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,271] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,272] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,272] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,272] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,272] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,272] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,272] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,272] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,276] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:13:12,276] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,288] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:13:12,288] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:13:12,288] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:13:12,296] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:13:12,297] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,297] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,297] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,297] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,297] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,298] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,299] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,299] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,299] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,299] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,299] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,299] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,299] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,299] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,299] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,299] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,300] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,300] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,304] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:13:12,310] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:13:12,316] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:13:12,324] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,327] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,328] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:13:12,331] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,333] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:13:12,337] INFO Socket connection established, initiating session, client: /127.0.0.1:33830, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,337] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,342] INFO Socket connection established, initiating session, client: /127.0.0.1:33832, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,348] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,353] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:13:12,357] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:13:12,357] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,361] INFO Socket connection established, initiating session, client: /127.0.0.1:33834, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,368] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d509860001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,368] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d509860000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,369] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d509860002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:13:12,372] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:13:12,372] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:13:12,373] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:13:12,684] INFO Cluster ID = 3MZ43dI7RgOybJrNlQH1rQ (kafka.server.KafkaServer)
[2020-04-04 18:13:12,689] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:13:12,723] INFO Cluster ID = 3MZ43dI7RgOybJrNlQH1rQ (kafka.server.KafkaServer)
[2020-04-04 18:13:12,727] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:13:12,739] INFO Cluster ID = 3MZ43dI7RgOybJrNlQH1rQ (kafka.server.KafkaServer)
[2020-04-04 18:13:12,744] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:13:12,761] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:13:12,774] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:13:12,804] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:13:12,805] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:13:12,811] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:13:12,815] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:13:12,818] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:13:12,819] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:13:12,832] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:13:12,841] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:13:12,847] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:13:12,847] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:13:12,848] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:13:12,848] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:13:12,856] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[2020-04-04 18:13:12,858] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:13:12,858] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:13:12,860] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:13:12,875] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:13:12,877] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:13:12,882] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:13:12,885] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:13:12,885] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:13:12,893] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[2020-04-04 18:13:12,894] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:13:12,904] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-04 18:13:12,912] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:13:12,917] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:13:12,926] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:13:12,931] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:13:13,375] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:13:13,430] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:13:13,432] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:13:13,471] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,475] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,475] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:13:13,484] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,485] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,491] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:13:13,516] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:13:13,518] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:13:13,522] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:13:13,533] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:13:13,534] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:13:13,541] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,542] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,543] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,544] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,548] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:13:13,558] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,559] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,560] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,561] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,565] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:13:13,572] INFO Stat of the created znode at /brokers/ids/1 is: 66,66,1586020393563,1586020393563,1,0,0,72058509025738752,174,0,66
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:13:13,573] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 66 (kafka.zk.KafkaZkClient)
[2020-04-04 18:13:13,583] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:13:13,618] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:13:13,636] INFO Stat of the created znode at /brokers/ids/0 is: 67,67,1586020393630,1586020393630,1,0,0,72058509025738753,174,0,67
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:13:13,637] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 67 (kafka.zk.KafkaZkClient)
[2020-04-04 18:13:13,639] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:13:13,657] INFO Stat of the created znode at /brokers/ids/2 is: 68,68,1586020393650,1586020393650,1,0,0,72058509025738754,174,0,68
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:13:13,658] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 68 (kafka.zk.KafkaZkClient)
[2020-04-04 18:13:13,665] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,666] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,670] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,675] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:13:13,715] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:13:13,718] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:13:13,724] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:13:13,725] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,728] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,737] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:13:13,742] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,751] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,754] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,771] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:13:13,773] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,773] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:13:13,773] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:13:13,791] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:13:13,795] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:13:13,803] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:13:13,804] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,809] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:13:13,811] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:13:13,813] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:13:13,829] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:13:13,844] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:13:13,845] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:13:13,848] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:13:13,849] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:13:13,870] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:13:13,878] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:13:13,886] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,896] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:13:13,896] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:13:13,935] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:13:13,943] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:13:13,943] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:13:13,950] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:13:13,950] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:13:13,951] INFO Kafka startTimeMs: 1586020393944 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:13:13,952] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:13:13,981] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:13:13,987] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:13:13,987] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:13:13,987] INFO Kafka startTimeMs: 1586020393981 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:13:13,989] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:13:14,008] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:13:14,027] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:13:14,031] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:13:14,031] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:13:14,031] INFO Kafka startTimeMs: 1586020394028 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:13:14,033] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:13:14,642] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:13:14,752] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:14,873] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:13:14,880] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2020-04-04 18:13:14,882] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:13:14,883] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:13:14,884] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:13:14,884] INFO [Partition BatchTopic-0 broker=1] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:13:14,902] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:13:14,959] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:13:14,964] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 142 ms (kafka.log.Log)
[2020-04-04 18:13:14,967] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:13:14,972] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:13:14,974] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:13:14,976] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:14,979] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 172 ms (kafka.log.Log)
[2020-04-04 18:13:14,984] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:13:14,987] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:13:14,987] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:13:14,989] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:15,009] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:13:15,015] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:15,016] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:13:15,021] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:16,020] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:13:16,022] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:13:16,026] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:13:16,029] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:13:16,522] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 2, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:13:16,578] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:16,586] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:13:16,586] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:13:16,586] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:13:16,587] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:13:16,587] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:13:16,588] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:13:16,588] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:13:16,588] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:13:16,589] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:13:16,589] INFO [Partition ReportTopic-0 broker=1] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:13:16,589] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:13:16,589] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:13:16,590] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:16,591] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:16,592] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:13:16,601] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:13:16,602] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:13:16,602] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:13:16,613] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:13:16,613] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:13:16,614] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:16,615] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:17,122] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:13:17,123] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:13:18,189] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 1, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:13:18,235] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:18,236] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:13:18,237] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:13:18,238] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:13:18,239] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:13:18,239] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:13:18,239] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:13:18,240] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:13:18,240] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:18,241] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:13:18,241] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:13:18,241] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:13:18,242] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:18,244] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:13:18,244] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:18,245] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:13:18,245] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:13:18,245] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:13:18,247] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:13:18,249] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:13:18,250] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:13:18,250] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:13:18,251] INFO [Partition AlarmTopic-0 broker=2] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:13:18,265] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:13:18,270] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:13:18,274] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition AlarmTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:13:19,275] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:13:19,278] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:15:30,146] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:15:30,163] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:15:30,165] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:15:30,165] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:15:30,170] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:15:30,171] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:15:30,173] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:15:30,173] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:15:30,173] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:15:30,173] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:15:30,175] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:15:30,211] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:15:30,211] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:15:30,211] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:15:30,212] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:15:30,212] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:15:30,212] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:15:30,216] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:15:30,237] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,237] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,237] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,238] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,238] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,238] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,239] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,239] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,239] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,239] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,239] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,239] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,239] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,239] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,239] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,239] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,240] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,240] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,241] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,242] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,242] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:15:30,251] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:15:30,252] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:15:30,256] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:15:30,261] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:15:30,285] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:15:30,298] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:15:30,304] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:15:30,307] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:15:30,339] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:15:30,913] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:15:30,914] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:15:30,916] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:15:30,949] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:15:30,957] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,957] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,957] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,957] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,957] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,957] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,958] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,958] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,958] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,959] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,959] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,959] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,959] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,959] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:15:30,959] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,959] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,959] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,959] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,959] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,959] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:15:30,960] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:15:30,961] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:30,967] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:15:30,973] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:15:30,990] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:15:30,991] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:15:30,992] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:15:30,992] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:15:31,000] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,001] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,001] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,001] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,001] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,001] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,002] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,002] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,002] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,002] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,002] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,002] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,002] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,002] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,003] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,003] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,003] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,003] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,006] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,013] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:15:31,020] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,020] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:15:31,026] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:15:31,028] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:15:31,030] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,035] INFO Socket connection established, initiating session, client: /127.0.0.1:34008, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,036] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,036] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,036] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,036] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,036] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,036] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,037] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,037] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,038] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,038] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,038] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,038] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,038] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,038] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,038] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,038] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,038] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,038] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,040] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:15:31,047] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:15:31,050] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,050] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:15:31,054] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:15:31,057] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:15:31,058] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,062] INFO Socket connection established, initiating session, client: /127.0.0.1:34010, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,065] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d727530000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,070] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:15:31,078] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,083] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:15:31,086] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d727530001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,086] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,091] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:15:31,091] INFO Socket connection established, initiating session, client: /127.0.0.1:34012, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,101] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d727530002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:15:31,105] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:15:31,402] INFO Cluster ID = 7i6TDQ5pRHWxVmdt_dOHuQ (kafka.server.KafkaServer)
[2020-04-04 18:15:31,406] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:15:31,451] INFO Cluster ID = 7i6TDQ5pRHWxVmdt_dOHuQ (kafka.server.KafkaServer)
[2020-04-04 18:15:31,452] INFO Cluster ID = 7i6TDQ5pRHWxVmdt_dOHuQ (kafka.server.KafkaServer)
[2020-04-04 18:15:31,457] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:15:31,458] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:15:31,481] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:15:31,494] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:15:31,523] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:15:31,523] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:15:31,525] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:15:31,551] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:15:31,551] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:15:31,557] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:15:31,566] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:15:31,567] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:15:31,568] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:15:31,578] INFO Logs loading complete in 12 ms. (kafka.log.LogManager)
[2020-04-04 18:15:31,594] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:15:31,598] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:15:31,599] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:15:31,600] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:15:31,600] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:15:31,602] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:15:31,602] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:15:31,604] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:15:31,631] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:15:31,632] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:15:31,638] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:15:31,640] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:15:31,647] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-04 18:15:31,650] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-04 18:15:31,669] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:15:31,670] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:15:31,676] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:15:31,677] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:15:32,069] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:15:32,125] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:15:32,128] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:15:32,158] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,172] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,173] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,175] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,194] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:15:32,214] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:15:32,222] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:15:32,236] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:15:32,237] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:15:32,252] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:15:32,254] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:15:32,255] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:15:32,262] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,265] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,266] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,266] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,277] INFO Stat of the created znode at /brokers/ids/0 is: 56,56,1586020532269,1586020532269,1,0,0,72058518115647489,174,0,56
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:15:32,278] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 56 (kafka.zk.KafkaZkClient)
[2020-04-04 18:15:32,281] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,283] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,283] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,285] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,286] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:15:32,307] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:15:32,337] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:15:32,358] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:15:32,358] INFO Stat of the created znode at /brokers/ids/2 is: 57,57,1586020532349,1586020532349,1,0,0,72058518115647490,174,0,57
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:15:32,359] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 57 (kafka.zk.KafkaZkClient)
[2020-04-04 18:15:32,367] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,371] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,375] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,383] INFO Stat of the created znode at /brokers/ids/1 is: 58,58,1586020532370,1586020532370,1,0,0,72058518115647488,174,0,58
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:15:32,384] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 58 (kafka.zk.KafkaZkClient)
[2020-04-04 18:15:32,409] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:15:32,436] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:15:32,439] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:15:32,445] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:15:32,466] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:15:32,468] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,472] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,480] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,494] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:15:32,495] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,502] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,507] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,511] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:15:32,519] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:15:32,520] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:15:32,523] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:15:32,528] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:15:32,547] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:15:32,577] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,581] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:15:32,581] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:15:32,583] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:15:32,585] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:15:32,586] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:15:32,607] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 24 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:15:32,618] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:15:32,647] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,650] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:15:32,662] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:15:32,663] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:15:32,691] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:15:32,698] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:15:32,698] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:15:32,760] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:15:32,766] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:15:32,766] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:15:32,766] INFO Kafka startTimeMs: 1586020532760 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:15:32,767] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:15:32,775] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:15:32,781] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:15:32,781] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:15:32,781] INFO Kafka startTimeMs: 1586020532775 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:15:32,783] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:15:32,804] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:15:32,826] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:15:32,847] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:15:32,847] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:15:32,847] INFO Kafka startTimeMs: 1586020532826 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:15:32,849] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:15:33,088] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 1, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:15:33,207] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:33,304] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:15:33,315] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:15:33,323] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2020-04-04 18:15:33,325] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:15:33,326] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:15:33,327] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:15:33,329] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:33,342] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 83 ms (kafka.log.Log)
[2020-04-04 18:15:33,345] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:15:33,347] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:15:33,348] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:15:33,351] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:15:33,368] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:15:33,372] INFO [Partition BatchTopic-0 broker=2] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:15:33,373] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:33,388] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 119 ms (kafka.log.Log)
[2020-04-04 18:15:33,391] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:15:33,392] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:15:33,393] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:15:33,395] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:33,432] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:15:33,435] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:33,439] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:15:33,443] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:15:34,380] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:15:34,385] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:15:35,209] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:15:35,231] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:35,234] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:15:35,234] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:15:35,235] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:15:35,236] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:15:35,236] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:15:35,236] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:35,237] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:15:35,237] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:15:35,237] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:15:35,237] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:15:35,238] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:15:35,239] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:15:35,239] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:15:35,239] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:15:35,239] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:15:35,239] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:15:35,240] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:35,240] INFO [Partition ReportTopic-0 broker=0] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:15:35,242] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:15:35,242] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:35,242] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:15:35,242] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:15:35,272] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:15:35,273] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:35,279] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:15:35,280] ERROR [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error for partition ReportTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:15:35,287] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:15:36,922] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 0, 1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:15:36,942] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:36,945] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:15:36,946] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:15:36,946] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:15:36,947] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:15:36,947] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:15:36,947] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:15:36,947] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:15:36,947] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:15:36,947] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:15:36,948] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:15:36,948] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:15:36,948] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:15:36,948] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:15:36,948] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:36,948] INFO [Partition AlarmTopic-0 broker=2] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:15:36,948] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:15:36,948] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:15:36,948] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:36,949] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:36,949] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:15:37,051] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:15:37,052] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:15:37,428] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:15:37,428] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:16:34,007] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:16:34,009] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:16:34,009] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:16:34,018] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:16:34,018] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:16:34,021] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:16:34,021] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:16:34,021] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:16:34,021] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:16:34,023] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:16:34,029] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:16:34,069] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:16:34,069] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:16:34,069] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:16:34,069] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:16:34,069] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:16:34,069] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:16:34,074] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:16:34,100] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,100] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,100] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,100] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,100] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,100] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,101] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,101] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,102] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,102] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,102] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,102] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,102] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,102] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,102] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,102] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,102] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,102] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,104] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,104] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,105] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:16:34,119] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:16:34,122] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:16:34,127] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:16:34,138] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:16:34,160] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:16:34,167] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:16:34,172] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:16:34,203] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:16:34,215] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:16:34,692] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:16:34,692] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:16:34,694] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:16:34,718] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:16:34,726] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,726] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,726] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,726] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,726] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,726] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,727] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,727] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,727] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,727] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,727] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,727] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,727] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,727] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,727] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,728] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,728] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,728] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,730] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,736] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:16:34,742] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:16:34,772] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:34,777] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:16:34,782] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:34,788] INFO Socket connection established, initiating session, client: /127.0.0.1:34058, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:34,804] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:16:34,826] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d820cc0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:34,831] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:16:34,832] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:16:34,833] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:16:34,834] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:16:34,868] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:16:34,875] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,875] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,875] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,875] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,875] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,875] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,876] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,876] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,876] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,876] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,876] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,876] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,876] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,877] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,877] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,877] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,877] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,877] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,880] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,886] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:16:34,892] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:16:34,921] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:34,927] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:16:34,928] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:34,932] INFO Socket connection established, initiating session, client: /127.0.0.1:34062, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:34,939] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d820cc0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:34,940] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:16:34,941] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:16:34,942] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:16:34,944] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:16:34,966] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:16:34,973] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,973] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,973] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,973] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,973] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,973] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,974] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,974] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,974] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,974] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,974] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,974] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,974] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,974] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,974] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,974] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,975] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,975] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,978] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:16:34,984] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:16:34,990] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:16:35,010] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:35,013] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:16:35,018] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:35,022] INFO Socket connection established, initiating session, client: /127.0.0.1:34066, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:35,027] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d820cc0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:16:35,032] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:16:35,238] INFO Cluster ID = iw3-3Er4TACWNWpKpInpUg (kafka.server.KafkaServer)
[2020-04-04 18:16:35,243] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:16:35,314] INFO Cluster ID = iw3-3Er4TACWNWpKpInpUg (kafka.server.KafkaServer)
[2020-04-04 18:16:35,319] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:16:35,326] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:16:35,331] INFO Cluster ID = iw3-3Er4TACWNWpKpInpUg (kafka.server.KafkaServer)
[2020-04-04 18:16:35,335] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:16:35,340] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:16:35,373] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:16:35,374] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:16:35,375] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:16:35,397] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:16:35,405] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:16:35,405] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:16:35,412] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:16:35,414] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:16:35,421] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-04 18:16:35,421] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:16:35,438] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:16:35,441] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:16:35,451] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:16:35,451] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:16:35,452] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:16:35,450] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:16:35,451] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:16:35,450] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:16:35,477] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:16:35,480] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:16:35,483] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:16:35,489] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:16:35,492] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[2020-04-04 18:16:35,497] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[2020-04-04 18:16:35,511] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:16:35,519] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:16:35,524] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:16:35,524] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:16:36,076] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:16:36,172] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:16:36,175] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:16:36,247] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,249] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,251] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,259] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,273] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:16:36,360] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:16:36,362] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:16:36,429] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:16:36,439] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:16:36,476] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:16:36,485] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:16:36,486] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:16:36,537] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,547] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,553] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,562] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,572] INFO Stat of the created znode at /brokers/ids/2 is: 54,54,1586020596548,1586020596548,1,0,0,72058522301104128,174,0,54
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:16:36,576] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 54 (kafka.zk.KafkaZkClient)
[2020-04-04 18:16:36,577] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,584] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,587] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,595] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,640] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:16:36,697] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:16:36,792] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:16:36,862] INFO Stat of the created znode at /brokers/ids/0 is: 55,55,1586020596841,1586020596841,1,0,0,72058522301104129,174,0,55
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:16:36,864] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 55 (kafka.zk.KafkaZkClient)
[2020-04-04 18:16:36,891] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,911] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:16:36,929] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,947] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:36,967] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:16:37,016] INFO Stat of the created znode at /brokers/ids/1 is: 58,58,1586020596987,1586020596987,1,0,0,72058522301104130,174,0,58
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:16:37,033] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 58 (kafka.zk.KafkaZkClient)
[2020-04-04 18:16:37,182] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:16:37,189] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:16:37,243] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:16:37,270] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 76 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:16:37,354] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:37,372] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:37,374] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:16:37,381] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:16:37,392] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:37,400] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:16:37,435] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:37,459] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:37,469] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:37,551] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:37,552] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:16:37,556] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:16:37,573] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 18 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:16:37,635] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:16:37,636] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:16:37,658] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:16:37,680] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 23 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:16:37,731] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:16:37,737] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:16:37,743] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:16:37,755] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:16:37,755] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:16:37,838] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:16:37,880] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:16:37,881] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:16:37,919] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:16:37,944] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:16:37,944] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:16:37,944] INFO Kafka startTimeMs: 1586020597920 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:16:37,954] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:16:37,963] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:38,020] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:16:38,061] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:16:38,157] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:16:38,172] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:16:38,172] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:16:38,173] INFO Kafka startTimeMs: 1586020598158 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:16:38,181] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:16:38,185] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:16:38,293] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:16:38,309] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:16:38,309] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:16:38,310] INFO Kafka startTimeMs: 1586020598295 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:16:38,322] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:16:39,150] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 1, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:16:39,385] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:39,649] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:16:39,676] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 158 ms (kafka.log.Log)
[2020-04-04 18:16:39,681] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:16:39,684] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:16:39,686] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:16:39,688] INFO [Partition BatchTopic-0 broker=2] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:16:39,759] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:16:39,770] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:16:39,785] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 256 ms (kafka.log.Log)
[2020-04-04 18:16:39,788] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 257 ms (kafka.log.Log)
[2020-04-04 18:16:39,793] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:16:39,795] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:16:39,797] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:16:39,799] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:16:39,799] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:16:39,802] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:39,802] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:16:39,808] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:39,871] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:16:39,873] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:39,885] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:16:39,898] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:16:39,902] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:16:39,908] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:39,924] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:16:39,932] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:16:42,500] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 1, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:16:42,533] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:42,539] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:16:42,540] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:16:42,542] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:16:42,543] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:16:42,544] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:16:42,545] INFO [Partition ReportTopic-0 broker=2] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:16:42,549] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:16:42,550] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:16:42,552] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:16:42,553] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:16:42,553] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:16:42,554] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:16:42,555] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:42,555] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:16:42,560] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:42,561] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:16:42,562] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:16:42,563] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:16:42,565] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:42,566] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:42,602] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:16:42,602] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:16:42,602] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:16:42,603] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:16:44,773] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 2, 1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:16:44,804] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:44,808] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:16:44,809] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:16:44,811] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:16:44,811] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:16:44,812] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:16:44,813] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:16:44,813] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:16:44,813] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:16:44,814] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:16:44,814] INFO [Partition AlarmTopic-0 broker=0] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:16:44,815] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:16:44,815] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:16:44,816] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:16:44,816] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:16:44,816] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:44,818] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:16:44,818] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:16:44,820] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:44,823] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:44,823] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:16:44,826] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:16:44,826] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:16:44,855] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:16:44,859] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:16:44,864] ERROR [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error for partition AlarmTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:16:44,867] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:16:44,872] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:17:58,521] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:17:58,523] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:17:58,523] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:17:58,527] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:17:58,529] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:17:58,531] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:17:58,530] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:17:58,531] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:17:58,533] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:17:58,534] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:17:58,534] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:17:58,534] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:17:58,536] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:17:58,566] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:17:58,566] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:17:58,566] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:17:58,566] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:17:58,566] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:17:58,566] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:17:58,570] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:17:58,590] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,590] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,590] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,590] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,590] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,590] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,592] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,592] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,592] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,592] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,592] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,592] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,592] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,592] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,592] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,592] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,593] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,593] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,596] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,596] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,596] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:17:58,607] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:17:58,611] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:17:58,616] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:17:58,644] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:17:58,650] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:17:58,654] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:17:58,683] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:17:59,206] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:17:59,207] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:17:59,208] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:17:59,229] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:17:59,235] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,235] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,235] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,235] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,235] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,235] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,236] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,236] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,236] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,236] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,236] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,237] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,237] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,237] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,237] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,237] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,237] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,237] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,240] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,245] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:17:59,246] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:17:59,246] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:17:59,247] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:17:59,254] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:17:59,278] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:17:59,285] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,285] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,285] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,285] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,285] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,285] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,286] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,286] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,286] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,286] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,286] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,286] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,286] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,286] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,286] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,286] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,286] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,287] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,289] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,294] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:17:59,294] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,298] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:17:59,300] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:17:59,300] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:17:59,300] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,301] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:17:59,301] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:17:59,305] INFO Socket connection established, initiating session, client: /127.0.0.1:34110, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,321] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:17:59,330] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:17:59,336] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,336] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,336] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,336] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,336] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,336] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,337] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,337] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,337] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,337] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,337] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,337] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,337] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,337] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,337] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,337] INFO Client environment:os.memory.free=974MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,337] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,338] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,340] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:17:59,346] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,347] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:17:59,349] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:17:59,361] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,361] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d96ace0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,363] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:17:59,366] INFO Socket connection established, initiating session, client: /127.0.0.1:34114, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,367] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:17:59,372] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d96ace0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,375] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,376] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:17:59,377] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:17:59,381] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,385] INFO Socket connection established, initiating session, client: /127.0.0.1:34116, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,391] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000d96ace0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:17:59,394] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:17:59,694] INFO Cluster ID = sPoXXp3DTcyFXiMkrpCtzg (kafka.server.KafkaServer)
[2020-04-04 18:17:59,700] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:17:59,731] INFO Cluster ID = sPoXXp3DTcyFXiMkrpCtzg (kafka.server.KafkaServer)
[2020-04-04 18:17:59,736] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:17:59,746] INFO Cluster ID = sPoXXp3DTcyFXiMkrpCtzg (kafka.server.KafkaServer)
[2020-04-04 18:17:59,750] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:17:59,777] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:17:59,789] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:17:59,815] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:17:59,820] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:17:59,820] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:17:59,821] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:17:59,827] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:17:59,829] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:17:59,842] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:17:59,854] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:17:59,861] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:17:59,861] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:17:59,862] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:17:59,862] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:17:59,870] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:17:59,871] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:17:59,871] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-04 18:17:59,871] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:17:59,889] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:17:59,890] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:17:59,895] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:17:59,898] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:17:59,899] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:17:59,907] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-04 18:17:59,908] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:17:59,918] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-04 18:17:59,927] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:17:59,940] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:17:59,940] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:17:59,948] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:18:00,668] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:18:00,889] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:18:00,894] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:18:00,920] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:18:00,926] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:18:00,985] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:00,988] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,003] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,017] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,022] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:18:01,028] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:18:01,046] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:18:01,050] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:18:01,074] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:18:01,099] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,103] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,107] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,109] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,121] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,125] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,130] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,133] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,151] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:18:01,168] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:18:01,228] INFO Stat of the created znode at /brokers/ids/2 is: 60,60,1586020681196,1586020681196,1,0,0,72058527837716482,174,0,60
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:18:01,230] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 60 (kafka.zk.KafkaZkClient)
[2020-04-04 18:18:01,239] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:18:01,278] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:18:01,332] INFO Stat of the created znode at /brokers/ids/0 is: 61,61,1586020681312,1586020681312,1,0,0,72058527837716481,174,0,61
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:18:01,334] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 61 (kafka.zk.KafkaZkClient)
[2020-04-04 18:18:01,425] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:18:01,478] INFO Stat of the created znode at /brokers/ids/1 is: 62,62,1586020681457,1586020681457,1,0,0,72058527837716480,174,0,62
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:18:01,481] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 62 (kafka.zk.KafkaZkClient)
[2020-04-04 18:18:01,491] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,500] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,503] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,554] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:18:01,639] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:18:01,641] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:18:01,643] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,673] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,691] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:18:01,705] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,715] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 65 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:01,823] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:18:01,828] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:18:01,830] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,833] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:18:01,835] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,838] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:18:01,851] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:18:01,854] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:01,889] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 36 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:01,949] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:18:01,984] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:18:01,986] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:18:01,989] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:02,036] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 51 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:02,068] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:18:02,075] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:18:02,100] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:18:02,128] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:18:02,174] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:18:02,185] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:18:02,201] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:18:02,202] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:18:02,261] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:02,274] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:18:02,306] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:18:02,306] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:18:02,306] INFO Kafka startTimeMs: 1586020682294 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:18:02,333] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:18:02,322] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:18:02,472] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:18:02,591] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:18:02,653] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:18:02,664] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:18:02,664] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:18:02,665] INFO Kafka startTimeMs: 1586020682654 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:18:02,683] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:18:02,696] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:18:02,708] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:18:02,708] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:18:02,708] INFO Kafka startTimeMs: 1586020682697 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:18:02,712] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:18:03,447] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 0, 1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:18:03,706] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:03,910] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:03,927] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 100 ms (kafka.log.Log)
[2020-04-04 18:18:03,928] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:03,931] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:03,934] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:18:03,935] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:03,937] INFO [Partition BatchTopic-0 broker=2] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:04,011] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:04,013] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 175 ms (kafka.log.Log)
[2020-04-04 18:18:04,024] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:04,029] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 195 ms (kafka.log.Log)
[2020-04-04 18:18:04,040] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:04,043] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:18:04,044] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:04,050] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:04,027] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:18:04,087] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:04,093] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:04,109] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:18:04,127] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:04,133] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:18:04,139] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:18:04,166] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:18:04,173] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:04,182] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:18:04,190] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:18:06,409] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 2, 1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:18:06,438] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:06,439] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:06,440] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:18:06,441] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:06,442] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:18:06,443] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:06,442] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:06,444] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:06,444] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:18:06,446] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:06,447] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:18:06,447] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:06,449] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:06,449] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:06,449] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:18:06,450] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:06,451] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:06,452] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:18:06,452] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:06,453] INFO [Partition ReportTopic-0 broker=0] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:06,450] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:18:06,457] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:18:06,457] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:18:06,479] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:18:06,484] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:06,489] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:18:06,487] ERROR [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error for partition ReportTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:18:06,494] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:18:08,537] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 0, 1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:18:08,579] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:08,586] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:08,589] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:08,590] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:08,590] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:08,590] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:08,591] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:18:08,591] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:08,591] INFO [Partition AlarmTopic-0 broker=2] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:08,592] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:08,590] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:08,592] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:18:08,593] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:08,593] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:08,595] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:08,595] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:08,596] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:08,597] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:18:08,597] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:08,597] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:08,598] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:08,806] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:18:08,806] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:18:08,810] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:18:08,811] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:18:11,729] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(2), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(2), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(2), 22 -> ArrayBuffer(2), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(2), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(2), 10 -> ArrayBuffer(2), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(2), 45 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:18:11,762] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-04-04 18:18:12,137] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:12,148] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,149] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,151] INFO Created log for partition __consumer_offsets-10 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,153] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-04-04 18:18:12,153] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,153] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,177] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:12,180] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,182] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:18:12,186] INFO Created log for partition __consumer_offsets-7 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,186] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-04-04 18:18:12,186] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,186] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,201] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,203] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,201] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:18:12,221] INFO Created log for partition __consumer_offsets-4 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,221] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-04-04 18:18:12,222] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,222] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,225] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,227] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:18:12,230] INFO Created log for partition __consumer_offsets-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,234] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,236] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:18:12,239] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,239] INFO Created log for partition __consumer_offsets-29 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,239] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,240] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:18:12,240] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,241] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,242] INFO Created log for partition __consumer_offsets-1 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,242] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-04-04 18:18:12,242] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,243] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,244] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-04-04 18:18:12,244] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,244] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,271] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,272] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,275] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:18:12,275] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:18:12,278] INFO Created log for partition __consumer_offsets-26 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,280] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-04-04 18:18:12,280] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,280] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,278] INFO Created log for partition __consumer_offsets-49 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,281] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-04-04 18:18:12,281] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,281] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,292] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,293] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,297] INFO Created log for partition __consumer_offsets-23 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,297] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-04-04 18:18:12,298] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,298] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,314] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,317] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:18:12,321] INFO Created log for partition __consumer_offsets-46 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,321] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-04-04 18:18:12,321] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,321] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,322] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,327] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-04-04 18:18:12,330] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,333] INFO Created log for partition __consumer_offsets-48 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,333] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-04-04 18:18:12,333] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,334] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,335] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:18:12,337] INFO Created log for partition __consumer_offsets-20 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,338] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-04-04 18:18:12,338] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,338] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,349] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,350] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,353] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,354] INFO Created log for partition __consumer_offsets-43 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,355] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-04-04 18:18:12,355] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:18:12,358] INFO Created log for partition __consumer_offsets-45 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,358] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-04-04 18:18:12,359] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,359] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,374] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,376] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:18:12,377] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,378] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,381] INFO Created log for partition __consumer_offsets-42 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,381] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-04-04 18:18:12,381] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,382] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,388] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,390] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-04-04 18:18:12,393] INFO Created log for partition __consumer_offsets-17 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,393] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-04-04 18:18:12,395] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,396] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,403] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,405] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,405] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,407] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:18:12,408] INFO Created log for partition __consumer_offsets-40 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,408] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-04-04 18:18:12,408] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,408] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,409] INFO Created log for partition __consumer_offsets-39 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,409] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-04-04 18:18:12,409] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,409] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,415] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,416] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,419] INFO Created log for partition __consumer_offsets-14 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,419] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-04-04 18:18:12,419] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,420] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,420] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,421] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:18:12,427] INFO Created log for partition __consumer_offsets-37 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,427] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-04-04 18:18:12,428] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,428] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,437] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,445] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:18:12,450] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,450] INFO Created log for partition __consumer_offsets-36 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,450] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-04-04 18:18:12,451] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,451] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,452] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,452] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:18:12,453] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,454] INFO Created log for partition __consumer_offsets-34 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,455] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-04-04 18:18:12,455] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,455] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,456] INFO Created log for partition __consumer_offsets-11 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,456] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-04-04 18:18:12,456] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,456] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,468] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,470] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,472] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,472] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,472] INFO Created log for partition __consumer_offsets-33 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,472] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-04-04 18:18:12,473] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,473] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,473] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,474] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,475] INFO Created log for partition __consumer_offsets-8 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,476] INFO Created log for partition __consumer_offsets-31 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,476] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-04-04 18:18:12,476] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-04-04 18:18:12,476] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,476] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,476] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,476] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,488] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,492] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:18:12,495] INFO Created log for partition __consumer_offsets-30 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,495] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-04-04 18:18:12,496] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,496] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,499] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,499] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,500] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:18:12,501] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:18:12,501] INFO Created log for partition __consumer_offsets-19 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,501] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-04-04 18:18:12,502] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,502] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,502] INFO Created log for partition __consumer_offsets-5 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,503] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-04-04 18:18:12,503] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,503] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,516] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,524] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,525] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,526] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,525] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:18:12,528] INFO Created log for partition __consumer_offsets-28 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,529] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-04-04 18:18:12,529] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,529] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,530] INFO Created log for partition __consumer_offsets-2 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,530] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-04-04 18:18:12,530] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-04-04 18:18:12,533] INFO Created log for partition __consumer_offsets-27 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,533] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-04-04 18:18:12,538] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,538] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,530] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,541] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,562] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,563] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,563] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:18:12,564] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,565] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-04-04 18:18:12,567] INFO Created log for partition __consumer_offsets-16 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,568] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-04-04 18:18:12,568] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,568] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,568] INFO Created log for partition __consumer_offsets-47 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,568] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-04-04 18:18:12,568] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,568] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,569] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:18:12,571] INFO Created log for partition __consumer_offsets-24 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,571] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-04-04 18:18:12,572] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,572] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,581] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,582] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,584] INFO Created log for partition __consumer_offsets-25 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,584] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-04-04 18:18:12,584] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,584] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,594] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,597] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,599] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:18:12,601] INFO Created log for partition __consumer_offsets-22 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,601] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-04-04 18:18:12,601] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,601] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,601] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,602] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:18:12,602] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-04-04 18:18:12,605] INFO Created log for partition __consumer_offsets-21 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,605] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-04-04 18:18:12,605] INFO Created log for partition __consumer_offsets-38 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,605] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,605] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-04-04 18:18:12,605] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,605] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,605] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,616] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,617] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:18:12,619] INFO Created log for partition __consumer_offsets-13 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,619] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-04-04 18:18:12,619] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,619] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,622] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,623] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,629] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,630] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,630] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,630] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,630] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,631] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,631] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,631] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,631] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,631] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,632] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,632] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,632] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,632] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,632] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,632] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:18:12,633] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,633] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,633] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,633] INFO Created log for partition __consumer_offsets-35 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,633] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-04-04 18:18:12,633] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,634] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,642] INFO Created log for partition __consumer_offsets-18 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,642] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-04-04 18:18:12,643] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,643] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,652] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,655] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:18:12,665] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,665] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 33 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,667] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:18:12,668] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,669] INFO Created log for partition __consumer_offsets-15 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,669] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-04-04 18:18:12,669] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,669] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,670] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,671] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,672] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,673] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,674] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,675] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,676] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,677] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,679] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,679] INFO Created log for partition __consumer_offsets-44 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,679] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,680] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-04-04 18:18:12,680] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,680] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,680] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,681] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,682] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,685] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,689] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,695] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,697] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,698] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-04-04 18:18:12,699] INFO Created log for partition __consumer_offsets-12 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,700] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-04-04 18:18:12,700] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,700] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,700] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:18:12,704] INFO Created log for partition __consumer_offsets-32 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,705] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-04-04 18:18:12,705] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,705] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,715] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,717] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:18:12,719] INFO Created log for partition __consumer_offsets-9 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,719] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-04-04 18:18:12,719] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,719] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,723] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,724] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:18:12,727] INFO Created log for partition __consumer_offsets-41 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,727] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-04-04 18:18:12,727] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,727] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,730] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,731] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:18:12,733] INFO Created log for partition __consumer_offsets-6 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,733] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-04-04 18:18:12,733] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,733] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,738] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,739] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,740] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,740] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,740] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,740] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,740] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,741] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,741] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,741] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,741] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,742] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,742] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,742] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,743] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,743] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,748] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:18:12,750] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:18:12,752] INFO Created log for partition __consumer_offsets-3 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:18:12,752] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-04-04 18:18:12,752] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:18:12,752] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:18:12,754] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,773] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,775] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,776] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,777] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,779] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,780] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,781] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,783] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,784] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,788] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,788] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,789] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,789] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,789] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,789] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,790] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,790] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,790] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,790] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,791] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,791] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,791] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,795] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,796] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,802] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,802] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,803] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,803] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,803] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,803] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,806] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 17 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,807] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,808] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,813] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,814] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,815] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,816] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,817] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,817] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,818] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,820] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,821] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,822] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,823] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,824] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,825] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,826] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,827] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,829] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:18:12,911] INFO [GroupCoordinator 1]: Preparing to rebalance group test in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-test-1-aee40404-bc08-4a16-92b0-7f516cdf057a with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:18:12,937] INFO [GroupCoordinator 1]: Stabilized group test generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:18:12,962] INFO [GroupCoordinator 1]: Assignment received from leader for group test for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:20:11,677] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:20:11,681] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:20:11,681] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:20:11,687] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:20:11,688] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:20:11,691] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:20:11,691] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:20:11,691] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:20:11,691] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:20:11,693] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:20:11,727] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:20:11,727] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:20:11,727] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:20:11,727] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:20:11,727] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:20:11,728] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:20:11,731] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:20:11,736] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:20:11,738] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:20:11,747] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,747] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,747] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,747] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,747] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,747] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,749] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,749] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,749] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,749] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,749] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,749] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,749] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,749] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,749] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,749] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,749] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,750] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,751] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,752] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,752] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:20:11,765] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:20:11,768] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:20:11,775] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:20:11,794] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:20:11,794] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:20:11,800] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:20:11,804] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:20:11,835] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:20:12,383] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:20:12,384] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:20:12,386] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:20:12,429] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:20:12,438] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,438] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,438] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,438] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,438] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,438] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,439] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,439] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,440] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,440] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,440] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,440] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,440] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,440] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,440] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,440] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,440] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,440] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,444] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,452] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:20:12,459] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:20:12,458] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:20:12,472] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:20:12,473] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:20:12,494] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,497] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:20:12,497] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:20:12,502] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,504] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:20:12,504] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:20:12,505] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:20:12,506] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,506] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,506] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,506] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,506] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,507] INFO Socket connection established, initiating session, client: /127.0.0.1:34210, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,507] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,508] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,508] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,508] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,508] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,508] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,508] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,508] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,508] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,508] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,508] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,509] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,509] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,512] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,519] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:20:12,520] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:20:12,526] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:20:12,528] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:20:12,533] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000db72ec0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,538] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:20:12,538] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,538] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,538] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,538] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,538] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,538] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,540] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,545] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:20:12,547] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,551] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:20:12,554] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,555] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:20:12,558] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:20:12,558] INFO Socket connection established, initiating session, client: /127.0.0.1:34214, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,579] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000db72ec0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,580] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,583] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:20:12,585] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:20:12,586] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,590] INFO Socket connection established, initiating session, client: /127.0.0.1:34216, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,603] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000db72ec0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:20:12,608] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:20:12,890] INFO Cluster ID = _gZYr959S2W_sOXHcyx2mw (kafka.server.KafkaServer)
[2020-04-04 18:20:12,896] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:20:12,950] INFO Cluster ID = _gZYr959S2W_sOXHcyx2mw (kafka.server.KafkaServer)
[2020-04-04 18:20:12,955] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:20:12,972] INFO Cluster ID = _gZYr959S2W_sOXHcyx2mw (kafka.server.KafkaServer)
[2020-04-04 18:20:12,973] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:20:12,977] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:20:12,986] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:20:13,024] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:20:13,030] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:20:13,032] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:20:13,043] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:20:13,056] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:20:13,068] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:20:13,070] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:20:13,076] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:20:13,083] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:20:13,088] INFO Logs loading complete in 12 ms. (kafka.log.LogManager)
[2020-04-04 18:20:13,097] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:20:13,097] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:20:13,098] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:20:13,110] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:20:13,115] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:20:13,123] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:20:13,123] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:20:13,124] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:20:13,127] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:20:13,135] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:20:13,147] INFO Logs loading complete in 12 ms. (kafka.log.LogManager)
[2020-04-04 18:20:13,151] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:20:13,158] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:20:13,168] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:20:13,169] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-04 18:20:13,172] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:20:13,192] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:20:13,196] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:20:13,634] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:20:13,685] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:20:13,686] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:20:13,719] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,735] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,736] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:20:13,743] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,746] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:20:13,747] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,771] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:20:13,781] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:20:13,783] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:20:13,787] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:20:13,789] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:20:13,803] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:20:13,806] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,807] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,808] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,809] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,812] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,813] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,813] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,814] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,831] INFO Stat of the created znode at /brokers/ids/2 is: 54,54,1586020813820,1586020813820,1,0,0,72058536563834880,174,0,54
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:20:13,832] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 54 (kafka.zk.KafkaZkClient)
[2020-04-04 18:20:13,833] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:20:13,836] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:20:13,886] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:20:13,911] INFO Stat of the created znode at /brokers/ids/1 is: 55,55,1586020813898,1586020813898,1,0,0,72058536563834882,174,0,55
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:20:13,912] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 55 (kafka.zk.KafkaZkClient)
[2020-04-04 18:20:13,913] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:20:13,927] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,933] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,936] INFO Stat of the created znode at /brokers/ids/0 is: 56,56,1586020813923,1586020813923,1,0,0,72058536563834881,174,0,56
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:20:13,937] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 56 (kafka.zk.KafkaZkClient)
[2020-04-04 18:20:13,947] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:13,958] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:20:14,010] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:20:14,012] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:14,014] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:20:14,017] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:14,020] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:14,027] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:14,047] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:20:14,063] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:20:14,069] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:20:14,077] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:14,077] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:14,080] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:14,083] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:14,090] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:20:14,095] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:20:14,109] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:20:14,110] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:20:14,127] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:20:14,144] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:20:14,150] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:20:14,150] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:20:14,153] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:14,154] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:20:14,184] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 31 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:14,206] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:20:14,215] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:14,261] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:20:14,276] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:20:14,276] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:20:14,277] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:20:14,315] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:20:14,361] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:20:14,367] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:20:14,372] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:20:14,384] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:20:14,388] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:20:14,388] INFO Kafka startTimeMs: 1586020814361 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:20:14,392] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:20:14,395] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:20:14,398] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:20:14,398] INFO Kafka startTimeMs: 1586020814373 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:20:14,401] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:20:14,508] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:20:14,576] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:20:14,596] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:20:14,596] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:20:14,597] INFO Kafka startTimeMs: 1586020814577 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:20:14,604] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:20:15,454] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 1, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:20:15,698] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:15,945] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:15,966] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 138 ms (kafka.log.Log)
[2020-04-04 18:20:15,971] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:15,975] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:20:15,977] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:15,980] INFO [Partition BatchTopic-0 broker=2] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:16,082] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:16,090] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:16,121] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 278 ms (kafka.log.Log)
[2020-04-04 18:20:16,127] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:16,130] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:20:16,132] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:16,137] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:16,171] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 297 ms (kafka.log.Log)
[2020-04-04 18:20:16,178] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:16,182] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:20:16,184] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:16,193] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:16,242] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:20:16,252] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:16,264] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:20:16,271] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:20:16,277] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:20:16,288] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:17,303] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:20:17,308] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:20:18,806] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 1, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:20:18,840] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:18,841] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:18,841] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:20:18,842] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:20:18,842] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:18,832] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:18,843] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:20:18,843] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:18,843] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:18,844] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:20:18,845] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:18,845] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:18,846] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:18,847] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:18,849] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:18,850] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:18,851] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:20:18,852] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:18,853] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:20:18,853] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:18,853] INFO [Partition ReportTopic-0 broker=2] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:18,868] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:20:18,869] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:20:18,967] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:20:18,968] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:20:20,824] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 2, 1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:20:20,853] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:20,855] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:20,856] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:20:20,857] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:20,858] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:20:20,858] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:20,858] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:20:20,859] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:20,860] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:20:20,860] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:20,859] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:20,860] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:20,860] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:20,860] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:20,861] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:20:20,863] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:20,864] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:20:20,864] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:20,865] INFO [Partition AlarmTopic-0 broker=0] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:20,866] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:20,866] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:20:20,867] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:20:20,867] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:20:20,890] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:20:20,894] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:20,899] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:20:20,914] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:20:20,905] ERROR [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error for partition AlarmTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:20:24,065] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(2), 32 -> ArrayBuffer(2), 41 -> ArrayBuffer(2), 17 -> ArrayBuffer(2), 8 -> ArrayBuffer(2), 35 -> ArrayBuffer(2), 44 -> ArrayBuffer(2), 26 -> ArrayBuffer(2), 11 -> ArrayBuffer(2), 29 -> ArrayBuffer(2), 38 -> ArrayBuffer(2), 47 -> ArrayBuffer(2), 20 -> ArrayBuffer(2), 2 -> ArrayBuffer(2), 5 -> ArrayBuffer(2), 14 -> ArrayBuffer(2), 46 -> ArrayBuffer(1), 49 -> ArrayBuffer(1), 40 -> ArrayBuffer(1), 13 -> ArrayBuffer(1), 4 -> ArrayBuffer(1), 22 -> ArrayBuffer(1), 31 -> ArrayBuffer(1), 16 -> ArrayBuffer(1), 7 -> ArrayBuffer(1), 43 -> ArrayBuffer(1), 25 -> ArrayBuffer(1), 34 -> ArrayBuffer(1), 10 -> ArrayBuffer(1), 37 -> ArrayBuffer(1), 1 -> ArrayBuffer(1), 19 -> ArrayBuffer(1), 28 -> ArrayBuffer(1), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:20:24,104] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-04-04 18:20:24,422] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:24,446] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,447] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-04-04 18:20:24,449] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:24,455] INFO Created log for partition __consumer_offsets-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,457] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,457] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,457] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,470] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:20:24,481] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,481] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,483] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-04-04 18:20:24,486] INFO Created log for partition __consumer_offsets-29 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,487] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-04-04 18:20:24,487] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,487] INFO [Partition __consumer_offsets-29 broker=2] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,490] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-04-04 18:20:24,492] INFO Created log for partition __consumer_offsets-48 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,493] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-04-04 18:20:24,493] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,493] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,500] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,502] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-04-04 18:20:24,503] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,504] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:20:24,507] INFO Created log for partition __consumer_offsets-26 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,507] INFO [Partition __consumer_offsets-26 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-04-04 18:20:24,508] INFO [Partition __consumer_offsets-26 broker=2] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,508] INFO [Partition __consumer_offsets-26 broker=2] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,513] INFO Created log for partition __consumer_offsets-10 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,514] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,515] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-04-04 18:20:24,515] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,516] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:20:24,517] INFO [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,522] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,523] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:20:24,523] INFO Created log for partition __consumer_offsets-45 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,523] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-04-04 18:20:24,524] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,525] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,526] INFO Created log for partition __consumer_offsets-23 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,526] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-04-04 18:20:24,526] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,527] INFO [Partition __consumer_offsets-23 broker=2] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,538] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,539] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:20:24,542] INFO Created log for partition __consumer_offsets-42 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,542] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-04-04 18:20:24,542] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,543] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,550] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,551] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:20:24,554] INFO Created log for partition __consumer_offsets-20 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,554] INFO [Partition __consumer_offsets-20 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-04-04 18:20:24,554] INFO [Partition __consumer_offsets-20 broker=2] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,554] INFO [Partition __consumer_offsets-20 broker=2] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,566] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,574] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,574] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-04-04 18:20:24,575] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:24,578] INFO Created log for partition __consumer_offsets-7 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,578] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-04-04 18:20:24,578] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,578] INFO Created log for partition __consumer_offsets-39 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,579] INFO [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,579] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-04-04 18:20:24,579] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,579] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,580] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,581] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:20:24,584] INFO Created log for partition __consumer_offsets-17 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,584] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-04-04 18:20:24,584] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,584] INFO [Partition __consumer_offsets-17 broker=2] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,600] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,602] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:24,603] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,604] INFO Created log for partition __consumer_offsets-4 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,605] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-04-04 18:20:24,605] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:24,605] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,605] INFO [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,608] INFO Created log for partition __consumer_offsets-14 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,608] INFO [Partition __consumer_offsets-14 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-04-04 18:20:24,608] INFO [Partition __consumer_offsets-14 broker=2] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,608] INFO [Partition __consumer_offsets-14 broker=2] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,609] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,611] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:20:24,616] INFO Created log for partition __consumer_offsets-36 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,616] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,616] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-04-04 18:20:24,617] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,617] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,617] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:20:24,620] INFO Created log for partition __consumer_offsets-1 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,620] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-04-04 18:20:24,621] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,621] INFO [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,626] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,632] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:20:24,634] INFO Created log for partition __consumer_offsets-11 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,635] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-04-04 18:20:24,635] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,635] INFO [Partition __consumer_offsets-11 broker=2] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,648] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,649] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,649] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:24,650] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,650] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:20:24,652] INFO Created log for partition __consumer_offsets-8 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,652] INFO [Partition __consumer_offsets-8 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-04-04 18:20:24,652] INFO [Partition __consumer_offsets-8 broker=2] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,653] INFO [Partition __consumer_offsets-8 broker=2] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,653] INFO Created log for partition __consumer_offsets-49 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,653] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-04-04 18:20:24,654] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,655] INFO [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,659] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:20:24,662] INFO Created log for partition __consumer_offsets-33 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,662] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-04-04 18:20:24,662] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,662] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,664] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,666] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:24,670] INFO Created log for partition __consumer_offsets-5 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,670] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-04-04 18:20:24,670] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,670] INFO [Partition __consumer_offsets-5 broker=2] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,684] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,686] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:20:24,690] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,690] INFO Created log for partition __consumer_offsets-46 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,691] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-04-04 18:20:24,691] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,691] INFO [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,692] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:20:24,693] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,694] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:20:24,695] INFO Created log for partition __consumer_offsets-30 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,696] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-04-04 18:20:24,696] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,696] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,699] INFO Created log for partition __consumer_offsets-2 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,699] INFO [Partition __consumer_offsets-2 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-04-04 18:20:24,699] INFO [Partition __consumer_offsets-2 broker=2] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,699] INFO [Partition __consumer_offsets-2 broker=2] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,709] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,710] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:24,714] INFO Created log for partition __consumer_offsets-43 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,714] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-04-04 18:20:24,714] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,715] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,714] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,715] INFO [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,717] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:20:24,717] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:20:24,719] INFO Created log for partition __consumer_offsets-27 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,720] INFO Created log for partition __consumer_offsets-47 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,720] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-04-04 18:20:24,720] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-04-04 18:20:24,720] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,720] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,720] INFO [Partition __consumer_offsets-47 broker=2] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,721] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,740] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,740] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,741] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:24,742] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:20:24,742] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,743] INFO Created log for partition __consumer_offsets-38 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,743] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:20:24,744] INFO [Partition __consumer_offsets-38 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-04-04 18:20:24,744] INFO [Partition __consumer_offsets-38 broker=2] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,744] INFO [Partition __consumer_offsets-38 broker=2] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,744] INFO Created log for partition __consumer_offsets-40 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,744] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-04-04 18:20:24,744] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,744] INFO [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,746] INFO Created log for partition __consumer_offsets-24 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,746] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-04-04 18:20:24,747] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,747] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,756] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,757] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:20:24,759] INFO Created log for partition __consumer_offsets-35 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,760] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-04-04 18:20:24,760] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,760] INFO [Partition __consumer_offsets-35 broker=2] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,766] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,770] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,772] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:20:24,775] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,775] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:20:24,777] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:24,778] INFO Created log for partition __consumer_offsets-37 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,778] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-04-04 18:20:24,779] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,780] INFO Created log for partition __consumer_offsets-44 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,780] INFO [Partition __consumer_offsets-44 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-04-04 18:20:24,780] INFO [Partition __consumer_offsets-44 broker=2] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,780] INFO [Partition __consumer_offsets-44 broker=2] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,779] INFO [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,794] INFO Created log for partition __consumer_offsets-21 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,794] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-04-04 18:20:24,794] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,795] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,808] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,810] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:24,812] INFO Created log for partition __consumer_offsets-34 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,813] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-04-04 18:20:24,813] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,813] INFO [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,816] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,820] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-04-04 18:20:24,823] INFO Created log for partition __consumer_offsets-32 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,823] INFO [Partition __consumer_offsets-32 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-04-04 18:20:24,823] INFO [Partition __consumer_offsets-32 broker=2] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,824] INFO [Partition __consumer_offsets-32 broker=2] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,830] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,837] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-04-04 18:20:24,839] INFO Created log for partition __consumer_offsets-18 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,842] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,845] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,847] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-04-04 18:20:24,847] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,848] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,848] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:20:24,849] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:20:24,852] INFO Created log for partition __consumer_offsets-31 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,852] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-04-04 18:20:24,852] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,852] INFO [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,852] INFO Created log for partition __consumer_offsets-41 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,853] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-04-04 18:20:24,853] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,854] INFO [Partition __consumer_offsets-41 broker=2] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,862] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,864] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:24,866] INFO Created log for partition __consumer_offsets-15 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,866] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-04-04 18:20:24,867] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,867] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,875] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,877] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:20:24,878] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,879] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,879] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,880] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,880] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,883] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,883] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,883] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,883] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,884] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,883] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,884] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,884] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,884] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,884] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,885] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,885] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,885] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:20:24,886] INFO Created log for partition __consumer_offsets-19 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,886] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-04-04 18:20:24,887] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,887] INFO [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,887] INFO Created log for partition __consumer_offsets-12 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,887] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-04-04 18:20:24,887] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,888] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,913] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,914] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-04-04 18:20:24,922] INFO Created log for partition __consumer_offsets-28 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,922] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-04-04 18:20:24,922] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,922] INFO [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,927] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,929] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:24,934] INFO Created log for partition __consumer_offsets-9 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,928] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 38 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,934] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-04-04 18:20:24,935] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,935] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,938] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,938] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,940] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,941] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,942] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,943] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,944] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,944] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,945] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:20:24,945] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,946] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,947] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,947] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,948] INFO Created log for partition __consumer_offsets-16 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,948] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-04-04 18:20:24,948] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,948] INFO [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,949] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,950] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,951] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,951] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:24,954] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,955] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:20:24,957] INFO Created log for partition __consumer_offsets-6 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,958] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-04-04 18:20:24,958] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,958] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,977] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,979] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:20:24,981] INFO Created log for partition __consumer_offsets-25 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,981] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-04-04 18:20:24,981] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,981] INFO [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:24,987] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:24,989] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:20:24,991] INFO Created log for partition __consumer_offsets-3 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:24,991] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-04-04 18:20:24,991] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:24,991] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:25,000] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:25,001] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:20:25,003] INFO Created log for partition __consumer_offsets-22 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:25,003] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-04-04 18:20:25,003] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:25,003] INFO [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:25,018] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,023] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:20:25,025] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:20:25,027] INFO Created log for partition __consumer_offsets-13 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:20:25,027] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-04-04 18:20:25,028] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:20:25,028] INFO [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:20:25,043] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,037] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,044] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,045] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,045] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,045] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,045] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,046] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,046] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,046] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,047] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,047] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,047] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,047] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,047] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,047] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,047] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,048] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,048] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,048] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,048] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,048] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,048] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,049] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,049] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,049] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,049] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,049] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,050] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,050] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,051] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,051] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,051] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,054] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,063] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,064] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,066] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,067] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,068] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,070] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,071] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,073] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,076] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,077] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,078] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,079] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,079] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,081] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,076] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 28 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,090] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,092] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,107] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,108] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,115] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,116] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,117] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,118] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,119] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,120] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,121] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,122] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:20:25,213] INFO [GroupCoordinator 0]: Preparing to rebalance group test in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-test-1-dd1f77fd-ae7d-40d4-9e74-9bad5ceaa503 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:20:25,243] INFO [GroupCoordinator 0]: Stabilized group test generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:20:25,273] INFO [GroupCoordinator 0]: Assignment received from leader for group test for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:43:19,371] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:43:19,373] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:43:19,374] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:43:19,379] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:43:19,380] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:43:19,382] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:43:19,382] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:43:19,382] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:43:19,382] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:43:19,384] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:43:19,414] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:43:19,414] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:43:19,414] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:43:19,415] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:43:19,415] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:43:19,415] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:43:19,419] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:43:19,433] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,434] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,434] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,434] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,434] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,434] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,435] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,435] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,435] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,435] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,435] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,435] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,435] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,435] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,436] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,436] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,436] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,436] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,438] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,438] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,439] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:43:19,445] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:43:19,448] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:43:19,454] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:43:19,461] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:43:19,484] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:43:19,490] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:43:19,496] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:43:19,530] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:43:19,531] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:43:19,537] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:43:20,242] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:43:20,250] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:43:20,251] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:43:20,258] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:43:20,259] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:43:20,260] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:43:20,286] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:43:20,293] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:43:20,295] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,295] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,295] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,295] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,295] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,295] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,296] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,296] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,296] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,296] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,296] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,296] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,296] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,296] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,296] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,297] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,297] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,297] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,299] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,300] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,300] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,300] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,300] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,300] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,300] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,301] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,301] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,301] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,301] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,301] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,301] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,302] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,302] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,302] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,302] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,302] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,302] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,306] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:43:20,306] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,312] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:43:20,313] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:43:20,321] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:43:20,323] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:43:20,324] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:43:20,325] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:43:20,354] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:43:20,355] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,360] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:43:20,361] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,362] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,362] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,362] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,362] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,362] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,362] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,363] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,364] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,364] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,364] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,364] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,364] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,364] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:43:20,364] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,364] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,364] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,364] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,364] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,364] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,364] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,367] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,368] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:43:20,371] INFO Socket connection established, initiating session, client: /127.0.0.1:34456, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,375] INFO Socket connection established, initiating session, client: /127.0.0.1:34458, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,378] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:43:20,383] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:43:20,383] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:43:20,405] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f09f980000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,405] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f09f980001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,409] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,410] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:43:20,410] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:43:20,414] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:43:20,415] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,421] INFO Socket connection established, initiating session, client: /127.0.0.1:34460, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,429] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f09f980002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:43:20,433] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:43:20,795] INFO Cluster ID = rourjs6wRCKUpat-3GwVAA (kafka.server.KafkaServer)
[2020-04-04 18:43:20,800] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:43:20,837] INFO Cluster ID = rourjs6wRCKUpat-3GwVAA (kafka.server.KafkaServer)
[2020-04-04 18:43:20,839] INFO Cluster ID = rourjs6wRCKUpat-3GwVAA (kafka.server.KafkaServer)
[2020-04-04 18:43:20,842] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:43:20,843] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:43:20,906] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:43:20,925] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:43:20,933] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:43:20,945] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:43:20,954] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:43:20,963] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:43:20,977] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:43:20,977] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:43:20,979] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:43:20,998] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:43:20,999] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:43:21,000] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:43:21,000] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:43:21,001] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:43:21,002] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:43:21,020] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:43:21,029] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:43:21,031] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:43:21,032] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:43:21,042] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:43:21,042] INFO Logs loading complete in 13 ms. (kafka.log.LogManager)
[2020-04-04 18:43:21,043] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:43:21,053] INFO Logs loading complete in 11 ms. (kafka.log.LogManager)
[2020-04-04 18:43:21,057] INFO Logs loading complete in 14 ms. (kafka.log.LogManager)
[2020-04-04 18:43:21,067] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:43:21,076] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:43:21,081] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:43:21,082] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:43:21,090] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:43:21,090] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:43:21,726] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:43:21,749] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:43:21,765] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:43:21,804] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:43:21,807] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:43:21,821] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:43:21,823] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:43:21,826] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:43:21,828] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:43:21,840] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,841] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,842] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,843] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,853] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,853] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,854] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,855] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,856] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,857] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,858] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,859] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:21,867] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:43:21,877] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:43:21,879] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:43:21,898] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:43:21,911] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:43:21,913] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:43:21,927] INFO Stat of the created znode at /brokers/ids/0 is: 62,62,1586022201916,1586022201916,1,0,0,72058627507617792,174,0,62
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:43:21,928] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 62 (kafka.zk.KafkaZkClient)
[2020-04-04 18:43:21,933] INFO Stat of the created znode at /brokers/ids/2 is: 63,63,1586022201920,1586022201920,1,0,0,72058627507617793,174,0,63
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:43:21,933] INFO Stat of the created znode at /brokers/ids/1 is: 64,64,1586022201923,1586022201923,1,0,0,72058627507617794,174,0,64
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:43:21,934] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 63 (kafka.zk.KafkaZkClient)
[2020-04-04 18:43:21,935] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 64 (kafka.zk.KafkaZkClient)
[2020-04-04 18:43:22,014] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,024] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,034] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,035] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,035] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:43:22,039] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,042] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,059] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,062] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,067] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,084] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:43:22,086] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:43:22,089] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:43:22,090] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:43:22,092] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:22,109] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 19 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:22,114] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:43:22,126] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:43:22,136] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:43:22,136] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:43:22,143] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:22,154] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:43:22,163] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:43:22,168] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:43:22,171] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:43:22,180] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:43:22,182] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:43:22,194] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:43:22,215] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:43:22,218] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,218] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:43:22,222] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,227] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:43:22,260] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:43:22,262] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:43:22,291] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:43:22,294] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:43:22,295] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:43:22,295] INFO Kafka startTimeMs: 1586022202291 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:43:22,302] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:43:22,305] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:43:22,306] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:43:22,336] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:43:22,361] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:43:22,360] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:43:22,370] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:43:22,370] INFO Kafka startTimeMs: 1586022202337 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:43:22,375] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:43:22,384] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:43:22,384] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:43:22,384] INFO Kafka startTimeMs: 1586022202362 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:43:22,387] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:43:22,662] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:43:22,813] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:22,976] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:22,991] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 102 ms (kafka.log.Log)
[2020-04-04 18:43:22,995] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:22,997] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:43:22,998] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:23,001] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:23,019] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:23,099] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:43:23,124] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 202 ms (kafka.log.Log)
[2020-04-04 18:43:23,128] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:23,134] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:23,136] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:43:23,139] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:43:23,142] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:23,149] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:43:23,151] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:23,231] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:23,268] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 357 ms (kafka.log.Log)
[2020-04-04 18:43:23,276] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:23,280] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:43:23,283] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:23,284] INFO [Partition BatchTopic-0 broker=1] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:23,295] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:43:23,308] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition BatchTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:43:23,329] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:23,339] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:43:23,359] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:43:23,431] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition BatchTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:43:26,399] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 2, 1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:43:26,432] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:26,433] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:26,434] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:43:26,436] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:26,437] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:43:26,437] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:26,438] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:26,441] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:26,441] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:26,441] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:43:26,442] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:43:26,443] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:26,444] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:26,444] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:43:26,444] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:26,445] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:43:26,445] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:26,445] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:26,446] INFO [Partition ReportTopic-0 broker=0] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:26,447] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:26,447] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:43:26,448] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:43:26,449] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:43:26,483] ERROR [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error for partition ReportTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:43:26,492] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:43:26,493] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:26,504] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:43:26,509] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:43:28,818] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 2, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:43:28,853] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:28,858] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:28,858] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:28,859] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:43:28,859] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:43:28,859] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:28,860] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:43:28,860] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:28,861] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:28,861] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:43:28,861] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:28,861] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:43:28,861] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:28,862] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:28,862] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:28,862] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:28,863] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:28,863] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:43:28,863] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:28,864] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:28,864] INFO [Partition AlarmTopic-0 broker=1] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:28,962] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:43:28,963] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:43:29,016] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:43:29,017] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:43:32,046] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(1), 32 -> ArrayBuffer(1), 41 -> ArrayBuffer(1), 17 -> ArrayBuffer(1), 8 -> ArrayBuffer(1), 35 -> ArrayBuffer(1), 44 -> ArrayBuffer(1), 26 -> ArrayBuffer(1), 11 -> ArrayBuffer(1), 29 -> ArrayBuffer(1), 38 -> ArrayBuffer(1), 47 -> ArrayBuffer(1), 20 -> ArrayBuffer(1), 2 -> ArrayBuffer(1), 5 -> ArrayBuffer(1), 14 -> ArrayBuffer(1), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(2), 27 -> ArrayBuffer(2), 36 -> ArrayBuffer(2), 18 -> ArrayBuffer(2), 9 -> ArrayBuffer(2), 21 -> ArrayBuffer(2), 48 -> ArrayBuffer(2), 3 -> ArrayBuffer(2), 12 -> ArrayBuffer(2), 30 -> ArrayBuffer(2), 39 -> ArrayBuffer(2), 15 -> ArrayBuffer(2), 42 -> ArrayBuffer(2), 24 -> ArrayBuffer(2), 6 -> ArrayBuffer(2), 33 -> ArrayBuffer(2), 0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:43:32,066] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-04-04 18:43:32,378] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:32,392] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,396] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:43:32,410] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:32,422] INFO Created log for partition __consumer_offsets-10 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,424] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-04-04 18:43:32,424] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,424] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,432] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,433] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:43:32,436] INFO Created log for partition __consumer_offsets-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,439] INFO [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,439] INFO [Partition __consumer_offsets-0 broker=2] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,441] INFO [Partition __consumer_offsets-0 broker=2] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,454] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,455] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:43:32,455] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:43:32,458] INFO Created log for partition __consumer_offsets-7 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,458] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-04-04 18:43:32,458] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,458] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,482] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,484] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:43:32,488] INFO Created log for partition __consumer_offsets-29 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,490] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,490] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-04-04 18:43:32,490] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,490] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,491] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:43:32,503] INFO Created log for partition __consumer_offsets-4 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,503] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-04-04 18:43:32,503] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,503] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,505] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,507] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:43:32,512] INFO Created log for partition __consumer_offsets-26 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,512] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-04-04 18:43:32,515] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,515] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,519] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,521] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:43:32,523] INFO Created log for partition __consumer_offsets-1 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,524] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-04-04 18:43:32,524] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,524] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,527] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,529] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:43:32,532] INFO Created log for partition __consumer_offsets-48 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,532] INFO [Partition __consumer_offsets-48 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-04-04 18:43:32,532] INFO [Partition __consumer_offsets-48 broker=2] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,532] INFO [Partition __consumer_offsets-48 broker=2] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,541] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,546] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:43:32,549] INFO Created log for partition __consumer_offsets-23 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,550] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-04-04 18:43:32,550] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,550] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,550] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,551] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,553] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:43:32,556] INFO Created log for partition __consumer_offsets-45 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,556] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-04-04 18:43:32,556] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,556] INFO [Partition __consumer_offsets-45 broker=2] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,556] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-04-04 18:43:32,559] INFO Created log for partition __consumer_offsets-49 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,559] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-04-04 18:43:32,560] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,560] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,577] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,578] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,579] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-04-04 18:43:32,579] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:43:32,582] INFO Created log for partition __consumer_offsets-20 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,582] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-04-04 18:43:32,582] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,583] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,584] INFO Created log for partition __consumer_offsets-46 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,585] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-04-04 18:43:32,585] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,585] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,607] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,608] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,609] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,610] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:43:32,612] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-04-04 18:43:32,613] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-04-04 18:43:32,615] INFO Created log for partition __consumer_offsets-42 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,616] INFO [Partition __consumer_offsets-42 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-04-04 18:43:32,616] INFO [Partition __consumer_offsets-42 broker=2] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,616] INFO [Partition __consumer_offsets-42 broker=2] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,618] INFO Created log for partition __consumer_offsets-43 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,619] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-04-04 18:43:32,619] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,619] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,620] INFO Created log for partition __consumer_offsets-17 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,620] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-04-04 18:43:32,620] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,621] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,641] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,643] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:43:32,647] INFO Created log for partition __consumer_offsets-39 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,648] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-04-04 18:43:32,648] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,648] INFO [Partition __consumer_offsets-39 broker=2] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,648] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,652] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-04-04 18:43:32,655] INFO Created log for partition __consumer_offsets-14 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,656] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-04-04 18:43:32,656] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,656] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,665] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,666] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-04-04 18:43:32,669] INFO Created log for partition __consumer_offsets-40 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,669] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,669] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-04-04 18:43:32,670] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,670] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,672] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:43:32,674] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,677] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:43:32,677] INFO Created log for partition __consumer_offsets-36 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,679] INFO [Partition __consumer_offsets-36 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-04-04 18:43:32,679] INFO [Partition __consumer_offsets-36 broker=2] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,680] INFO [Partition __consumer_offsets-36 broker=2] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,683] INFO Created log for partition __consumer_offsets-11 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,683] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-04-04 18:43:32,684] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,684] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,689] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,691] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:43:32,695] INFO Created log for partition __consumer_offsets-37 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,696] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-04-04 18:43:32,696] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,696] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,703] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,708] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:43:32,716] INFO Created log for partition __consumer_offsets-33 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,716] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-04-04 18:43:32,716] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,717] INFO [Partition __consumer_offsets-33 broker=2] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,722] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,723] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,724] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:43:32,727] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:43:32,731] INFO Created log for partition __consumer_offsets-34 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,731] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-04-04 18:43:32,731] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,731] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,734] INFO Created log for partition __consumer_offsets-8 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,734] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,734] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-04-04 18:43:32,735] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,735] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,736] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:43:32,744] INFO Created log for partition __consumer_offsets-30 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,745] INFO [Partition __consumer_offsets-30 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-04-04 18:43:32,745] INFO [Partition __consumer_offsets-30 broker=2] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,745] INFO [Partition __consumer_offsets-30 broker=2] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,754] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,756] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:43:32,758] INFO Created log for partition __consumer_offsets-31 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,758] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-04-04 18:43:32,758] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,758] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,762] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,765] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:43:32,767] INFO Created log for partition __consumer_offsets-27 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,767] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-04-04 18:43:32,768] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,768] INFO [Partition __consumer_offsets-27 broker=2] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,772] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,773] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:43:32,776] INFO Created log for partition __consumer_offsets-5 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,777] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-04-04 18:43:32,778] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,779] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,780] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,781] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:43:32,785] INFO Created log for partition __consumer_offsets-19 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,785] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-04-04 18:43:32,785] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,786] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,791] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,793] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:43:32,798] INFO Created log for partition __consumer_offsets-24 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,799] INFO [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-04-04 18:43:32,799] INFO [Partition __consumer_offsets-24 broker=2] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,799] INFO [Partition __consumer_offsets-24 broker=2] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,799] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,801] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:43:32,814] INFO Created log for partition __consumer_offsets-2 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,818] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-04-04 18:43:32,818] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,818] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,820] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,822] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-04-04 18:43:32,828] INFO Created log for partition __consumer_offsets-28 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,829] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-04-04 18:43:32,829] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,829] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,832] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,834] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-04-04 18:43:32,837] INFO Created log for partition __consumer_offsets-21 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,837] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-04-04 18:43:32,837] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,837] INFO [Partition __consumer_offsets-21 broker=2] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,848] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,851] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:43:32,853] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,854] INFO Created log for partition __consumer_offsets-16 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,855] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-04-04 18:43:32,856] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-04-04 18:43:32,856] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,856] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,856] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,857] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:43:32,857] INFO Created log for partition __consumer_offsets-47 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,858] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-04-04 18:43:32,858] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,858] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,860] INFO Created log for partition __consumer_offsets-18 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,862] INFO [Partition __consumer_offsets-18 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-04-04 18:43:32,862] INFO [Partition __consumer_offsets-18 broker=2] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,863] INFO [Partition __consumer_offsets-18 broker=2] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,871] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,872] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:43:32,874] INFO Created log for partition __consumer_offsets-25 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,875] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-04-04 18:43:32,875] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,875] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,882] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,883] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:43:32,885] INFO Created log for partition __consumer_offsets-15 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,885] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-04-04 18:43:32,885] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,886] INFO [Partition __consumer_offsets-15 broker=2] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,888] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,889] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:43:32,891] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,895] INFO Created log for partition __consumer_offsets-38 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,896] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-04-04 18:43:32,896] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:43:32,899] INFO Created log for partition __consumer_offsets-22 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,899] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-04-04 18:43:32,899] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,899] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,896] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,904] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,906] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,909] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:43:32,913] INFO Created log for partition __consumer_offsets-12 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,913] INFO [Partition __consumer_offsets-12 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-04-04 18:43:32,914] INFO [Partition __consumer_offsets-12 broker=2] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,914] INFO [Partition __consumer_offsets-12 broker=2] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,930] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,931] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:43:32,934] INFO Created log for partition __consumer_offsets-13 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,934] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-04-04 18:43:32,934] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,934] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,938] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,939] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-04-04 18:43:32,942] INFO Created log for partition __consumer_offsets-35 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,942] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-04-04 18:43:32,942] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,943] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,945] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,947] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:43:32,949] INFO Created log for partition __consumer_offsets-9 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,949] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-04-04 18:43:32,950] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,950] INFO [Partition __consumer_offsets-9 broker=2] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,958] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,960] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,960] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,960] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,960] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,961] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,961] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,961] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,961] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,961] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,962] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,963] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,963] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,967] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,967] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,967] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,967] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,969] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,982] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-04-04 18:43:32,984] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:32,986] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:43:32,991] INFO Created log for partition __consumer_offsets-44 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,981] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,991] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-04-04 18:43:32,992] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,992] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,994] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,996] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,996] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,997] INFO Created log for partition __consumer_offsets-6 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:32,997] INFO [Partition __consumer_offsets-6 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-04-04 18:43:32,997] INFO [Partition __consumer_offsets-6 broker=2] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:32,997] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,997] INFO [Partition __consumer_offsets-6 broker=2] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:32,998] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:32,999] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,000] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,001] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,003] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,005] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,006] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,007] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,008] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,009] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,021] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:33,024] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-04-04 18:43:33,026] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:33,028] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:43:33,031] INFO Created log for partition __consumer_offsets-3 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:33,031] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-04-04 18:43:33,032] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:33,032] INFO [Partition __consumer_offsets-3 broker=2] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:33,034] INFO Created log for partition __consumer_offsets-32 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:33,034] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-04-04 18:43:33,034] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:33,034] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:33,050] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,052] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,052] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,053] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,053] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,054] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,054] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,054] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,055] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,055] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,055] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,055] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,056] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,056] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,057] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,057] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,057] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,067] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:43:33,074] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-04-04 18:43:33,077] INFO Created log for partition __consumer_offsets-41 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:43:33,077] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-04-04 18:43:33,077] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:43:33,077] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:43:33,084] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 31 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,087] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,088] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,089] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,090] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,094] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,095] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,096] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,097] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,099] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,100] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,101] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,102] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,104] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,106] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,106] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,107] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,107] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,108] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,108] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,108] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,109] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,109] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,110] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,110] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-48 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,110] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,111] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,111] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,111] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,112] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,112] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,113] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,113] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,127] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 19 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,134] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,136] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,137] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,138] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,140] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,141] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,145] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,147] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,148] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,149] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,151] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,152] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,153] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,154] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,155] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:43:33,265] INFO [GroupCoordinator 2]: Preparing to rebalance group test in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-test-1-11a6f5dc-3a7e-4451-9c09-33ff95f21519 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:43:33,288] INFO [GroupCoordinator 2]: Stabilized group test generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:43:33,316] INFO [GroupCoordinator 2]: Assignment received from leader for group test for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:45:17,971] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:45:17,973] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:45:17,973] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:45:17,981] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:45:17,981] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:45:17,983] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:45:17,983] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:45:17,983] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:45:17,983] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:45:17,985] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:45:17,989] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:45:18,012] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:45:18,012] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:45:18,012] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:45:18,012] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:45:18,012] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:45:18,012] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:45:18,016] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:45:18,042] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,042] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,042] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,042] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,042] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,042] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,043] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,045] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,045] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,046] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:45:18,053] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:45:18,056] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:45:18,059] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:45:18,064] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:45:18,065] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:45:18,087] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:45:18,094] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:45:18,098] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:45:18,122] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:45:18,629] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:45:18,630] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:45:18,631] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:45:18,659] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:45:18,667] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,667] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,667] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,668] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,668] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,668] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,669] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,669] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,669] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,669] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,669] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,669] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,669] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,669] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,669] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,669] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,670] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,670] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,673] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,678] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:45:18,678] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:45:18,679] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:45:18,680] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:45:18,690] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:45:18,714] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,723] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:45:18,726] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:45:18,731] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,733] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,733] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,733] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,733] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,733] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,733] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,735] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,735] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,735] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,735] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,735] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,735] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,735] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,735] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,736] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,736] INFO Socket connection established, initiating session, client: /127.0.0.1:34516, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,736] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,736] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,736] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,742] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,750] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:45:18,754] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:45:18,759] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:45:18,786] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f26ee20000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,790] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,792] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:45:18,798] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,799] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:45:18,804] INFO Socket connection established, initiating session, client: /127.0.0.1:34520, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,822] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f26ee20001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,827] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:45:18,837] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:45:18,840] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:45:18,841] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:45:18,868] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:45:18,878] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,878] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,878] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,878] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,878] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,878] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,879] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,879] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,879] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,879] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,879] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,879] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,880] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,880] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,880] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,880] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,880] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,880] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,883] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:45:18,889] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:45:18,895] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:45:18,913] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,917] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:45:18,920] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,928] INFO Socket connection established, initiating session, client: /127.0.0.1:34524, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,934] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f26ee20002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:45:18,942] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:45:19,158] INFO Cluster ID = NOobA-qsQEK7I9-kww9Dgw (kafka.server.KafkaServer)
[2020-04-04 18:45:19,165] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:45:19,231] INFO Cluster ID = NOobA-qsQEK7I9-kww9Dgw (kafka.server.KafkaServer)
[2020-04-04 18:45:19,234] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:45:19,243] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:45:19,265] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:45:19,303] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:45:19,303] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:45:19,303] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:45:19,314] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:45:19,337] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:45:19,340] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:45:19,348] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:45:19,352] INFO Cluster ID = NOobA-qsQEK7I9-kww9Dgw (kafka.server.KafkaServer)
[2020-04-04 18:45:19,358] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:45:19,359] INFO Logs loading complete in 11 ms. (kafka.log.LogManager)
[2020-04-04 18:45:19,380] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:45:19,384] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:45:19,384] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:45:19,386] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:45:19,387] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:45:19,420] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:45:19,429] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:45:19,440] INFO Logs loading complete in 11 ms. (kafka.log.LogManager)
[2020-04-04 18:45:19,442] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:45:19,462] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:45:19,462] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:45:19,468] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:45:19,501] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:45:19,501] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:45:19,502] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:45:19,531] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:45:19,539] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:45:19,548] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-04 18:45:19,571] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:45:19,581] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:45:19,996] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:45:20,040] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:45:20,042] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:45:20,048] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:45:20,065] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,066] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,071] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,072] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,092] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:45:20,094] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:45:20,095] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:45:20,126] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,126] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,127] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,127] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:45:20,134] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,152] INFO Stat of the created znode at /brokers/ids/1 is: 54,54,1586022320144,1586022320144,1,0,0,72058635280318465,174,0,54
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:45:20,153] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 54 (kafka.zk.KafkaZkClient)
[2020-04-04 18:45:20,165] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:45:20,177] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:45:20,220] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:45:20,222] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:45:20,224] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:45:20,239] INFO Stat of the created znode at /brokers/ids/0 is: 55,55,1586022320231,1586022320231,1,0,0,72058635280318464,174,0,55
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:45:20,240] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 55 (kafka.zk.KafkaZkClient)
[2020-04-04 18:45:20,248] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,256] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,256] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,271] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:45:20,279] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,281] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,287] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,294] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,315] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:45:20,322] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:45:20,334] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:20,343] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:45:20,348] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:45:20,352] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,356] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,366] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,385] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:45:20,416] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:45:20,422] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:45:20,423] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:45:20,427] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:45:20,428] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:45:20,442] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:20,461] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:45:20,466] INFO Stat of the created znode at /brokers/ids/2 is: 59,59,1586022320449,1586022320449,1,0,0,72058635280318466,174,0,59
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:45:20,467] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 59 (kafka.zk.KafkaZkClient)
[2020-04-04 18:45:20,527] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,531] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:45:20,537] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:45:20,538] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:45:20,608] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:45:20,653] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,707] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:45:20,726] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:45:20,726] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:45:20,726] INFO Kafka startTimeMs: 1586022320708 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:45:20,730] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:45:20,739] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,755] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,765] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:20,786] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:45:20,889] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:45:20,892] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:45:20,895] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:45:20,909] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:45:20,910] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:45:20,910] INFO Kafka startTimeMs: 1586022320891 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:45:20,916] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 22 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:20,925] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:45:20,957] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:45:21,064] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:45:21,071] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:45:21,072] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:45:21,178] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:45:21,288] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:45:21,364] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:45:21,376] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:45:21,376] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:45:21,376] INFO Kafka startTimeMs: 1586022321365 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:45:21,380] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:45:22,035] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:45:22,290] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:22,523] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:22,550] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 128 ms (kafka.log.Log)
[2020-04-04 18:45:22,558] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:22,562] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:45:22,565] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:22,567] INFO [Partition BatchTopic-0 broker=1] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:22,619] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:22,647] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 205 ms (kafka.log.Log)
[2020-04-04 18:45:22,659] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:22,663] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:45:22,665] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:22,688] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:22,704] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:22,730] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 291 ms (kafka.log.Log)
[2020-04-04 18:45:22,742] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:22,746] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:45:22,749] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:22,753] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:22,831] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:45:22,833] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:45:22,838] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:22,841] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:22,856] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:45:22,859] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:45:22,882] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:45:22,880] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:45:25,702] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 0, 1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:45:25,732] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:25,733] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:25,734] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:45:25,735] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:25,736] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:45:25,736] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:25,737] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:25,739] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:25,740] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:45:25,742] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:25,742] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:45:25,742] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:25,742] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:25,743] INFO [Partition ReportTopic-0 broker=2] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:25,744] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:45:25,746] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:25,747] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:45:25,747] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:25,747] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:25,748] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:25,748] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:45:25,750] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:45:25,750] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:45:25,783] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:45:25,792] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:25,792] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition ReportTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:45:26,798] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:45:26,801] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:45:27,889] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:45:27,917] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:27,923] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:27,924] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:45:27,923] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:27,925] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:27,925] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:27,925] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:45:27,926] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:45:27,926] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:27,926] INFO [Partition AlarmTopic-0 broker=1] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:27,927] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:45:27,927] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:27,928] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:45:27,928] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:27,928] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:27,928] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:27,929] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:27,929] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:45:27,930] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:27,930] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:27,931] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:28,145] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:45:28,146] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:45:28,156] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:45:28,157] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:45:30,957] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(2), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(2), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(2), 22 -> ArrayBuffer(2), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(2), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(2), 10 -> ArrayBuffer(2), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(2), 45 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:45:31,004] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-04-04 18:45:31,384] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:31,406] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:31,427] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,429] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:45:31,433] INFO Created log for partition __consumer_offsets-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,435] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,435] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,435] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,451] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,452] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,453] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:45:31,454] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:45:31,455] INFO Created log for partition __consumer_offsets-48 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,455] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-04-04 18:45:31,456] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,456] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,457] INFO Created log for partition __consumer_offsets-10 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,458] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-04-04 18:45:31,459] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,459] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,469] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,470] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:45:31,472] INFO Created log for partition __consumer_offsets-45 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,472] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-04-04 18:45:31,473] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,473] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,481] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,483] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:45:31,486] INFO Created log for partition __consumer_offsets-7 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,486] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-04-04 18:45:31,486] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,486] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,487] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:45:31,509] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,513] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,514] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,515] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:45:31,516] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:45:31,518] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-04-04 18:45:31,518] INFO Created log for partition __consumer_offsets-29 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,520] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-04-04 18:45:31,521] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,522] INFO Created log for partition __consumer_offsets-42 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,522] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-04-04 18:45:31,522] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,522] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,523] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,525] INFO Created log for partition __consumer_offsets-4 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,525] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-04-04 18:45:31,525] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,526] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,551] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,552] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,553] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-04-04 18:45:31,556] INFO Created log for partition __consumer_offsets-39 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,556] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-04-04 18:45:31,556] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,556] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,557] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-04-04 18:45:31,565] INFO Created log for partition __consumer_offsets-1 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,566] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-04-04 18:45:31,566] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,566] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,574] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,575] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:45:31,577] INFO Created log for partition __consumer_offsets-36 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,578] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-04-04 18:45:31,579] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,579] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,587] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,589] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:45:31,591] INFO Created log for partition __consumer_offsets-49 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,592] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-04-04 18:45:31,592] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,592] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,597] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,600] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:45:31,602] INFO Created log for partition __consumer_offsets-26 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,603] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-04-04 18:45:31,603] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,603] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,604] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,606] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:45:31,608] INFO Created log for partition __consumer_offsets-33 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,608] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-04-04 18:45:31,608] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,608] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,614] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,616] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:45:31,618] INFO Created log for partition __consumer_offsets-46 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,618] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-04-04 18:45:31,619] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,619] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,626] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,632] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,637] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-04-04 18:45:31,640] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,642] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:45:31,643] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-04-04 18:45:31,643] INFO Created log for partition __consumer_offsets-23 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,643] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-04-04 18:45:31,644] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,644] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,644] INFO Created log for partition __consumer_offsets-43 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,645] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-04-04 18:45:31,645] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,646] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,646] INFO Created log for partition __consumer_offsets-30 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,646] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-04-04 18:45:31,646] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,647] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,665] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,666] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:45:31,669] INFO Created log for partition __consumer_offsets-20 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,669] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-04-04 18:45:31,669] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,670] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,670] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,672] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,673] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:45:31,676] INFO Created log for partition __consumer_offsets-40 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,676] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-04-04 18:45:31,676] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,677] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,671] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:45:31,682] INFO Created log for partition __consumer_offsets-27 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,682] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-04-04 18:45:31,682] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,682] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,688] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,690] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:45:31,692] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,693] INFO Created log for partition __consumer_offsets-17 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,693] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-04-04 18:45:31,693] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,693] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,694] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:45:31,697] INFO Created log for partition __consumer_offsets-37 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,698] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-04-04 18:45:31,699] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,699] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,703] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,704] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:45:31,706] INFO Created log for partition __consumer_offsets-24 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,706] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-04-04 18:45:31,706] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,706] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,734] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,736] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:45:31,738] INFO Created log for partition __consumer_offsets-34 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,738] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-04-04 18:45:31,738] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,739] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,742] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,743] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-04-04 18:45:31,746] INFO Created log for partition __consumer_offsets-14 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,746] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-04-04 18:45:31,747] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,747] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,753] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,754] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:45:31,756] INFO Created log for partition __consumer_offsets-21 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,756] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-04-04 18:45:31,756] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,756] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,758] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,768] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,770] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:45:31,772] INFO Created log for partition __consumer_offsets-11 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,772] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-04-04 18:45:31,773] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,773] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,774] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-04-04 18:45:31,778] INFO Created log for partition __consumer_offsets-31 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,778] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-04-04 18:45:31,778] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,778] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,784] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,785] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:45:31,787] INFO Created log for partition __consumer_offsets-18 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,788] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-04-04 18:45:31,788] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,788] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,794] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,797] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:45:31,799] INFO Created log for partition __consumer_offsets-8 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,800] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-04-04 18:45:31,800] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,800] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,804] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,805] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:45:31,808] INFO Created log for partition __consumer_offsets-15 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,808] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-04-04 18:45:31,808] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,808] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,811] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,813] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:45:31,818] INFO Created log for partition __consumer_offsets-19 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,818] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-04-04 18:45:31,818] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,818] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,819] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,821] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:45:31,823] INFO Created log for partition __consumer_offsets-5 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,824] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-04-04 18:45:31,824] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,824] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,839] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,840] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:45:31,840] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,841] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:45:31,842] INFO Created log for partition __consumer_offsets-2 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,842] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-04-04 18:45:31,842] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,843] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,843] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,844] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:45:31,847] INFO Created log for partition __consumer_offsets-28 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,848] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-04-04 18:45:31,848] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,849] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,851] INFO Created log for partition __consumer_offsets-12 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,851] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-04-04 18:45:31,851] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,852] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,860] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,866] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:45:31,868] INFO Created log for partition __consumer_offsets-47 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,869] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-04-04 18:45:31,869] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,870] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:45:31,871] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,872] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,872] INFO Created log for partition __consumer_offsets-16 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,873] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-04-04 18:45:31,873] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,873] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,884] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,885] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:45:31,887] INFO Created log for partition __consumer_offsets-9 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,887] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-04-04 18:45:31,887] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,887] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,891] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,892] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:45:31,908] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,910] INFO Created log for partition __consumer_offsets-25 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,911] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-04-04 18:45:31,912] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,912] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-04-04 18:45:31,912] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,914] INFO Created log for partition __consumer_offsets-38 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,914] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-04-04 18:45:31,914] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,915] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,923] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,924] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:45:31,927] INFO Created log for partition __consumer_offsets-6 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,927] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-04-04 18:45:31,927] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,928] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,936] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,938] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:45:31,948] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,952] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:45:31,953] INFO Created log for partition __consumer_offsets-22 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,953] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-04-04 18:45:31,953] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,953] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,954] INFO Created log for partition __consumer_offsets-3 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,955] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-04-04 18:45:31,955] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,955] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,964] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,967] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:45:31,969] INFO Created log for partition __consumer_offsets-35 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,969] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-04-04 18:45:31,970] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,970] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:31,974] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,975] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,976] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,976] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,976] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,976] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,977] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,977] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,977] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,978] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,979] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,979] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,979] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,980] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,981] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,981] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,981] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:31,981] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:31,991] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-04-04 18:45:31,993] INFO Created log for partition __consumer_offsets-13 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:31,994] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-04-04 18:45:31,994] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:31,995] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:32,007] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 30 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,010] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,012] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,013] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,014] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,015] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,015] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,016] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,017] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,017] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,018] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,019] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,019] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,019] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,019] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,019] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,019] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,019] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,020] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,020] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,020] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,020] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,020] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,020] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,020] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,021] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,021] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,021] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,021] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,021] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,022] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,022] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,023] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,023] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,027] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:32,043] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 23 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,050] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,051] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,052] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,052] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,053] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,053] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2020-04-04 18:45:32,054] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,055] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,056] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,056] INFO Created log for partition __consumer_offsets-44 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:32,056] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-04-04 18:45:32,057] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:32,057] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:32,057] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,058] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,059] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,060] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,065] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,067] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,068] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,069] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,080] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:32,081] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:45:32,085] INFO Created log for partition __consumer_offsets-32 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:32,085] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-04-04 18:45:32,085] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:32,085] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:32,100] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:45:32,101] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:45:32,103] INFO Created log for partition __consumer_offsets-41 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:45:32,103] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-04-04 18:45:32,103] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:45:32,104] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:45:32,117] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,119] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,119] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,123] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,123] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,124] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,124] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,124] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,124] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,125] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,125] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,125] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,126] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,131] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,132] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,133] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,136] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,151] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,152] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,154] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,155] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,171] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,172] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,173] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,174] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,175] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,177] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,178] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,180] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,180] INFO [GroupCoordinator 1]: Preparing to rebalance group test in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-test-1-45c71442-2a5d-4b0a-b8b5-7037ed1b8198 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:45:32,181] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,183] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,184] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:45:32,212] INFO [GroupCoordinator 1]: Stabilized group test generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:45:32,243] INFO [GroupCoordinator 1]: Assignment received from leader for group test for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:46:42,028] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:46:42,065] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:46:42,065] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:46:42,067] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:46:42,068] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:46:42,076] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:46:42,076] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:46:42,079] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:46:42,079] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:46:42,079] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:46:42,079] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:46:42,081] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:46:42,110] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:46:42,110] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:46:42,110] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:46:42,110] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:46:42,110] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:46:42,110] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:46:42,115] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:46:42,136] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,136] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,136] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,137] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,137] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,137] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,139] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,139] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,139] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,139] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,139] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,139] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,139] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,139] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,139] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,140] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,140] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,140] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,142] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,142] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,143] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:46:42,143] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:46:42,157] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:46:42,165] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:46:42,173] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:46:42,197] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:46:42,206] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:46:42,210] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:46:42,247] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:46:42,849] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:46:42,850] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:46:42,851] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:46:42,865] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:46:42,866] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:46:42,867] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:46:42,879] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:46:42,889] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,889] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,889] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,889] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,889] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,889] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,890] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,890] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,890] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,890] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,890] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,891] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,891] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,891] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,891] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,891] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,891] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,891] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,894] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,900] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:46:42,901] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:46:42,910] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:46:42,910] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,910] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,910] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,910] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,910] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,910] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,911] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,911] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,911] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,912] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,912] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,912] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,912] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,912] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,912] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,912] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,912] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,912] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,915] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:42,922] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:46:42,928] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:46:42,939] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:42,950] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:46:42,950] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:42,956] INFO Socket connection established, initiating session, client: /127.0.0.1:34580, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:42,960] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:42,967] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:46:42,971] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:42,972] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:46:42,972] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:46:42,974] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:46:42,976] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:46:42,976] INFO Socket connection established, initiating session, client: /127.0.0.1:34582, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:42,999] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:46:42,999] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f3b7730000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:43,000] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f3b7730001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:43,004] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:46:43,004] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:46:43,006] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,006] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,006] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,006] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,006] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,006] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,008] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,008] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,008] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,009] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,009] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,009] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,009] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,009] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,009] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,009] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,009] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,009] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,012] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:46:43,017] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:46:43,024] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:46:43,048] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:43,055] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:46:43,056] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:43,061] INFO Socket connection established, initiating session, client: /127.0.0.1:34586, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:43,074] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f3b7730002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:46:43,078] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:46:43,392] INFO Cluster ID = lERMW53eQ6ecy4wDMd4FHw (kafka.server.KafkaServer)
[2020-04-04 18:46:43,404] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:46:43,468] INFO Cluster ID = lERMW53eQ6ecy4wDMd4FHw (kafka.server.KafkaServer)
[2020-04-04 18:46:43,477] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:46:43,558] INFO Cluster ID = lERMW53eQ6ecy4wDMd4FHw (kafka.server.KafkaServer)
[2020-04-04 18:46:43,566] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:46:43,578] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:46:43,617] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:46:43,646] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:46:43,679] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:46:43,697] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:46:43,697] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:46:43,699] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:46:43,729] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:46:43,757] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:46:43,757] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:46:43,760] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:46:43,765] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:46:43,767] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:46:43,782] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:46:43,806] INFO Logs loading complete in 24 ms. (kafka.log.LogManager)
[2020-04-04 18:46:43,821] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:46:43,834] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:46:43,834] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:46:43,837] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:46:43,840] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:46:43,848] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:46:43,864] INFO Logs loading complete in 23 ms. (kafka.log.LogManager)
[2020-04-04 18:46:43,864] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:46:43,905] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:46:43,908] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:46:43,919] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:46:43,925] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:46:43,947] INFO Logs loading complete in 22 ms. (kafka.log.LogManager)
[2020-04-04 18:46:43,984] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:46:43,994] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:46:45,350] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:46:45,435] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:46:45,494] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:46:45,503] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:46:45,532] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:46:45,558] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:46:45,562] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:46:45,591] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,597] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,604] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,606] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,637] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,647] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,648] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,650] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,662] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:46:45,668] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:46:45,675] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:46:45,706] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:46:45,747] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,749] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,751] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,752] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:46:45,755] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:45,784] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:46:45,807] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:46:45,812] INFO Stat of the created znode at /brokers/ids/2 is: 60,60,1586022405789,1586022405789,1,0,0,72058640792748033,174,0,60
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:46:45,814] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 60 (kafka.zk.KafkaZkClient)
[2020-04-04 18:46:45,826] INFO Stat of the created znode at /brokers/ids/1 is: 61,61,1586022405812,1586022405812,1,0,0,72058640792748032,174,0,61
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:46:45,827] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 61 (kafka.zk.KafkaZkClient)
[2020-04-04 18:46:45,935] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:46:45,992] INFO Stat of the created znode at /brokers/ids/0 is: 62,62,1586022405970,1586022405970,1,0,0,72058640792748034,174,0,62
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:46:45,994] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 62 (kafka.zk.KafkaZkClient)
[2020-04-04 18:46:46,060] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,073] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:46:46,076] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,095] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,115] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,129] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,146] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,218] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:46:46,222] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:46:46,248] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 24 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:46:46,265] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,267] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:46:46,270] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:46:46,276] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:46:46,295] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,300] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 25 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:46:46,301] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,335] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:46:46,365] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:46:46,377] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:46:46,391] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:46:46,418] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:46:46,421] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:46:46,429] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:46:46,451] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:46:46,462] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:46:46,466] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 35 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:46:46,550] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:46:46,567] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,603] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,640] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:46:46,650] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:46:46,658] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:46:46,735] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:46:46,780] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:46:46,812] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:46:46,832] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:46:46,846] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:46:46,847] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:46:46,847] INFO Kafka startTimeMs: 1586022406833 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:46:46,843] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:46:46,863] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:46:46,887] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:46:46,887] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:46:46,887] INFO Kafka startTimeMs: 1586022406856 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:46:46,904] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:46:46,921] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:46:46,995] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:46:47,020] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:46:47,020] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:46:47,020] INFO Kafka startTimeMs: 1586022406997 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:46:47,043] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:46:47,946] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:46:48,275] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:48,544] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:46:48,595] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:46:48,600] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 261 ms (kafka.log.Log)
[2020-04-04 18:46:48,605] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:46:48,609] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:46:48,616] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:46:48,618] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 153 ms (kafka.log.Log)
[2020-04-04 18:46:48,620] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:48,630] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:46:48,643] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:46:48,644] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:46:48,646] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:46:48,676] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 323 ms (kafka.log.Log)
[2020-04-04 18:46:48,685] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:46:48,688] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:46:48,691] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:46:48,695] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:48,696] INFO [Partition BatchTopic-0 broker=1] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:46:48,695] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:46:48,721] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:48,787] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:46:48,795] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:48,817] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:46:48,837] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:46:49,737] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:46:49,742] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:46:51,785] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:46:51,823] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:46:51,823] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:51,823] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:46:51,825] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:46:51,825] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:46:51,826] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:46:51,827] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:51,836] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:46:51,837] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:46:51,837] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:46:51,838] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:46:51,839] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:46:51,840] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:46:51,840] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:46:51,841] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:46:51,841] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:46:51,841] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:46:51,842] INFO [Partition ReportTopic-0 broker=0] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:46:51,842] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:51,842] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:51,842] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:46:51,847] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:46:51,848] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:46:51,889] ERROR [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error for partition ReportTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:46:51,899] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:46:51,906] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:51,911] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:46:51,916] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:46:54,104] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 2, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:46:54,136] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:54,139] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:46:54,140] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:46:54,140] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:46:54,140] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:46:54,140] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:46:54,142] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:46:54,143] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:46:54,143] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:46:54,143] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:54,144] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:54,144] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:46:54,145] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:46:54,146] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:46:54,146] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:46:54,147] INFO [Partition AlarmTopic-0 broker=1] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:46:54,152] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:46:54,153] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:46:54,153] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:46:54,154] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:54,154] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:46:54,332] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:46:54,333] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:46:54,597] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:46:54,598] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:48:32,271] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:48:32,273] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:48:32,274] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:48:32,280] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:48:32,280] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:48:32,283] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:48:32,283] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:48:32,283] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:48:32,283] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:48:32,284] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:48:32,285] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:48:32,307] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:48:32,307] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:48:32,307] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:48:32,307] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:48:32,307] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:48:32,308] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:48:32,312] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:48:32,334] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,334] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,334] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,334] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,335] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,335] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,336] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,336] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,336] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,336] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,336] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,336] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,336] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,336] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,337] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,337] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,337] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,337] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,339] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,339] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,340] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:48:32,351] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:48:32,356] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:48:32,362] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:48:32,363] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:48:32,372] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:48:32,393] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:48:32,400] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:48:32,404] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:48:32,427] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:48:32,971] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:48:32,972] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:48:32,974] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:48:33,005] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:48:33,016] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,016] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,016] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,016] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,016] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,016] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,017] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,017] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,017] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,017] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,017] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,017] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,017] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,017] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,017] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,017] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,018] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,018] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,020] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,026] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:48:33,031] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:48:33,053] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,056] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:48:33,058] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,063] INFO Socket connection established, initiating session, client: /127.0.0.1:34630, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,075] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:48:33,076] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:48:33,077] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:48:33,078] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:48:33,110] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:48:33,110] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:48:33,112] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:48:33,112] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:48:33,117] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f565e40000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,120] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,120] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,120] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,120] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,120] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,121] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:48:33,120] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,122] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,125] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,129] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:48:33,135] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:48:33,135] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:48:33,141] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,142] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,142] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,142] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,142] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,142] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,143] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,143] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,143] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,143] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,143] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,143] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,144] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,144] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,144] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,144] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,144] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,144] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,146] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:48:33,154] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:48:33,154] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,157] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:48:33,159] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,159] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:48:33,163] INFO Socket connection established, initiating session, client: /127.0.0.1:34634, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,175] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f565e40001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,179] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,179] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:48:33,181] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:48:33,184] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,188] INFO Socket connection established, initiating session, client: /127.0.0.1:34636, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,194] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f565e40002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:48:33,198] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:48:33,415] INFO Cluster ID = T9TOtRrcRGC1x-Jm8neRBA (kafka.server.KafkaServer)
[2020-04-04 18:48:33,418] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:48:33,494] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:48:33,507] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:48:33,510] INFO Cluster ID = T9TOtRrcRGC1x-Jm8neRBA (kafka.server.KafkaServer)
[2020-04-04 18:48:33,514] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:48:33,521] INFO Cluster ID = T9TOtRrcRGC1x-Jm8neRBA (kafka.server.KafkaServer)
[2020-04-04 18:48:33,525] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:48:33,536] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:48:33,536] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:48:33,537] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:48:33,569] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:48:33,577] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:48:33,586] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-04 18:48:33,588] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:48:33,595] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:48:33,600] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:48:33,606] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:48:33,612] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:48:33,616] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:48:33,632] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:48:33,635] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:48:33,637] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:48:33,641] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:48:33,641] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:48:33,642] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:48:33,664] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:48:33,669] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:48:33,670] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:48:33,678] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:48:33,679] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[2020-04-04 18:48:33,686] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[2020-04-04 18:48:33,702] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:48:33,707] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:48:33,710] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:48:33,711] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:48:34,248] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:48:34,358] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:48:34,361] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:48:34,390] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:48:34,406] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:48:34,440] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,454] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,460] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,461] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,486] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:48:34,489] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:48:34,525] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:48:34,528] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:48:34,533] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:48:34,557] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,559] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,565] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,567] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,591] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,594] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:48:34,595] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,597] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,601] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,615] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:48:34,643] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:48:34,650] INFO Stat of the created znode at /brokers/ids/2 is: 54,54,1586022514630,1586022514630,1,0,0,72058648014356480,174,0,54
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:48:34,651] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 54 (kafka.zk.KafkaZkClient)
[2020-04-04 18:48:34,756] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:48:34,757] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:48:34,795] INFO Stat of the created znode at /brokers/ids/0 is: 55,55,1586022514781,1586022514781,1,0,0,72058648014356481,174,0,55
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:48:34,798] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 55 (kafka.zk.KafkaZkClient)
[2020-04-04 18:48:34,808] INFO Stat of the created znode at /brokers/ids/1 is: 56,56,1586022514786,1586022514786,1,0,0,72058648014356482,174,0,56
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:48:34,809] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 56 (kafka.zk.KafkaZkClient)
[2020-04-04 18:48:34,854] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,895] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,905] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:34,968] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:48:35,086] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:48:35,094] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:48:35,111] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:35,118] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:35,130] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:35,132] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:35,137] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 44 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:48:35,150] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:35,151] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:35,198] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:48:35,281] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:48:35,311] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:48:35,315] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:48:35,331] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:48:35,335] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:48:35,349] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:48:35,352] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:48:35,372] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 58 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:48:35,420] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:48:35,421] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 84 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:48:35,446] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:48:35,523] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:35,566] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:48:35,573] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:48:35,583] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:48:35,597] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:48:35,633] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:48:35,636] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:48:35,679] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:48:35,689] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:35,776] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:48:35,799] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:48:35,799] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:48:35,800] INFO Kafka startTimeMs: 1586022515777 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:48:35,804] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:48:35,844] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:48:35,845] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:48:35,932] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:48:35,945] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:48:35,945] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:48:35,946] INFO Kafka startTimeMs: 1586022515934 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:48:35,955] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:48:36,003] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:48:36,053] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:48:36,063] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:48:36,063] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:48:36,064] INFO Kafka startTimeMs: 1586022516055 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:48:36,067] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:48:36,864] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:48:37,184] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:37,428] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:48:37,453] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 166 ms (kafka.log.Log)
[2020-04-04 18:48:37,458] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:48:37,461] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:48:37,463] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:48:37,466] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:37,496] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:48:37,523] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:37,531] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:48:37,551] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:48:37,571] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 263 ms (kafka.log.Log)
[2020-04-04 18:48:37,563] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:48:37,578] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:48:37,582] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:48:37,583] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:48:37,587] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:48:37,587] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:37,613] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 265 ms (kafka.log.Log)
[2020-04-04 18:48:37,620] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:48:37,622] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:48:37,624] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:48:37,626] INFO [Partition BatchTopic-0 broker=0] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:48:37,667] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:37,671] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:48:37,689] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:48:37,700] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:48:37,726] ERROR [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error for partition BatchTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:48:40,544] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:48:40,575] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:40,576] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:48:40,577] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:48:40,579] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:48:40,579] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:48:40,580] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:48:40,581] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:40,581] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:48:40,583] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:48:40,585] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:48:40,585] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:48:40,586] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:48:40,586] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:48:40,587] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:48:40,587] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:40,587] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:40,587] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:48:40,588] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:48:40,588] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:48:40,589] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:48:40,590] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:48:40,590] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:48:40,599] INFO [Partition ReportTopic-0 broker=1] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:48:40,633] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:48:40,639] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:40,642] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition ReportTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:48:40,648] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:48:40,652] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:48:42,574] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:48:42,598] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:42,601] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:48:42,601] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:48:42,601] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:48:42,603] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:48:42,603] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:48:42,603] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:48:42,603] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:48:42,603] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:48:42,603] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:48:42,604] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:42,604] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:42,604] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:48:42,605] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:48:42,605] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:48:42,605] INFO [Partition AlarmTopic-0 broker=0] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:48:42,606] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:48:42,606] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:48:42,607] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:48:42,607] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:42,608] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:48:42,814] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:48:42,815] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:48:42,893] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:48:42,894] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:51:45,554] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:51:45,556] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:51:45,557] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:51:45,565] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:51:45,565] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:51:45,575] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:51:45,576] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:51:45,576] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:51:45,576] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:51:45,578] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:51:45,606] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:51:45,606] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:51:45,607] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:51:45,607] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:51:45,607] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:51:45,607] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:51:45,613] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:51:45,631] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,631] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,631] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,631] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,631] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,631] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,633] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,633] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,633] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,633] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,633] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,633] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,633] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,633] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,634] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,634] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,634] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,634] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,634] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:51:45,636] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:51:45,640] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,641] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,643] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:51:45,654] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:51:45,660] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:51:45,672] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:51:45,710] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:51:45,717] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:51:45,722] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:51:45,747] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:51:45,773] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:51:46,329] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:51:46,330] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:51:46,331] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:51:46,356] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:51:46,362] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,363] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,363] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,363] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,363] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,363] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,364] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,364] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,364] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,364] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,364] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,364] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,364] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,364] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,364] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,364] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,365] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,365] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,368] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,373] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:51:46,378] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:51:46,397] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,398] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:51:46,399] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:51:46,400] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:51:46,408] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,411] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:51:46,412] INFO Socket connection established, initiating session, client: /127.0.0.1:34688, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,424] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:51:46,426] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:51:46,432] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,432] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,432] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,432] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,432] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,432] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,433] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,436] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,436] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f859140000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,440] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:51:46,440] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:51:46,445] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:51:46,451] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:51:46,453] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:51:46,454] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:51:46,468] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,473] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:51:46,475] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,479] INFO Socket connection established, initiating session, client: /127.0.0.1:34692, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,481] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:51:46,490] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,490] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,490] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,490] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,490] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,490] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,491] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,492] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,492] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,492] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,492] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,492] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,492] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,492] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,492] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,492] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,492] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,492] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,495] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:51:46,498] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f859140001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,501] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:51:46,502] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:51:46,509] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:51:46,531] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,534] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:51:46,537] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,541] INFO Socket connection established, initiating session, client: /127.0.0.1:34694, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,547] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000f859140002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:51:46,551] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:51:46,790] INFO Cluster ID = _8aJ3VSuTE-2aiCo19CEwg (kafka.server.KafkaServer)
[2020-04-04 18:51:46,796] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:51:46,857] INFO Cluster ID = _8aJ3VSuTE-2aiCo19CEwg (kafka.server.KafkaServer)
[2020-04-04 18:51:46,862] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:51:46,892] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:51:46,911] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:51:46,942] INFO Cluster ID = _8aJ3VSuTE-2aiCo19CEwg (kafka.server.KafkaServer)
[2020-04-04 18:51:46,945] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:51:46,946] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:51:46,946] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:51:46,950] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:51:46,952] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:51:46,961] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:51:46,989] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:51:46,996] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:51:46,996] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:51:46,997] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:51:46,998] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:51:47,009] INFO Logs loading complete in 11 ms. (kafka.log.LogManager)
[2020-04-04 18:51:47,024] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:51:47,029] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:51:47,030] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:51:47,033] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:51:47,036] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:51:47,047] INFO Logs loading complete in 14 ms. (kafka.log.LogManager)
[2020-04-04 18:51:47,048] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:51:47,066] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:51:47,070] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:51:47,083] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:51:47,083] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:51:47,087] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:51:47,117] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:51:47,126] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:51:47,135] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-04 18:51:47,160] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:51:47,168] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:51:47,651] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:51:47,725] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:51:47,727] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:51:47,729] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:51:47,759] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,760] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,767] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,771] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,773] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:51:47,776] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:51:47,810] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:51:47,815] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,819] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,819] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:51:47,820] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,821] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,837] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:51:47,839] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:51:47,864] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:51:47,866] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:51:47,869] INFO Stat of the created znode at /brokers/ids/2 is: 54,54,1586022707859,1586022707859,1,0,0,72058660684300288,174,0,54
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:51:47,870] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 54 (kafka.zk.KafkaZkClient)
[2020-04-04 18:51:47,872] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:51:47,892] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,894] INFO Stat of the created znode at /brokers/ids/0 is: 55,55,1586022707885,1586022707885,1,0,0,72058660684300289,174,0,55
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:51:47,895] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 55 (kafka.zk.KafkaZkClient)
[2020-04-04 18:51:47,895] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,896] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,896] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,932] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:51:47,951] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,956] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,958] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:47,965] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:51:47,988] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:51:47,995] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:48,006] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:48,014] INFO Stat of the created znode at /brokers/ids/1 is: 58,58,1586022708006,1586022708006,1,0,0,72058660684300290,174,0,58
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:51:48,015] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:48,015] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:51:48,015] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 58 (kafka.zk.KafkaZkClient)
[2020-04-04 18:51:48,023] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:51:48,034] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:51:48,047] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:51:48,080] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:51:48,093] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:51:48,107] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:51:48,115] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 21 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:51:48,132] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:51:48,147] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:51:48,148] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:48,151] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:51:48,156] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:48,160] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:48,166] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:51:48,168] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:51:48,171] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:51:48,194] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:48,201] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:51:48,210] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:51:48,217] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:51:48,224] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:48,239] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:51:48,270] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:51:48,304] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:51:48,304] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:51:48,324] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:51:48,328] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:51:48,345] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:51:48,346] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:51:48,347] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:51:48,351] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:51:48,351] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:51:48,351] INFO Kafka startTimeMs: 1586022708347 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:51:48,351] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:51:48,351] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:51:48,351] INFO Kafka startTimeMs: 1586022708348 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:51:48,352] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:51:48,353] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:51:48,405] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:51:48,423] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:51:48,428] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:51:48,428] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:51:48,428] INFO Kafka startTimeMs: 1586022708424 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:51:48,429] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:51:48,627] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:51:48,743] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:48,831] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:51:48,838] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2020-04-04 18:51:48,840] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:51:48,841] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:51:48,842] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:51:48,844] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:48,873] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:48,876] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:51:48,881] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:51:48,886] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:51:48,892] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:51:48,896] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 96 ms (kafka.log.Log)
[2020-04-04 18:51:48,898] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:51:48,901] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 100 ms (kafka.log.Log)
[2020-04-04 18:51:48,901] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:51:48,935] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:51:48,942] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:51:48,944] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:51:48,946] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:48,948] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:51:48,949] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:51:48,950] INFO [Partition BatchTopic-0 broker=0] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:51:48,980] ERROR [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error for partition BatchTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:51:48,994] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:51:48,997] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:49,002] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:51:49,008] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:51:51,335] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:51:51,376] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:51:51,377] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:51:51,377] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:51,379] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:51:51,380] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:51:51,380] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:51:51,381] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:51,383] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:51:51,384] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:51:51,391] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:51,391] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:51:51,392] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:51:51,392] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:51:51,393] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:51:51,395] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:51:51,395] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:51:51,397] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:51,428] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:51:51,430] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-04-04 18:51:51,432] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:51:51,433] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:51:51,433] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:51:51,434] INFO [Partition ReportTopic-0 broker=1] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:51:51,440] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition ReportTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:51:51,455] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:51:51,471] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:52,481] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:51:52,489] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:51:53,935] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:51:53,964] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:53,969] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:51:53,970] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:51:53,970] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:51:53,970] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:51:53,971] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:51:53,971] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:51:53,972] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:51:53,973] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:51:53,973] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:51:53,973] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:53,973] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:51:53,974] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:51:53,974] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:53,974] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:51:53,974] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:51:53,974] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:51:53,974] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:51:53,975] INFO [Partition AlarmTopic-0 broker=0] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:51:53,975] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:53,976] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:51:54,040] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:51:54,041] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:51:54,113] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:51:54,114] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:55:51,106] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:55:51,108] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:55:51,108] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:55:51,113] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:55:51,113] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:55:51,116] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:55:51,116] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:55:51,116] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:55:51,116] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:55:51,118] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:55:51,144] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:55:51,144] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:55:51,144] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:55:51,144] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:55:51,144] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:55:51,145] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:55:51,149] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:55:51,170] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,171] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,171] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,171] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,171] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,171] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,172] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,172] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,172] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,172] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,172] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,172] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,172] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,172] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,172] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,173] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,173] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,173] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,174] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,174] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,175] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:55:51,185] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:55:51,186] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:55:51,189] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:55:51,190] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:55:51,195] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:55:51,224] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:55:51,234] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:55:51,240] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:55:51,244] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:55:51,274] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:55:51,828] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:55:51,829] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:55:51,830] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:55:51,853] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:55:51,859] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,859] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,859] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,860] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,860] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,860] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,861] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,864] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,864] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:55:51,865] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:55:51,866] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:55:51,871] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:55:51,871] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:55:51,871] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:55:51,872] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:55:51,877] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:55:51,889] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:55:51,896] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,896] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,896] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,896] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,896] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,897] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:55:51,896] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,898] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,898] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,900] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:55:51,901] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,904] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,905] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,905] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,905] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,905] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,905] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,905] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,906] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,906] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,906] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,906] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,906] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:55:51,906] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,906] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,906] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,907] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,907] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,907] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,907] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,907] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,908] INFO Socket connection established, initiating session, client: /127.0.0.1:34784, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,910] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:55:51,913] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:55:51,915] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:55:51,921] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:55:51,922] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:55:51,934] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,936] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000fc181f0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,939] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:55:51,940] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,941] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:55:51,945] INFO Socket connection established, initiating session, client: /127.0.0.1:34786, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,945] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,948] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:55:51,951] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,958] INFO Socket connection established, initiating session, client: /127.0.0.1:34790, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,960] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000fc181f0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,965] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:55:51,967] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000fc181f0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:55:51,971] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:55:52,250] INFO Cluster ID = GV81tOWuTROCN8uucj1y7A (kafka.server.KafkaServer)
[2020-04-04 18:55:52,257] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:55:52,279] INFO Cluster ID = GV81tOWuTROCN8uucj1y7A (kafka.server.KafkaServer)
[2020-04-04 18:55:52,283] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:55:52,293] INFO Cluster ID = GV81tOWuTROCN8uucj1y7A (kafka.server.KafkaServer)
[2020-04-04 18:55:52,299] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:55:52,335] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:55:52,350] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:55:52,366] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:55:52,378] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:55:52,379] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:55:52,380] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:55:52,380] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:55:52,388] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:55:52,401] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:55:52,416] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:55:52,416] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:55:52,417] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:55:52,417] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:55:52,426] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:55:52,429] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:55:52,429] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:55:52,430] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:55:52,436] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-04 18:55:52,447] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:55:52,454] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:55:52,456] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:55:52,458] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:55:52,464] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:55:52,465] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-04 18:55:52,467] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:55:52,478] INFO Logs loading complete in 11 ms. (kafka.log.LogManager)
[2020-04-04 18:55:52,483] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:55:52,489] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:55:52,500] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:55:52,507] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:55:52,931] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:55:52,986] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:55:52,988] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:55:53,021] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:55:53,023] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:55:53,024] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,027] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,030] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,032] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,064] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:55:53,066] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:55:53,067] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:55:53,069] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:55:53,069] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:55:53,098] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:55:53,103] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,103] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,104] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,104] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,105] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,105] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,106] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,106] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,127] INFO Stat of the created znode at /brokers/ids/1 is: 56,56,1586022953117,1586022953117,1,0,0,72058676774371330,174,0,56
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:55:53,128] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 56 (kafka.zk.KafkaZkClient)
[2020-04-04 18:55:53,133] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:55:53,136] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:55:53,197] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:55:53,197] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:55:53,218] INFO Stat of the created znode at /brokers/ids/2 is: 57,57,1586022953208,1586022953208,1,0,0,72058676774371329,174,0,57
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:55:53,219] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 57 (kafka.zk.KafkaZkClient)
[2020-04-04 18:55:53,221] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,225] INFO Stat of the created znode at /brokers/ids/0 is: 58,58,1586022953210,1586022953210,1,0,0,72058676774371328,174,0,58
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:55:53,226] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 58 (kafka.zk.KafkaZkClient)
[2020-04-04 18:55:53,229] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,229] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,248] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:55:53,308] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:55:53,323] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:55:53,334] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:55:53,355] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:55:53,389] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,412] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,418] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:55:53,423] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,440] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:55:53,441] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:55:53,454] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,459] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,463] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,530] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:55:53,536] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,556] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:55:53,568] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:55:53,572] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 17 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:55:53,579] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:55:53,604] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:55:53,620] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 39 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:55:53,633] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:55:53,661] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:55:53,729] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:55:53,733] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:55:53,736] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:55:53,740] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:55:53,742] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:55:53,751] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:55:53,752] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:55:53,766] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:55:53,766] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:55:53,766] INFO Kafka startTimeMs: 1586022953737 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:55:53,770] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:55:53,884] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:53,889] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:55:54,020] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:55:54,055] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:55:54,102] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:55:54,110] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:55:54,112] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:55:54,113] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:55:54,113] INFO Kafka startTimeMs: 1586022954103 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:55:54,117] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:55:54,130] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:55:54,131] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:55:54,131] INFO Kafka startTimeMs: 1586022954111 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:55:54,136] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:55:54,973] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:55:55,286] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:55:55,524] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:55:55,551] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 154 ms (kafka.log.Log)
[2020-04-04 18:55:55,557] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:55:55,563] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:55:55,565] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:55:55,569] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:55:55,654] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:55:55,664] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:55:55,672] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:55:55,691] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:55:55,717] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:55:55,718] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 257 ms (kafka.log.Log)
[2020-04-04 18:55:55,753] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:55:55,750] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:55:55,759] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:55:55,762] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:55:55,765] INFO [Partition BatchTopic-0 broker=0] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:55:55,785] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 324 ms (kafka.log.Log)
[2020-04-04 18:55:55,798] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:55:55,802] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:55:55,804] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:55:55,816] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:55:55,981] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:55:55,992] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:55:55,990] ERROR [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error for partition BatchTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:55:56,051] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:55:56,064] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:55:58,732] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 2, 1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:55:58,759] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:55:58,767] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:55:58,767] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:55:58,767] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:55:58,768] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:55:58,768] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:55:58,768] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:55:58,769] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:55:58,769] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:55:58,770] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:55:58,770] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:55:58,770] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:55:58,770] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:55:58,771] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:55:58,771] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:55:58,771] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:55:58,771] INFO [Partition ReportTopic-0 broker=0] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:55:58,771] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:55:58,772] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:55:58,772] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:55:58,773] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:55:59,104] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:55:59,105] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:55:59,230] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:55:59,231] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:56:00,700] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:56:00,732] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:56:00,735] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:00,735] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:56:00,737] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:00,737] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:56:00,737] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:00,737] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:00,738] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:56:00,738] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:56:00,739] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:00,739] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:00,739] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:56:00,739] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:00,740] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:56:00,740] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:56:00,741] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:00,742] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:56:00,742] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:00,743] INFO [Partition AlarmTopic-0 broker=1] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:00,745] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:56:00,745] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:56:00,746] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:56:00,746] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:56:00,774] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition AlarmTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:56:00,779] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:56:00,797] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:56:00,807] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:56:00,811] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:56:04,032] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(1), 32 -> ArrayBuffer(1), 41 -> ArrayBuffer(1), 17 -> ArrayBuffer(1), 8 -> ArrayBuffer(1), 35 -> ArrayBuffer(1), 44 -> ArrayBuffer(1), 26 -> ArrayBuffer(1), 11 -> ArrayBuffer(1), 29 -> ArrayBuffer(1), 38 -> ArrayBuffer(1), 47 -> ArrayBuffer(1), 20 -> ArrayBuffer(1), 2 -> ArrayBuffer(1), 5 -> ArrayBuffer(1), 14 -> ArrayBuffer(1), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(2), 27 -> ArrayBuffer(2), 36 -> ArrayBuffer(2), 18 -> ArrayBuffer(2), 9 -> ArrayBuffer(2), 21 -> ArrayBuffer(2), 48 -> ArrayBuffer(2), 3 -> ArrayBuffer(2), 12 -> ArrayBuffer(2), 30 -> ArrayBuffer(2), 39 -> ArrayBuffer(2), 15 -> ArrayBuffer(2), 42 -> ArrayBuffer(2), 24 -> ArrayBuffer(2), 6 -> ArrayBuffer(2), 33 -> ArrayBuffer(2), 0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:56:04,071] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-04-04 18:56:04,492] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:56:04,496] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:56:04,509] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,512] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:56:04,515] INFO Created log for partition __consumer_offsets-29 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,517] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-04-04 18:56:04,517] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,517] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,510] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:56:04,524] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,534] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,539] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-04-04 18:56:04,540] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:56:04,541] INFO Created log for partition __consumer_offsets-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,542] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,543] INFO Created log for partition __consumer_offsets-26 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,543] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-04-04 18:56:04,543] INFO [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,545] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,545] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,546] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:56:04,548] INFO Created log for partition __consumer_offsets-10 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,550] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-04-04 18:56:04,550] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,551] INFO [Partition __consumer_offsets-0 broker=2] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,550] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,560] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,562] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:56:04,562] INFO [Partition __consumer_offsets-0 broker=2] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,564] INFO Created log for partition __consumer_offsets-23 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,564] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-04-04 18:56:04,564] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,564] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,570] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,572] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:56:04,575] INFO Created log for partition __consumer_offsets-7 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,575] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-04-04 18:56:04,576] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,576] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,580] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,581] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:56:04,583] INFO Created log for partition __consumer_offsets-20 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,583] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-04-04 18:56:04,583] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,583] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,591] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,593] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:56:04,595] INFO Created log for partition __consumer_offsets-4 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,595] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-04-04 18:56:04,595] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,595] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,612] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,615] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:56:04,618] INFO Created log for partition __consumer_offsets-17 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,618] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-04-04 18:56:04,618] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,618] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,621] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,623] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-04-04 18:56:04,626] INFO Created log for partition __consumer_offsets-1 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,627] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-04-04 18:56:04,627] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,629] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,638] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,639] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,640] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:56:04,641] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-04-04 18:56:04,643] INFO Created log for partition __consumer_offsets-48 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,644] INFO [Partition __consumer_offsets-48 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-04-04 18:56:04,644] INFO [Partition __consumer_offsets-48 broker=2] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,644] INFO [Partition __consumer_offsets-48 broker=2] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,644] INFO Created log for partition __consumer_offsets-14 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,645] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-04-04 18:56:04,645] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,645] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,654] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,656] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:56:04,659] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,659] INFO Created log for partition __consumer_offsets-49 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,660] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-04-04 18:56:04,661] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:56:04,660] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,661] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,678] INFO Created log for partition __consumer_offsets-11 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,678] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-04-04 18:56:04,678] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,678] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,681] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,684] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:56:04,689] INFO Created log for partition __consumer_offsets-45 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,690] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,690] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-04-04 18:56:04,690] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,690] INFO [Partition __consumer_offsets-45 broker=2] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,692] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:56:04,694] INFO Created log for partition __consumer_offsets-46 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,694] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-04-04 18:56:04,694] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,695] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,704] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,706] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:56:04,708] INFO Created log for partition __consumer_offsets-42 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,708] INFO [Partition __consumer_offsets-42 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-04-04 18:56:04,709] INFO [Partition __consumer_offsets-42 broker=2] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,709] INFO [Partition __consumer_offsets-42 broker=2] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,713] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,715] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:56:04,718] INFO Created log for partition __consumer_offsets-43 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,718] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-04-04 18:56:04,718] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,719] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,721] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,722] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:56:04,729] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,731] INFO Created log for partition __consumer_offsets-8 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,732] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-04-04 18:56:04,732] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,732] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,736] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,737] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-04-04 18:56:04,740] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:56:04,743] INFO Created log for partition __consumer_offsets-40 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,743] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-04-04 18:56:04,743] INFO Created log for partition __consumer_offsets-39 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,744] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,744] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-04-04 18:56:04,744] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,744] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,744] INFO [Partition __consumer_offsets-39 broker=2] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,770] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,771] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:56:04,773] INFO Created log for partition __consumer_offsets-37 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,774] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-04-04 18:56:04,774] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,774] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,774] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,775] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:56:04,781] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,784] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:56:04,785] INFO Created log for partition __consumer_offsets-36 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,785] INFO [Partition __consumer_offsets-36 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-04-04 18:56:04,786] INFO [Partition __consumer_offsets-36 broker=2] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,786] INFO [Partition __consumer_offsets-36 broker=2] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,791] INFO Created log for partition __consumer_offsets-5 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,791] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-04-04 18:56:04,791] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,791] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,796] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,798] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:56:04,806] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,807] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:56:04,809] INFO Created log for partition __consumer_offsets-33 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,810] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-04-04 18:56:04,810] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,810] INFO [Partition __consumer_offsets-33 broker=2] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,813] INFO Created log for partition __consumer_offsets-34 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,814] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-04-04 18:56:04,814] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,814] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,822] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,824] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:56:04,826] INFO Created log for partition __consumer_offsets-2 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,826] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-04-04 18:56:04,826] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,827] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,829] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,830] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:56:04,832] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,833] INFO Created log for partition __consumer_offsets-30 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,833] INFO [Partition __consumer_offsets-30 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-04-04 18:56:04,834] INFO [Partition __consumer_offsets-30 broker=2] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,834] INFO [Partition __consumer_offsets-30 broker=2] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,843] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-04-04 18:56:04,845] INFO Created log for partition __consumer_offsets-31 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,846] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-04-04 18:56:04,846] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,846] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,857] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,858] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:56:04,859] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,861] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:56:04,863] INFO Created log for partition __consumer_offsets-47 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,863] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-04-04 18:56:04,863] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,863] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,863] INFO Created log for partition __consumer_offsets-27 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,880] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,880] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,881] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:56:04,883] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-04-04 18:56:04,883] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,883] INFO [Partition __consumer_offsets-27 broker=2] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,884] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:56:04,887] INFO Created log for partition __consumer_offsets-19 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,889] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-04-04 18:56:04,890] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,890] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,893] INFO Created log for partition __consumer_offsets-38 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,895] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-04-04 18:56:04,895] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,895] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,907] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,908] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:56:04,911] INFO Created log for partition __consumer_offsets-24 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,911] INFO [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-04-04 18:56:04,911] INFO [Partition __consumer_offsets-24 broker=2] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,911] INFO [Partition __consumer_offsets-24 broker=2] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,918] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,920] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-04-04 18:56:04,922] INFO Created log for partition __consumer_offsets-28 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,922] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-04-04 18:56:04,923] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,923] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,923] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,924] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:56:04,925] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,926] INFO Created log for partition __consumer_offsets-35 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,926] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-04-04 18:56:04,926] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,926] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,927] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:56:04,929] INFO Created log for partition __consumer_offsets-21 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,930] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-04-04 18:56:04,930] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,930] INFO [Partition __consumer_offsets-21 broker=2] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,940] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,942] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:56:04,945] INFO Created log for partition __consumer_offsets-44 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,945] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-04-04 18:56:04,945] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,945] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,948] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,950] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:56:04,954] INFO Created log for partition __consumer_offsets-16 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,955] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-04-04 18:56:04,955] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,955] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,965] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,967] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:56:04,970] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,972] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-04-04 18:56:04,974] INFO Created log for partition __consumer_offsets-18 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,975] INFO [Partition __consumer_offsets-18 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-04-04 18:56:04,975] INFO [Partition __consumer_offsets-18 broker=2] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,975] INFO [Partition __consumer_offsets-18 broker=2] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,979] INFO Created log for partition __consumer_offsets-32 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,981] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:04,982] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:56:04,985] INFO Created log for partition __consumer_offsets-25 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:04,985] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-04-04 18:56:04,986] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,986] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:04,979] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-04-04 18:56:04,993] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:04,993] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:05,002] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:05,005] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:56:05,006] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:05,008] INFO Created log for partition __consumer_offsets-15 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:05,008] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:56:05,008] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-04-04 18:56:05,009] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:05,009] INFO [Partition __consumer_offsets-15 broker=2] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:05,015] INFO Created log for partition __consumer_offsets-22 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:05,015] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-04-04 18:56:05,016] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:05,016] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:05,025] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:05,026] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:56:05,028] INFO Created log for partition __consumer_offsets-41 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:05,028] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-04-04 18:56:05,028] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:05,028] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:05,036] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:05,038] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:56:05,038] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:05,039] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:56:05,041] INFO Created log for partition __consumer_offsets-12 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:05,041] INFO [Partition __consumer_offsets-12 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-04-04 18:56:05,041] INFO [Partition __consumer_offsets-12 broker=2] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:05,041] INFO [Partition __consumer_offsets-12 broker=2] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:05,041] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,041] INFO Created log for partition __consumer_offsets-13 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:05,042] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-04-04 18:56:05,042] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:05,042] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:05,043] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,043] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,043] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,043] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,043] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,055] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:05,057] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:56:05,059] INFO Created log for partition __consumer_offsets-9 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:05,060] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-04-04 18:56:05,060] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:05,059] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,060] INFO [Partition __consumer_offsets-9 broker=2] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:05,062] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,062] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,063] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,064] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,064] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,064] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,067] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,068] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,068] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,068] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,069] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,069] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,069] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,069] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,070] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,070] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,070] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,070] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,071] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,071] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,072] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,072] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,073] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,074] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,077] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,073] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:05,078] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,079] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:56:05,079] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,081] INFO Created log for partition __consumer_offsets-6 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:05,081] INFO [Partition __consumer_offsets-6 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-04-04 18:56:05,081] INFO [Partition __consumer_offsets-6 broker=2] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:05,081] INFO [Partition __consumer_offsets-6 broker=2] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:05,083] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,083] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,092] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,094] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,095] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,095] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,096] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,096] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,097] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,099] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,100] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,101] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,103] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,104] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,105] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,107] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,109] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:56:05,111] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:56:05,112] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,113] INFO Created log for partition __consumer_offsets-3 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:56:05,113] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-04-04 18:56:05,113] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:56:05,113] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,114] INFO [Partition __consumer_offsets-3 broker=2] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:56:05,115] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,116] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,118] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,119] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,130] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,131] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,132] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,132] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,132] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,132] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,132] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,133] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,133] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,133] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,133] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,134] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,134] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,135] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,136] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,136] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,136] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,162] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 30 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,165] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,167] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,168] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,170] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,171] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,172] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,172] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,173] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,175] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,176] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,177] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,178] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,196] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,198] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,199] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,202] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-48 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:56:05,320] INFO [GroupCoordinator 2]: Preparing to rebalance group test in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-test-1-465fb8b9-fd43-4955-a791-78197660bb34 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:56:05,350] INFO [GroupCoordinator 2]: Stabilized group test generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:56:05,377] INFO [GroupCoordinator 2]: Assignment received from leader for group test for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:57:21,547] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:57:21,551] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:57:21,552] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:57:21,560] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:57:21,560] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:57:21,564] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:57:21,564] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:57:21,564] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:57:21,564] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:57:21,566] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:57:21,608] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:57:21,608] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:57:21,608] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:57:21,609] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:57:21,609] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:57:21,609] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:57:21,614] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:57:21,634] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:57:21,635] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,635] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,636] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,636] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,636] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,636] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,637] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,637] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,637] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,637] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,638] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,638] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,638] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,638] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,638] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,638] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,638] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,638] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,642] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,642] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,642] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:57:21,655] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:57:21,663] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:57:21,668] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:57:21,669] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:57:21,691] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:57:21,695] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:57:21,701] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:57:21,706] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:57:21,739] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:57:22,324] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:57:22,326] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:57:22,327] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:57:22,350] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:57:22,357] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,358] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,358] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,358] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,358] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,358] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,359] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,362] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,366] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:57:22,371] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:57:22,401] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,409] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:57:22,413] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,416] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:57:22,417] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:57:22,418] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:57:22,418] INFO Socket connection established, initiating session, client: /127.0.0.1:34842, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,433] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:57:22,444] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:57:22,445] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000fd797c0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,449] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:57:22,451] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,451] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,451] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,451] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,451] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,452] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,453] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:57:22,453] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,453] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,453] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,453] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,453] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,453] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,453] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,453] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,453] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:57:22,453] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,453] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,454] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,454] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,454] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:57:22,457] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,464] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:57:22,471] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:57:22,474] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:57:22,487] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,487] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,487] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,487] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,487] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,487] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,488] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,491] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,491] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:57:22,495] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:57:22,498] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:57:22,499] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,504] INFO Socket connection established, initiating session, client: /127.0.0.1:34844, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,504] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:57:22,523] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000fd797c0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,524] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,528] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:57:22,529] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:57:22,530] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,534] INFO Socket connection established, initiating session, client: /127.0.0.1:34848, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,545] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000fd797c0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:57:22,549] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:57:22,790] INFO Cluster ID = 6KbTii8WS0qchQP5CUHKdQ (kafka.server.KafkaServer)
[2020-04-04 18:57:22,793] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:57:22,859] INFO Cluster ID = 6KbTii8WS0qchQP5CUHKdQ (kafka.server.KafkaServer)
[2020-04-04 18:57:22,859] INFO Cluster ID = 6KbTii8WS0qchQP5CUHKdQ (kafka.server.KafkaServer)
[2020-04-04 18:57:22,863] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:57:22,863] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:57:22,870] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:57:22,881] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:57:22,915] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:57:22,915] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:57:22,916] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:57:22,946] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:57:22,947] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:57:22,952] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:57:22,954] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:57:22,965] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:57:22,968] INFO Logs loading complete in 14 ms. (kafka.log.LogManager)
[2020-04-04 18:57:22,981] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:57:22,992] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:57:22,997] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:57:23,004] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:57:23,004] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:57:23,007] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:57:23,017] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:57:23,019] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:57:23,023] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:57:23,040] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:57:23,047] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:57:23,050] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:57:23,058] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-04 18:57:23,059] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:57:23,068] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-04 18:57:23,077] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:57:23,082] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:57:23,093] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:57:23,104] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:57:23,598] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:57:23,678] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:57:23,679] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:57:23,719] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,719] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,723] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,724] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,786] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:57:23,791] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:57:23,796] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:57:23,834] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:57:23,836] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:57:23,839] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:57:23,846] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:57:23,848] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:57:23,862] INFO Stat of the created znode at /brokers/ids/0 is: 54,54,1586023043853,1586023043853,1,0,0,72058682702823424,174,0,54
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:57:23,863] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 54 (kafka.zk.KafkaZkClient)
[2020-04-04 18:57:23,865] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,865] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,867] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,868] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,875] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,879] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,881] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,883] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,899] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:57:23,904] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:57:23,951] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:57:23,953] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,953] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,956] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:23,960] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:57:23,970] INFO Stat of the created znode at /brokers/ids/1 is: 55,55,1586023043961,1586023043961,1,0,0,72058682702823426,174,0,55
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:57:23,971] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 55 (kafka.zk.KafkaZkClient)
[2020-04-04 18:57:23,976] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:57:23,983] INFO Stat of the created znode at /brokers/ids/2 is: 56,56,1586023043972,1586023043972,1,0,0,72058682702823425,174,0,56
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:57:23,984] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 56 (kafka.zk.KafkaZkClient)
[2020-04-04 18:57:24,006] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:57:24,015] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:57:24,025] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:24,036] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:57:24,071] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:24,074] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:24,081] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:57:24,083] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:24,089] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:57:24,093] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:24,099] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:57:24,101] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:24,108] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:24,116] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:57:24,117] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:57:24,138] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:24,144] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:57:24,145] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 24 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:24,173] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:57:24,180] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:57:24,181] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:57:24,185] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:57:24,187] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:57:24,188] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:24,213] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:57:24,233] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:24,249] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:57:24,255] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:57:24,255] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:57:24,265] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:57:24,293] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:57:24,294] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:57:24,299] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:57:24,299] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:57:24,299] INFO Kafka startTimeMs: 1586023044294 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:57:24,301] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:57:24,306] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:57:24,340] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:57:24,345] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:57:24,345] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:57:24,345] INFO Kafka startTimeMs: 1586023044341 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:57:24,346] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:57:24,380] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:57:24,402] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:57:24,406] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:57:24,406] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:57:24,407] INFO Kafka startTimeMs: 1586023044403 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:57:24,408] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:57:24,624] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 1, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:57:24,734] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:24,824] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:24,831] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2020-04-04 18:57:24,834] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:24,835] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:57:24,836] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:24,838] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:24,860] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:24,867] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:24,873] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:57:24,880] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:24,899] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 106 ms (kafka.log.Log)
[2020-04-04 18:57:24,903] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:24,906] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:57:24,910] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:24,915] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:24,958] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 164 ms (kafka.log.Log)
[2020-04-04 18:57:24,975] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:24,978] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:57:24,978] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:57:24,979] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:24,982] INFO [Partition BatchTopic-0 broker=2] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:24,986] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:25,891] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:57:25,898] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:57:25,997] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:57:26,002] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:57:27,900] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:57:27,932] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:27,932] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:27,932] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:57:27,934] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:27,935] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:57:27,936] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:27,937] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:27,939] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:27,940] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:57:27,941] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:27,942] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:57:27,942] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:27,943] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:27,943] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:57:27,943] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:27,943] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:57:27,944] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:27,944] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:57:27,944] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:27,944] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:57:27,945] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:57:27,945] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:27,946] INFO [Partition ReportTopic-0 broker=1] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:27,981] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition ReportTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:57:27,988] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:57:27,996] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:28,003] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:57:28,009] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:57:30,189] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 0, 1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:57:30,225] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:30,230] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:30,229] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:30,230] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:57:30,230] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:57:30,231] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:30,231] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:57:30,231] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:30,232] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:30,233] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:57:30,233] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:30,234] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:30,234] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:57:30,234] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:30,234] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:30,235] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:57:30,235] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:30,235] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:30,235] INFO [Partition AlarmTopic-0 broker=2] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:30,235] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:30,236] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:30,585] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:57:30,586] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:57:30,606] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:57:30,607] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:57:33,157] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(2), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(2), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(2), 22 -> ArrayBuffer(2), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(2), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(2), 10 -> ArrayBuffer(2), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(2), 45 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:57:33,174] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-04-04 18:57:33,498] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:33,503] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:33,511] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,513] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:57:33,512] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:57:33,522] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,524] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:57:33,523] INFO Created log for partition __consumer_offsets-10 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,527] INFO Created log for partition __consumer_offsets-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,528] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-04-04 18:57:33,528] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,529] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,529] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,530] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,530] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,548] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,546] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,549] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:57:33,550] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:57:33,552] INFO Created log for partition __consumer_offsets-48 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,552] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-04-04 18:57:33,552] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,552] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,553] INFO Created log for partition __consumer_offsets-29 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,554] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-04-04 18:57:33,554] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,556] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,563] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,564] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:57:33,567] INFO Created log for partition __consumer_offsets-7 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,570] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-04-04 18:57:33,571] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,571] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,577] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,579] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:57:33,581] INFO Created log for partition __consumer_offsets-45 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,581] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-04-04 18:57:33,581] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,582] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,600] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,606] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:57:33,609] INFO Created log for partition __consumer_offsets-26 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,610] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-04-04 18:57:33,610] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,610] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,611] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,611] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,612] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:57:33,612] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-04-04 18:57:33,614] INFO Created log for partition __consumer_offsets-42 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,614] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-04-04 18:57:33,614] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,614] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,614] INFO Created log for partition __consumer_offsets-4 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,615] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-04-04 18:57:33,616] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,616] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,625] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,633] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,633] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,634] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:57:33,634] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:57:33,637] INFO Created log for partition __consumer_offsets-39 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,637] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-04-04 18:57:33,637] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,638] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,639] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-04-04 18:57:33,642] INFO Created log for partition __consumer_offsets-23 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,642] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-04-04 18:57:33,642] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,642] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,648] INFO Created log for partition __consumer_offsets-1 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,648] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-04-04 18:57:33,648] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,648] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,662] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,663] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:57:33,666] INFO Created log for partition __consumer_offsets-20 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,667] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-04-04 18:57:33,667] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,667] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,667] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,669] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:57:33,671] INFO Created log for partition __consumer_offsets-36 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,671] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-04-04 18:57:33,672] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,672] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,676] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,678] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:57:33,679] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,680] INFO Created log for partition __consumer_offsets-49 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,680] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:57:33,680] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-04-04 18:57:33,680] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,680] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,682] INFO Created log for partition __consumer_offsets-17 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,682] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-04-04 18:57:33,682] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,682] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,688] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,689] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:57:33,691] INFO Created log for partition __consumer_offsets-33 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,692] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-04-04 18:57:33,692] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,692] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,702] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,703] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:57:33,706] INFO Created log for partition __consumer_offsets-14 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,706] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-04-04 18:57:33,706] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,706] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,708] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,709] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:57:33,711] INFO Created log for partition __consumer_offsets-46 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,711] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-04-04 18:57:33,712] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,712] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,715] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,717] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:57:33,720] INFO Created log for partition __consumer_offsets-30 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,720] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-04-04 18:57:33,721] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,721] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,729] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,729] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,731] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:57:33,732] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:57:33,735] INFO Created log for partition __consumer_offsets-11 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,735] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-04-04 18:57:33,735] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,736] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,736] INFO Created log for partition __consumer_offsets-43 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,736] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-04-04 18:57:33,737] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,737] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,740] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,741] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:57:33,743] INFO Created log for partition __consumer_offsets-27 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,743] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-04-04 18:57:33,743] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,744] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,762] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,764] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-04-04 18:57:33,766] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,766] INFO Created log for partition __consumer_offsets-8 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,767] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-04-04 18:57:33,767] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,767] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:57:33,770] INFO Created log for partition __consumer_offsets-24 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,770] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-04-04 18:57:33,770] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,770] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,771] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,772] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,775] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:57:33,779] INFO Created log for partition __consumer_offsets-40 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,780] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-04-04 18:57:33,780] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,783] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,795] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,801] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:57:33,802] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,803] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:57:33,806] INFO Created log for partition __consumer_offsets-5 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,806] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-04-04 18:57:33,806] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,806] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,812] INFO Created log for partition __consumer_offsets-21 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,812] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-04-04 18:57:33,813] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,813] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,823] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,825] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:57:33,828] INFO Created log for partition __consumer_offsets-37 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,829] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-04-04 18:57:33,829] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,829] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,837] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,838] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:57:33,838] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,840] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:57:33,840] INFO Created log for partition __consumer_offsets-2 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,841] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-04-04 18:57:33,841] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,841] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,842] INFO Created log for partition __consumer_offsets-18 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,842] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-04-04 18:57:33,842] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,843] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,850] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,852] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:57:33,854] INFO Created log for partition __consumer_offsets-34 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,855] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-04-04 18:57:33,855] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,855] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,858] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,859] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:57:33,862] INFO Created log for partition __consumer_offsets-47 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,862] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-04-04 18:57:33,862] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,863] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,871] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,872] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:57:33,872] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,874] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:57:33,874] INFO Created log for partition __consumer_offsets-15 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,875] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-04-04 18:57:33,875] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,875] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,876] INFO Created log for partition __consumer_offsets-31 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,876] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-04-04 18:57:33,876] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,876] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,885] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,887] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:57:33,889] INFO Created log for partition __consumer_offsets-38 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,890] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-04-04 18:57:33,890] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,890] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,895] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,896] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:57:33,898] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,899] INFO Created log for partition __consumer_offsets-12 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,899] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-04-04 18:57:33,899] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:57:33,899] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,900] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,902] INFO Created log for partition __consumer_offsets-19 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,902] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-04-04 18:57:33,902] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,902] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,906] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,908] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:57:33,910] INFO Created log for partition __consumer_offsets-35 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,911] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-04-04 18:57:33,911] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,911] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,914] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,920] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:57:33,922] INFO Created log for partition __consumer_offsets-9 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,922] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-04-04 18:57:33,922] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,922] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,925] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,927] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:57:33,929] INFO Created log for partition __consumer_offsets-28 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,929] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-04-04 18:57:33,929] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,929] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,934] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,935] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:57:33,936] INFO Created log for partition __consumer_offsets-44 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,937] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-04-04 18:57:33,937] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,937] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,938] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,939] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:57:33,941] INFO Created log for partition __consumer_offsets-6 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,941] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-04-04 18:57:33,942] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,942] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,945] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,946] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:57:33,948] INFO Created log for partition __consumer_offsets-16 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,948] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-04-04 18:57:33,949] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,949] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,953] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,954] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:57:33,954] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,955] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:57:33,956] INFO Created log for partition __consumer_offsets-3 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,957] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-04-04 18:57:33,957] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,957] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,957] INFO Created log for partition __consumer_offsets-32 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,957] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-04-04 18:57:33,958] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,958] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,962] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,963] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-04 18:57:33,965] INFO Created log for partition __consumer_offsets-25 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,965] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-04-04 18:57:33,965] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,965] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,969] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,971] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,971] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,971] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,971] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,972] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,972] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,972] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,972] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,972] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:57:33,973] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,973] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,973] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,973] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,974] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,974] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,975] INFO Created log for partition __consumer_offsets-41 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:33,975] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,975] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-04-04 18:57:33,975] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:33,975] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,975] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:33,975] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:33,998] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:33,987] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,000] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:57:34,002] INFO Created log for partition __consumer_offsets-22 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:34,002] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-04-04 18:57:34,002] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,003] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:34,003] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:34,005] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,006] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,007] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,008] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,009] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,009] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,011] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,011] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,011] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,011] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,011] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,015] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,015] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,016] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,017] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,018] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,019] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:57:34,021] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,021] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:57:34,022] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,022] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,023] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,024] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,024] INFO Created log for partition __consumer_offsets-13 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:57:34,025] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-04-04 18:57:34,025] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:57:34,025] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:57:34,025] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,026] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,026] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,027] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,027] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,029] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,031] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,031] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,032] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,033] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,033] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,034] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,036] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,037] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,037] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,038] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,038] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,040] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,042] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,043] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,046] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,050] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,050] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,050] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,051] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,051] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,051] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,051] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,052] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,052] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,052] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,052] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,052] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,053] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,054] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,054] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,054] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,065] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,068] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,069] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,070] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,071] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,072] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,073] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,074] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,075] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,076] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,078] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,078] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,079] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,080] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,082] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,083] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,084] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:57:34,148] INFO [GroupCoordinator 1]: Preparing to rebalance group test in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-test-1-2ce050bd-71f9-4b70-911e-a94701bb8304 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:57:34,172] INFO [GroupCoordinator 1]: Stabilized group test generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:57:34,197] INFO [GroupCoordinator 1]: Assignment received from leader for group test for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:59:24,865] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:59:24,875] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:59:24,877] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:59:24,877] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:59:24,884] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:59:24,884] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:59:24,887] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:59:24,887] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:59:24,887] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-04 18:59:24,887] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-04 18:59:24,889] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-04 18:59:24,899] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:59:24,902] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-04 18:59:24,909] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:59:24,909] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:59:24,909] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:59:24,910] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:59:24,910] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-04 18:59:24,910] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-04 18:59:24,914] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:59:24,933] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,933] INFO Server environment:host.name=pc (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,933] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,933] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,933] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,933] INFO Server environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,934] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,934] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,934] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,935] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,935] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,935] INFO Server environment:os.version=4.15.0-20-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,935] INFO Server environment:user.name=joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,935] INFO Server environment:user.home=/home/joaoalegria (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,935] INFO Server environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,935] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,935] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,935] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,937] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,937] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,938] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-04 18:59:24,947] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-04 18:59:24,950] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:59:24,955] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-04 18:59:24,976] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-04 18:59:24,982] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:59:24,986] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-04 18:59:25,009] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-04 18:59:25,572] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:59:25,575] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:59:25,577] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:59:25,580] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:59:25,581] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-04 18:59:25,581] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:59:25,582] INFO starting (kafka.server.KafkaServer)
[2020-04-04 18:59:25,583] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:59:25,583] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-04 18:59:25,602] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:59:25,609] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,609] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,609] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,610] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,610] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,610] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,611] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,612] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:59:25,615] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:59:25,615] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,618] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,619] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,619] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,619] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,619] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,619] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,620] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:59:25,621] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,621] INFO Client environment:host.name=pc (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,621] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,621] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,621] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,621] INFO Client environment:java.class.path=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:os.version=4.15.0-20-generic (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:user.name=joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:user.home=/home/joaoalegria (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:user.dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,622] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,623] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,625] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7722c3c3 (org.apache.zookeeper.ZooKeeper)
[2020-04-04 18:59:25,626] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:59:25,628] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:59:25,630] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-04 18:59:25,634] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:59:25,637] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-04 18:59:25,652] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,655] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:59:25,655] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,659] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,660] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:59:25,660] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,663] INFO Socket connection established, initiating session, client: /127.0.0.1:34904, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,664] INFO Socket connection established, initiating session, client: /127.0.0.1:34908, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,669] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,672] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:59:25,675] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-04 18:59:25,676] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,679] INFO Socket connection established, initiating session, client: /127.0.0.1:34910, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,690] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000ff5b0a0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,692] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000ff5b0a0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,692] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000ff5b0a0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-04 18:59:25,694] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:59:25,696] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:59:25,696] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-04 18:59:25,993] INFO Cluster ID = 8fA1w6bSSCa7NH99PebQAw (kafka.server.KafkaServer)
[2020-04-04 18:59:25,997] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:59:26,033] INFO Cluster ID = 8fA1w6bSSCa7NH99PebQAw (kafka.server.KafkaServer)
[2020-04-04 18:59:26,035] INFO Cluster ID = 8fA1w6bSSCa7NH99PebQAw (kafka.server.KafkaServer)
[2020-04-04 18:59:26,037] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:59:26,040] WARN No meta.properties file under dir /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-04 18:59:26,079] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:59:26,097] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:59:26,100] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:59:26,113] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:59:26,124] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:59:26,133] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:59:26,133] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:59:26,134] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:59:26,136] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-04 18:59:26,147] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:59:26,148] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:59:26,149] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:59:26,160] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:59:26,162] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:59:26,163] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:59:26,163] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-04 18:59:26,170] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:59:26,173] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:59:26,181] INFO Logs loading complete in 11 ms. (kafka.log.LogManager)
[2020-04-04 18:59:26,182] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:59:26,189] INFO Log directory /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-04 18:59:26,191] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-04 18:59:26,197] INFO Loading logs. (kafka.log.LogManager)
[2020-04-04 18:59:26,201] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:59:26,207] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-04 18:59:26,211] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:59:26,212] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:59:26,216] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:59:26,227] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-04 18:59:26,231] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-04 18:59:26,722] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-04 18:59:26,736] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-04 18:59:26,757] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-04 18:59:26,789] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:59:26,790] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:59:26,805] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:59:26,807] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:59:26,807] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-04 18:59:26,809] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-04 18:59:26,816] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,819] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,821] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,822] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,830] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,831] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,831] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,832] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,832] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,833] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,833] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,834] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,841] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:59:26,852] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:59:26,855] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-04 18:59:26,873] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:59:26,888] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:59:26,889] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-04 18:59:26,902] INFO Stat of the created znode at /brokers/ids/0 is: 66,66,1586023166890,1586023166890,1,0,0,72058690781970434,174,0,66
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:59:26,903] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(pc,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 66 (kafka.zk.KafkaZkClient)
[2020-04-04 18:59:26,908] INFO Stat of the created znode at /brokers/ids/1 is: 67,67,1586023166899,1586023166899,1,0,0,72058690781970433,174,0,67
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:59:26,908] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(pc,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 67 (kafka.zk.KafkaZkClient)
[2020-04-04 18:59:26,909] INFO Stat of the created znode at /brokers/ids/2 is: 68,68,1586023166901,1586023166901,1,0,0,72058690781970432,174,0,68
 (kafka.zk.KafkaZkClient)
[2020-04-04 18:59:26,910] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(pc,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 68 (kafka.zk.KafkaZkClient)
[2020-04-04 18:59:26,989] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,994] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:26,999] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:27,003] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:27,004] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:27,016] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-04 18:59:27,017] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:27,017] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:27,022] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:27,033] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:27,058] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:59:27,064] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:59:27,071] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:27,072] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:59:27,073] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:59:27,079] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:59:27,080] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:59:27,081] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:27,092] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:59:27,097] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:27,109] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:59:27,115] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-04 18:59:27,124] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:59:27,135] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:59:27,135] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:59:27,141] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:59:27,143] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:59:27,145] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:59:27,148] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:59:27,150] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-04 18:59:27,151] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-04 18:59:27,184] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:27,191] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:27,195] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-04 18:59:27,223] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:59:27,233] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:59:27,263] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:59:27,267] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:59:27,268] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:59:27,268] INFO Kafka startTimeMs: 1586023167263 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:59:27,270] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-04 18:59:27,287] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-04 18:59:27,289] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:59:27,294] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:59:27,294] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:59:27,294] INFO Kafka startTimeMs: 1586023167290 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:59:27,296] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-04 18:59:27,338] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-04 18:59:27,350] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:59:27,350] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:59:27,350] INFO Kafka startTimeMs: 1586023167338 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-04 18:59:27,354] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-04 18:59:27,725] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 2, 1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:59:27,836] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:27,928] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:27,937] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 55 ms (kafka.log.Log)
[2020-04-04 18:59:27,939] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:27,941] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:59:27,942] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:27,943] INFO [Partition BatchTopic-0 broker=0] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:27,960] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:27,968] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 55 ms (kafka.log.Log)
[2020-04-04 18:59:27,971] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:27,973] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:59:27,976] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:28,019] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:28,022] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:28,040] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 130 ms (kafka.log.Log)
[2020-04-04 18:59:28,051] INFO Created log for partition BatchTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:28,053] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:59:28,054] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:28,056] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:28,072] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:28,078] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:28,091] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:28,097] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=pc:9092) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:29,083] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:29,087] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:59:29,102] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:29,108] INFO [Log partition=BatchTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:59:30,108] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-04 18:59:30,132] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:30,134] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:30,134] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:59:30,135] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:30,135] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:30,136] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-04 18:59:30,136] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:59:30,136] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:30,137] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:30,137] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:30,137] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:59:30,137] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:30,138] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:30,138] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:30,139] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:59:30,140] INFO Created log for partition ReportTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:30,142] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:59:30,142] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:30,142] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:30,142] INFO [Partition ReportTopic-0 broker=1] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:30,143] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:30,144] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:30,144] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:59:30,158] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:30,161] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=pc:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:30,166] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:30,170] INFO [Log partition=ReportTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:59:30,172] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition ReportTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:59:31,979] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2, 1, 0)) (kafka.zk.AdminZkClient)
[2020-04-04 18:59:32,024] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:32,024] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:32,025] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:59:32,026] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:32,027] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:32,026] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:59:32,028] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:32,029] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:59:32,029] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:32,029] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:59:32,029] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:32,030] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:32,030] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:32,031] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:32,031] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-04 18:59:32,032] INFO Created log for partition AlarmTopic-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:32,033] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-04 18:59:32,033] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:32,034] INFO [Partition AlarmTopic-0 broker=2] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:32,034] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:32,035] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=pc:9094) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:32,035] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:32,035] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:32,036] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:59:32,035] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:32,037] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-04 18:59:32,037] INFO [Log partition=AlarmTopic-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-04 18:59:32,073] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition AlarmTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:59:32,073] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition AlarmTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-04 18:59:34,771] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(2), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(2), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(2), 22 -> ArrayBuffer(2), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(2), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(2), 10 -> ArrayBuffer(2), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(2), 45 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-04-04 18:59:34,791] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-04-04 18:59:35,146] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:35,159] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,161] INFO [Log partition=__consumer_offsets-0, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:59:35,164] INFO Created log for partition __consumer_offsets-0 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,165] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,166] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,166] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,181] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,177] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:35,205] INFO [Log partition=__consumer_offsets-48, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-04-04 18:59:35,208] INFO Created log for partition __consumer_offsets-48 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,210] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,211] INFO [Log partition=__consumer_offsets-29, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:59:35,216] INFO Created log for partition __consumer_offsets-29 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,209] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-04-04 18:59:35,219] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,219] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,228] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-04-04 18:59:35,228] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,228] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,251] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-04-04 18:59:35,256] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,258] INFO [Log partition=__consumer_offsets-45, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:59:35,265] INFO Created log for partition __consumer_offsets-45 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,266] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-04-04 18:59:35,266] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,266] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,268] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,272] INFO [Log partition=__consumer_offsets-10, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:59:35,276] INFO Created log for partition __consumer_offsets-10 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,278] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-04-04 18:59:35,278] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,278] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,281] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,282] INFO [Log partition=__consumer_offsets-26, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2020-04-04 18:59:35,285] INFO Created log for partition __consumer_offsets-26 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,285] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-04-04 18:59:35,285] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,285] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,293] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,295] INFO [Log partition=__consumer_offsets-42, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:59:35,301] INFO Created log for partition __consumer_offsets-42 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,302] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-04-04 18:59:35,302] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,303] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,311] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,314] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,315] INFO [Log partition=__consumer_offsets-7, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:59:35,319] INFO [Log partition=__consumer_offsets-23, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-04-04 18:59:35,322] INFO Created log for partition __consumer_offsets-23 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,323] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-04-04 18:59:35,323] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,323] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,325] INFO Created log for partition __consumer_offsets-7 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,325] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-04-04 18:59:35,325] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,326] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,335] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,338] INFO [Log partition=__consumer_offsets-39, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:59:35,341] INFO Created log for partition __consumer_offsets-39 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,341] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-04-04 18:59:35,341] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,341] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,348] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,350] INFO [Log partition=__consumer_offsets-4, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:59:35,351] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,360] INFO [Log partition=__consumer_offsets-20, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:59:35,353] INFO Created log for partition __consumer_offsets-4 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,362] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-04-04 18:59:35,363] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,363] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,364] INFO Created log for partition __consumer_offsets-20 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,364] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-04-04 18:59:35,364] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,365] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,371] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,373] INFO [Log partition=__consumer_offsets-36, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:59:35,394] INFO Created log for partition __consumer_offsets-36 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,394] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-04-04 18:59:35,394] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,394] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,395] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,397] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,398] INFO [Log partition=__consumer_offsets-1, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-04-04 18:59:35,399] INFO [Log partition=__consumer_offsets-17, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-04-04 18:59:35,404] INFO Created log for partition __consumer_offsets-1 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,404] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-04-04 18:59:35,405] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,405] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,410] INFO Created log for partition __consumer_offsets-17 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,410] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-04-04 18:59:35,410] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,410] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,411] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,413] INFO [Log partition=__consumer_offsets-33, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:59:35,424] INFO Created log for partition __consumer_offsets-33 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,425] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-04-04 18:59:35,425] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,425] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,441] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,448] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,450] INFO [Log partition=__consumer_offsets-14, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:59:35,453] INFO Created log for partition __consumer_offsets-14 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,453] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-04-04 18:59:35,443] INFO [Log partition=__consumer_offsets-30, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:59:35,456] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,456] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,464] INFO Created log for partition __consumer_offsets-30 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,464] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-04-04 18:59:35,467] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,470] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,468] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,473] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,475] INFO [Log partition=__consumer_offsets-49, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2020-04-04 18:59:35,476] INFO [Log partition=__consumer_offsets-11, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:59:35,478] INFO Created log for partition __consumer_offsets-49 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,478] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-04-04 18:59:35,478] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,478] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,478] INFO Created log for partition __consumer_offsets-11 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,479] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-04-04 18:59:35,479] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,481] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,507] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,507] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,508] INFO [Log partition=__consumer_offsets-46, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:59:35,508] INFO [Log partition=__consumer_offsets-27, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-04 18:59:35,511] INFO Created log for partition __consumer_offsets-27 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,511] INFO Created log for partition __consumer_offsets-46 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,511] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-04-04 18:59:35,511] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-04-04 18:59:35,511] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,512] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,512] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,512] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,512] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,513] INFO [Log partition=__consumer_offsets-8, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:59:35,515] INFO Created log for partition __consumer_offsets-8 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,515] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-04-04 18:59:35,515] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,516] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,538] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,535] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,539] INFO [Log partition=__consumer_offsets-5, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:59:35,540] INFO [Log partition=__consumer_offsets-24, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:59:35,542] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,549] INFO Created log for partition __consumer_offsets-24 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,558] INFO Created log for partition __consumer_offsets-5 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,559] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-04-04 18:59:35,559] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,559] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,549] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-04-04 18:59:35,560] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,560] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,560] INFO [Log partition=__consumer_offsets-43, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-04-04 18:59:35,563] INFO Created log for partition __consumer_offsets-43 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,563] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-04-04 18:59:35,563] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,564] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,579] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,580] INFO [Log partition=__consumer_offsets-21, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:59:35,584] INFO Created log for partition __consumer_offsets-21 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,584] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-04-04 18:59:35,584] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,585] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,593] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,594] INFO [Log partition=__consumer_offsets-40, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:59:35,596] INFO Created log for partition __consumer_offsets-40 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,597] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-04-04 18:59:35,597] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,597] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,599] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,605] INFO [Log partition=__consumer_offsets-2, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-04-04 18:59:35,608] INFO Created log for partition __consumer_offsets-2 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,608] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-04-04 18:59:35,608] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,608] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,614] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,616] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,617] INFO [Log partition=__consumer_offsets-18, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-04-04 18:59:35,621] INFO Created log for partition __consumer_offsets-18 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,621] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-04-04 18:59:35,621] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,621] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,622] INFO [Log partition=__consumer_offsets-37, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-04-04 18:59:35,625] INFO Created log for partition __consumer_offsets-37 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,625] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-04-04 18:59:35,627] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,627] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,640] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,642] INFO [Log partition=__consumer_offsets-47, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-04-04 18:59:35,644] INFO Created log for partition __consumer_offsets-47 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,644] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-04-04 18:59:35,644] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,645] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,648] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,653] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,654] INFO [Log partition=__consumer_offsets-15, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-04-04 18:59:35,656] INFO [Log partition=__consumer_offsets-34, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:59:35,661] INFO Created log for partition __consumer_offsets-34 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,661] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-04-04 18:59:35,662] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,662] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,662] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,663] INFO [Log partition=__consumer_offsets-38, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:59:35,665] INFO Created log for partition __consumer_offsets-38 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,665] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-04-04 18:59:35,665] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,666] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,672] INFO Created log for partition __consumer_offsets-15 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,672] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-04-04 18:59:35,673] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,673] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,684] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,686] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,687] INFO [Log partition=__consumer_offsets-31, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:59:35,687] INFO [Log partition=__consumer_offsets-35, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:59:35,690] INFO Created log for partition __consumer_offsets-35 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,690] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-04-04 18:59:35,690] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,690] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,691] INFO Created log for partition __consumer_offsets-31 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,691] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-04-04 18:59:35,691] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,691] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,703] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,705] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,705] INFO [Log partition=__consumer_offsets-12, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:59:35,706] INFO [Log partition=__consumer_offsets-44, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:59:35,707] INFO Created log for partition __consumer_offsets-12 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,707] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-04-04 18:59:35,707] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,707] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,709] INFO Created log for partition __consumer_offsets-44 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,709] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-04-04 18:59:35,709] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,709] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,717] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,719] INFO [Log partition=__consumer_offsets-19, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:59:35,722] INFO Created log for partition __consumer_offsets-19 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,722] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-04-04 18:59:35,723] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,723] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,723] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,725] INFO [Log partition=__consumer_offsets-9, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:59:35,727] INFO Created log for partition __consumer_offsets-9 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,727] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-04-04 18:59:35,728] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,728] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,735] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,737] INFO [Log partition=__consumer_offsets-32, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:59:35,740] INFO Created log for partition __consumer_offsets-32 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,740] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-04-04 18:59:35,740] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,740] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,751] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,753] INFO [Log partition=__consumer_offsets-28, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-04-04 18:59:35,754] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,755] INFO [Log partition=__consumer_offsets-6, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:59:35,761] INFO Created log for partition __consumer_offsets-28 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,761] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-04-04 18:59:35,761] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,762] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,763] INFO Created log for partition __consumer_offsets-6 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,763] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-04-04 18:59:35,763] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,763] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,765] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,769] INFO [Log partition=__consumer_offsets-41, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-04 18:59:35,780] INFO Created log for partition __consumer_offsets-41 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,780] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,780] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-04-04 18:59:35,780] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,780] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,781] INFO [Log partition=__consumer_offsets-16, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-04 18:59:35,786] INFO Created log for partition __consumer_offsets-16 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,786] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-04-04 18:59:35,786] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,786] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,786] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,788] INFO [Log partition=__consumer_offsets-3, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-04 18:59:35,791] INFO Created log for partition __consumer_offsets-3 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,791] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-04-04 18:59:35,791] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,792] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,793] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,794] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,795] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,795] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,795] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,795] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,797] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,797] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,798] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,798] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,798] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,808] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,812] INFO [Log partition=__consumer_offsets-25, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-04-04 18:59:35,814] INFO Created log for partition __consumer_offsets-25 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,814] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-04-04 18:59:35,815] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,815] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,820] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,821] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,821] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,822] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,822] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,822] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,822] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,825] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,826] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,826] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,826] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,826] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,827] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,827] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,815] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 20 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,829] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,831] INFO [Log partition=__consumer_offsets-22, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-04 18:59:35,836] INFO Created log for partition __consumer_offsets-22 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,837] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-04-04 18:59:35,837] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,837] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,841] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,846] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,847] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,847] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 25 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,848] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,861] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,862] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,862] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,865] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,865] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,866] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,868] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,869] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,869] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-04 18:59:35,870] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,871] INFO [Log partition=__consumer_offsets-13, dir=/home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-04-04 18:59:35,871] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,872] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,873] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,874] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,875] INFO Created log for partition __consumer_offsets-13 in /home/joaoalegria/Desktop/AS/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-04 18:59:35,875] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,875] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-04-04 18:59:35,875] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-04 18:59:35,875] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-04 18:59:35,876] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,877] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,877] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,879] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,880] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,881] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,883] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,885] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,887] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,889] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,890] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,896] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,898] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,898] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,898] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,898] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,899] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,899] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,903] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,904] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,904] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,905] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,905] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,905] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,906] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,906] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,907] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,907] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,939] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 40 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,944] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,946] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,948] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,950] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,952] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,953] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,954] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,958] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,959] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,960] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,961] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,963] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,968] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,970] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:35,971] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-04 18:59:36,032] INFO [GroupCoordinator 1]: Preparing to rebalance group test in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-test-1-9fba5349-7c95-42ba-9e7f-50efd22f93fd with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:59:36,072] INFO [GroupCoordinator 1]: Stabilized group test generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-04-04 18:59:36,103] INFO [GroupCoordinator 1]: Assignment received from leader for group test for generation 1 (kafka.coordinator.group.GroupCoordinator)
