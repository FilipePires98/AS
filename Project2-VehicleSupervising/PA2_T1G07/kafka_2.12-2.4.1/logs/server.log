[2020-04-18 13:00:22,134] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-18 13:00:22,761] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-18 13:00:22,762] INFO starting (kafka.server.KafkaServer)
[2020-04-18 13:00:22,766] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-18 13:00:22,792] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:00:22,800] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,801] INFO Client environment:host.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,801] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,801] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,801] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,801] INFO Client environment:java.class.path=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,802] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,802] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,802] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,802] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,802] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,803] INFO Client environment:os.version=4.19.108-1-MANJARO (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,803] INFO Client environment:user.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,803] INFO Client environment:user.home=/home/fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,803] INFO Client environment:user.dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,803] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,803] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,803] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,807] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3d51f06e (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:00:22,814] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-18 13:00:22,822] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-18 13:00:22,834] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:00:22,841] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:00:22,845] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59116, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:00:22,872] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:00:23,462] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000086bae60000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:00:23,465] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:00:25,705] INFO Cluster ID = Se9cOpaXQvS_g91UAd38_A (kafka.server.KafkaServer)
[2020-04-18 13:00:25,710] WARN No meta.properties file under dir /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-18 13:00:25,787] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:00:25,805] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:00:25,831] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:00:25,831] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:00:25,844] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:00:25,871] INFO Log directory /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-18 13:00:25,878] INFO Loading logs. (kafka.log.LogManager)
[2020-04-18 13:00:25,888] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-18 13:00:25,915] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-18 13:00:25,920] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-18 13:00:26,386] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-18 13:00:26,429] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-18 13:00:26,430] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-18 13:00:26,458] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:00:26,459] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:00:26,458] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:00:26,460] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:00:26,484] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-18 13:00:26,735] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-18 13:00:26,976] INFO Stat of the created znode at /brokers/ids/1 is: 67,67,1587211226744,1587211226744,1,0,0,72058172699181056,174,0,67
 (kafka.zk.KafkaZkClient)
[2020-04-18 13:00:26,977] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(fp,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 67 (kafka.zk.KafkaZkClient)
[2020-04-18 13:00:27,081] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:00:27,084] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:00:27,084] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:00:27,281] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:00:27,283] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:00:27,294] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:27,338] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-18 13:00:27,565] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:00:27,566] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-18 13:00:27,567] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:00:27,604] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:00:27,621] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-18 13:00:28,029] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-18 13:00:28,033] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:00:28,033] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:00:28,033] INFO Kafka startTimeMs: 1587211228030 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:00:28,035] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-18 13:00:30,176] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:30,319] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:30,330] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 102 ms (kafka.log.Log)
[2020-04-18 13:00:30,333] INFO Created log for partition BatchTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:30,334] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:00:30,335] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:30,336] INFO [Partition BatchTopic-0 broker=1] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:30,406] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:30,407] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-18 13:00:30,408] INFO Created log for partition BatchTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:30,409] INFO [Partition BatchTopic-1 broker=1] No checkpointed highwatermark is found for partition BatchTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:00:30,409] INFO [Partition BatchTopic-1 broker=1] Log loaded for partition BatchTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:30,414] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:30,415] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:00:30,416] INFO Created log for partition BatchTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:30,416] INFO [Partition BatchTopic-2 broker=1] No checkpointed highwatermark is found for partition BatchTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:00:30,417] INFO [Partition BatchTopic-2 broker=1] Log loaded for partition BatchTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:30,418] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-2, BatchTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:30,451] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:00:30,455] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(BatchTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:30,459] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:00:30,459] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(BatchTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:30,460] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition BatchTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:00:30,460] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition BatchTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:00:30,469] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:00:30,474] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:00:30,545] ERROR [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error for partition BatchTopic-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-18 13:00:33,811] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:33,819] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:33,820] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-18 13:00:33,821] INFO Created log for partition ReportTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:33,821] INFO [Partition ReportTopic-2 broker=1] No checkpointed highwatermark is found for partition ReportTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:00:33,825] INFO [Partition ReportTopic-2 broker=1] Log loaded for partition ReportTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:33,826] INFO [Partition ReportTopic-2 broker=1] ReportTopic-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:34,285] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:34,286] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:34,287] INFO Created log for partition ReportTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:34,287] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:00:34,288] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:34,293] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:34,293] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:34,294] INFO Created log for partition ReportTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:34,294] INFO [Partition ReportTopic-1 broker=1] No checkpointed highwatermark is found for partition ReportTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:00:34,294] INFO [Partition ReportTopic-1 broker=1] Log loaded for partition ReportTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:34,295] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0, ReportTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:34,296] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(ReportTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:34,296] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:34,612] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:00:34,612] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:00:34,634] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition ReportTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:00:34,634] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:00:36,880] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:36,885] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:36,886] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:00:36,887] INFO Created log for partition AlarmTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:36,888] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:00:36,888] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:36,888] INFO [Partition AlarmTopic-0 broker=1] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:36,936] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:36,938] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-18 13:00:36,939] INFO Created log for partition AlarmTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:36,939] INFO [Partition AlarmTopic-1 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:00:36,939] INFO [Partition AlarmTopic-1 broker=1] Log loaded for partition AlarmTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:36,946] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:36,946] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:36,947] INFO Created log for partition AlarmTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:36,947] INFO [Partition AlarmTopic-2 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:00:36,947] INFO [Partition AlarmTopic-2 broker=1] Log loaded for partition AlarmTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:36,948] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-2, AlarmTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:36,949] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(AlarmTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:36,949] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(AlarmTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:37,151] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:00:37,152] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:00:37,157] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:00:37,157] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:00:44,175] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:00:44,179] INFO [Log partition=__consumer_offsets-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:44,180] INFO [Log partition=__consumer_offsets-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:44,183] INFO Created log for partition __consumer_offsets-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:44,185] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-04-18 13:00:44,185] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:44,185] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:44,269] INFO [Log partition=__consumer_offsets-48, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:44,270] INFO [Log partition=__consumer_offsets-48, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:44,271] INFO Created log for partition __consumer_offsets-48 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:44,271] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-04-18 13:00:44,271] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:44,271] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:44,513] INFO [Log partition=__consumer_offsets-45, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:44,513] INFO [Log partition=__consumer_offsets-45, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-18 13:00:44,515] INFO Created log for partition __consumer_offsets-45 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:44,515] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-04-18 13:00:44,515] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:44,515] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:44,780] INFO [Log partition=__consumer_offsets-42, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:44,780] INFO [Log partition=__consumer_offsets-42, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:00:44,782] INFO Created log for partition __consumer_offsets-42 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:44,783] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-04-18 13:00:44,783] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:44,783] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:44,882] INFO [Log partition=__consumer_offsets-39, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:44,882] INFO [Log partition=__consumer_offsets-39, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:44,883] INFO Created log for partition __consumer_offsets-39 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:44,883] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-04-18 13:00:44,883] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:44,883] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:45,214] INFO [Log partition=__consumer_offsets-36, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:45,214] INFO [Log partition=__consumer_offsets-36, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:45,216] INFO Created log for partition __consumer_offsets-36 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:45,216] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-04-18 13:00:45,216] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:45,216] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:45,509] INFO [Log partition=__consumer_offsets-33, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:45,510] INFO [Log partition=__consumer_offsets-33, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:45,511] INFO Created log for partition __consumer_offsets-33 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:45,511] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-04-18 13:00:45,511] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:45,511] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:46,323] INFO [Log partition=__consumer_offsets-30, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:46,324] INFO [Log partition=__consumer_offsets-30, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:00:46,325] INFO Created log for partition __consumer_offsets-30 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:46,325] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-04-18 13:00:46,325] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:46,325] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:47,305] INFO [Log partition=__consumer_offsets-27, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:47,305] INFO [Log partition=__consumer_offsets-27, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:47,307] INFO Created log for partition __consumer_offsets-27 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:47,307] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-04-18 13:00:47,307] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:47,307] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:48,178] INFO [Log partition=__consumer_offsets-24, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:48,179] INFO [Log partition=__consumer_offsets-24, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:48,180] INFO Created log for partition __consumer_offsets-24 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:48,180] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-04-18 13:00:48,180] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:48,180] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:48,953] INFO [Log partition=__consumer_offsets-21, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:48,953] INFO [Log partition=__consumer_offsets-21, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:00:48,954] INFO Created log for partition __consumer_offsets-21 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:48,954] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-04-18 13:00:48,954] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:48,955] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:49,630] INFO [Log partition=__consumer_offsets-18, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:49,630] INFO [Log partition=__consumer_offsets-18, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:49,631] INFO Created log for partition __consumer_offsets-18 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:49,631] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-04-18 13:00:49,631] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:49,631] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:50,196] INFO [Log partition=__consumer_offsets-15, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:50,197] INFO [Log partition=__consumer_offsets-15, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-18 13:00:50,198] INFO Created log for partition __consumer_offsets-15 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:50,199] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-04-18 13:00:50,199] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:50,199] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:50,675] INFO [Log partition=__consumer_offsets-12, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:50,675] INFO [Log partition=__consumer_offsets-12, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:50,676] INFO Created log for partition __consumer_offsets-12 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:50,677] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-04-18 13:00:50,677] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:50,677] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:51,067] INFO [Log partition=__consumer_offsets-9, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:51,068] INFO [Log partition=__consumer_offsets-9, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:51,068] INFO Created log for partition __consumer_offsets-9 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:51,069] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-04-18 13:00:51,069] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:51,069] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:51,140] INFO [Log partition=__consumer_offsets-6, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:51,140] INFO [Log partition=__consumer_offsets-6, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:00:51,140] INFO Created log for partition __consumer_offsets-6 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:51,140] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-04-18 13:00:51,140] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:51,141] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:51,259] INFO [Log partition=__consumer_offsets-3, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:00:51,259] INFO [Log partition=__consumer_offsets-3, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:00:51,261] INFO Created log for partition __consumer_offsets-3 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:00:51,262] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-04-18 13:00:51,262] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:00:51,262] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:00:51,539] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,540] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,540] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,540] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,540] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,540] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,541] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,541] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,541] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,541] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,541] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,541] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,541] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,541] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,541] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,541] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,541] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,548] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,551] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,551] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,551] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,551] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,552] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,552] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,552] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,552] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,552] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,553] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,553] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,553] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,553] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,553] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,555] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:00:51,555] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:25,212] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:02:25,214] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:02:25,218] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:02:25,226] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:02:25,226] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:02:25,229] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-18 13:02:25,229] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-18 13:02:25,229] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-18 13:02:25,229] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-18 13:02:25,231] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-18 13:02:25,253] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:02:25,253] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:02:25,253] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:02:25,253] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:02:25,253] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:02:25,253] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-18 13:02:25,256] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-18 13:02:25,257] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-18 13:02:25,271] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,271] INFO Server environment:host.name=fp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,271] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,271] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,271] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,271] INFO Server environment:java.class.path=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,272] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,272] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,273] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,273] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,273] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,273] INFO Server environment:os.version=4.19.108-1-MANJARO (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,273] INFO Server environment:user.name=fp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,273] INFO Server environment:user.home=/home/fp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,273] INFO Server environment:user.dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,273] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,273] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,273] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,277] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,277] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,278] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:02:25,287] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-18 13:02:25,291] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-18 13:02:25,295] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-18 13:02:25,331] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-18 13:02:25,338] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-18 13:02:25,342] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-18 13:02:25,353] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-18 13:02:25,375] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-18 13:02:25,405] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-18 13:02:25,853] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-18 13:02:25,859] INFO starting (kafka.server.KafkaServer)
[2020-04-18 13:02:25,866] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-18 13:02:25,905] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:02:25,914] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,914] INFO Client environment:host.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,914] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,914] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,915] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,915] INFO Client environment:java.class.path=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,916] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,916] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,916] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,916] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,916] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,916] INFO Client environment:os.version=4.19.108-1-MANJARO (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,916] INFO Client environment:user.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,916] INFO Client environment:user.home=/home/fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,916] INFO Client environment:user.dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,917] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,917] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,917] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,920] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3d51f06e (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,926] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-18 13:02:25,933] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-18 13:02:25,941] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:25,942] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-18 13:02:25,943] INFO starting (kafka.server.KafkaServer)
[2020-04-18 13:02:25,944] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-18 13:02:25,946] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:02:25,947] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:25,952] INFO Socket connection established, initiating session, client: /127.0.0.1:33010, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:25,963] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-18 13:02:25,968] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:02:25,973] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,973] INFO Client environment:host.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,973] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,973] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,973] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,973] INFO Client environment:java.class.path=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:os.version=4.19.108-1-MANJARO (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:user.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:user.home=/home/fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:user.dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,974] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,976] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3d51f06e (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:25,980] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-18 13:02:25,981] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-18 13:02:25,981] INFO starting (kafka.server.KafkaServer)
[2020-04-18 13:02:25,982] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-18 13:02:25,985] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-18 13:02:25,990] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:25,992] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:02:25,996] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:26,000] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59286, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:26,001] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:02:26,006] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,006] INFO Client environment:host.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,006] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,006] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,006] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,006] INFO Client environment:java.class.path=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:os.version=4.19.108-1-MANJARO (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:user.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:user.home=/home/fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:user.dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,007] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,009] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3d51f06e (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:02:26,013] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-18 13:02:26,017] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-18 13:02:26,021] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:26,023] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:02:26,026] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:26,029] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59288, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:26,039] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000889bac0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:26,049] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:02:26,077] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000889bac0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:26,078] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000889bac0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:02:26,092] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:02:26,094] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:02:26,808] INFO Cluster ID = H6tPsBk5S0e160hbqd9dGQ (kafka.server.KafkaServer)
[2020-04-18 13:02:26,811] WARN No meta.properties file under dir /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-18 13:02:26,840] INFO Cluster ID = H6tPsBk5S0e160hbqd9dGQ (kafka.server.KafkaServer)
[2020-04-18 13:02:26,844] WARN No meta.properties file under dir /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-18 13:02:26,847] INFO Cluster ID = H6tPsBk5S0e160hbqd9dGQ (kafka.server.KafkaServer)
[2020-04-18 13:02:26,852] WARN No meta.properties file under dir /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-18 13:02:26,880] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:02:26,894] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:02:26,903] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:02:26,917] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:02:26,926] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:02:26,928] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:02:26,930] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:02:26,930] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:02:26,938] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:02:26,945] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:02:26,946] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:02:26,947] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:02:26,962] INFO Log directory /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-18 13:02:26,965] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:02:26,965] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:02:26,966] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:02:26,971] INFO Loading logs. (kafka.log.LogManager)
[2020-04-18 13:02:26,973] INFO Log directory /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-18 13:02:26,981] INFO Loading logs. (kafka.log.LogManager)
[2020-04-18 13:02:26,981] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-18 13:02:26,987] INFO Log directory /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-18 13:02:26,991] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2020-04-18 13:02:26,995] INFO Loading logs. (kafka.log.LogManager)
[2020-04-18 13:02:27,002] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-18 13:02:27,004] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-18 13:02:27,009] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-18 13:02:27,012] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-18 13:02:27,015] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-18 13:02:27,024] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-18 13:02:27,032] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-18 13:02:27,458] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-18 13:02:27,480] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-18 13:02:27,496] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-18 13:02:27,544] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-18 13:02:27,546] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-18 13:02:27,546] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-18 13:02:27,548] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-18 13:02:27,550] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-18 13:02:27,552] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-18 13:02:27,570] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,571] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,573] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,574] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,574] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,575] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,576] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,576] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,584] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,589] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,593] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,600] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-18 13:02:27,601] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,602] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-18 13:02:27,627] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-18 13:02:27,629] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-18 13:02:27,637] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-18 13:02:27,664] INFO Stat of the created znode at /brokers/ids/2 is: 68,68,1587211347643,1587211347643,1,0,0,72058180765220864,174,0,68
 (kafka.zk.KafkaZkClient)
[2020-04-18 13:02:27,665] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(fp,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 68 (kafka.zk.KafkaZkClient)
[2020-04-18 13:02:27,674] INFO Stat of the created znode at /brokers/ids/1 is: 69,69,1587211347643,1587211347643,1,0,0,72058180765220865,174,0,69
 (kafka.zk.KafkaZkClient)
[2020-04-18 13:02:27,675] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(fp,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 69 (kafka.zk.KafkaZkClient)
[2020-04-18 13:02:27,706] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-18 13:02:27,760] INFO Stat of the created znode at /brokers/ids/0 is: 70,70,1587211347726,1587211347726,1,0,0,72058180765220866,174,0,70
 (kafka.zk.KafkaZkClient)
[2020-04-18 13:02:27,761] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(fp,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 70 (kafka.zk.KafkaZkClient)
[2020-04-18 13:02:27,779] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,782] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,794] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,805] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,807] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,808] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,932] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-18 13:02:27,954] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:27,955] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:27,956] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:27,958] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:27,960] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:27,963] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:27,987] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,989] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:27,990] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:28,000] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-18 13:02:28,036] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:28,037] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:28,039] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:02:28,041] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:28,042] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-18 13:02:28,042] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:02:28,062] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:28,067] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-18 13:02:28,083] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-18 13:02:28,098] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-18 13:02:28,118] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:02:28,126] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:02:28,126] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-18 13:02:28,126] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:02:28,128] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-18 13:02:28,134] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:02:28,134] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:02:28,134] INFO Kafka startTimeMs: 1587211348129 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:02:28,136] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-18 13:02:28,138] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-18 13:02:28,138] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:02:28,166] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:28,176] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:02:28,244] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-18 13:02:28,269] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-18 13:02:28,285] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-18 13:02:28,294] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:02:28,294] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:02:28,294] INFO Kafka startTimeMs: 1587211348285 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:02:28,296] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-18 13:02:28,329] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-18 13:02:28,355] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:02:28,355] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:02:28,355] INFO Kafka startTimeMs: 1587211348335 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:02:28,357] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-18 13:02:28,581] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(2 -> ArrayBuffer(1, 2, 0), 1 -> ArrayBuffer(2, 0, 1), 0 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2020-04-18 13:02:28,747] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:28,751] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:28,753] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:28,839] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:28,847] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2020-04-18 13:02:28,850] INFO Created log for partition BatchTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:28,851] INFO [Partition BatchTopic-1 broker=2] No checkpointed highwatermark is found for partition BatchTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:02:28,852] INFO [Partition BatchTopic-1 broker=2] Log loaded for partition BatchTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:28,853] INFO [Partition BatchTopic-1 broker=2] BatchTopic-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:28,901] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:28,901] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:28,902] INFO Created log for partition BatchTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:28,902] INFO [Partition BatchTopic-2 broker=2] No checkpointed highwatermark is found for partition BatchTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:02:28,902] INFO [Partition BatchTopic-2 broker=2] Log loaded for partition BatchTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:28,907] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:28,908] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:28,909] INFO Created log for partition BatchTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:28,909] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:02:28,909] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:28,910] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0, BatchTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:28,933] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:28,934] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:28,939] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(BatchTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:28,942] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 103 ms (kafka.log.Log)
[2020-04-18 13:02:28,944] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:28,944] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:28,947] INFO Created log for partition BatchTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:28,948] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:28,950] INFO [Partition BatchTopic-2 broker=1] No checkpointed highwatermark is found for partition BatchTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:02:28,951] INFO [Partition BatchTopic-2 broker=1] Log loaded for partition BatchTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:28,952] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:28,954] INFO [Partition BatchTopic-2 broker=1] BatchTopic-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:28,961] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:28,971] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 134 ms (kafka.log.Log)
[2020-04-18 13:02:28,973] INFO Created log for partition BatchTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:28,975] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:02:28,976] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:28,976] INFO [Partition BatchTopic-0 broker=0] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:28,998] ERROR [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error for partition BatchTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-18 13:02:29,022] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:29,023] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:29,023] INFO Created log for partition BatchTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:29,023] INFO [Partition BatchTopic-1 broker=1] No checkpointed highwatermark is found for partition BatchTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:02:29,024] INFO [Partition BatchTopic-1 broker=1] Log loaded for partition BatchTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:29,027] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:29,027] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:29,028] INFO Created log for partition BatchTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:29,028] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:02:29,028] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:29,029] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0, BatchTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:29,048] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:29,051] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(BatchTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:29,054] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:29,054] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:29,054] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition BatchTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:29,054] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:29,057] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:29,064] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:29,073] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:29,073] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:29,074] INFO Created log for partition BatchTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:29,074] INFO [Partition BatchTopic-1 broker=0] No checkpointed highwatermark is found for partition BatchTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:02:29,075] INFO [Partition BatchTopic-1 broker=0] Log loaded for partition BatchTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:29,086] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:29,087] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:29,087] ERROR [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error for partition BatchTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-18 13:02:29,089] INFO Created log for partition BatchTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:29,089] INFO [Partition BatchTopic-2 broker=0] No checkpointed highwatermark is found for partition BatchTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:02:29,089] INFO [Partition BatchTopic-2 broker=0] Log loaded for partition BatchTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:29,091] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-2, BatchTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:29,142] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:29,146] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(BatchTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:29,149] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:29,149] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(BatchTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:29,152] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition BatchTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:29,155] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:29,941] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition BatchTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:29,941] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:30,148] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition BatchTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:30,149] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:30,954] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(2 -> ArrayBuffer(1, 0, 2), 1 -> ArrayBuffer(2, 1, 0), 0 -> ArrayBuffer(0, 2, 1)) (kafka.zk.AdminZkClient)
[2020-04-18 13:02:32,742] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,743] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,743] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,748] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:32,748] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:32,749] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:32,749] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:32,750] INFO Created log for partition ReportTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:32,750] INFO Created log for partition ReportTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:32,751] INFO [Partition ReportTopic-1 broker=2] No checkpointed highwatermark is found for partition ReportTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:02:32,751] INFO [Partition ReportTopic-1 broker=2] Log loaded for partition ReportTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,751] INFO [Partition ReportTopic-1 broker=2] ReportTopic-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:32,751] INFO [Partition ReportTopic-2 broker=1] No checkpointed highwatermark is found for partition ReportTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:02:32,752] INFO [Partition ReportTopic-2 broker=1] Log loaded for partition ReportTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,752] INFO [Partition ReportTopic-2 broker=1] ReportTopic-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:32,752] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:32,753] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:32,754] INFO Created log for partition ReportTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:32,754] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,754] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,754] INFO [Partition ReportTopic-0 broker=0] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:32,785] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:32,785] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:32,786] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:32,786] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:32,787] INFO Created log for partition ReportTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:32,787] INFO Created log for partition ReportTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:32,787] INFO [Partition ReportTopic-2 broker=2] No checkpointed highwatermark is found for partition ReportTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:02:32,787] INFO [Partition ReportTopic-2 broker=0] No checkpointed highwatermark is found for partition ReportTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:02:32,787] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:32,787] INFO [Partition ReportTopic-2 broker=2] Log loaded for partition ReportTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,787] INFO [Partition ReportTopic-2 broker=0] Log loaded for partition ReportTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,788] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:32,789] INFO Created log for partition ReportTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:32,790] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,790] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,793] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:32,793] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:32,794] INFO Created log for partition ReportTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:32,794] INFO [Partition ReportTopic-1 broker=0] No checkpointed highwatermark is found for partition ReportTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:02:32,795] INFO [Partition ReportTopic-1 broker=0] Log loaded for partition ReportTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,795] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-2, ReportTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,796] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(ReportTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,796] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(ReportTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,796] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:32,797] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:32,798] INFO Created log for partition ReportTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:32,798] INFO [Partition ReportTopic-1 broker=1] No checkpointed highwatermark is found for partition ReportTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:02:32,798] INFO [Partition ReportTopic-1 broker=1] Log loaded for partition ReportTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,799] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0, ReportTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,799] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:32,799] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(ReportTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,800] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,800] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:32,801] INFO Created log for partition ReportTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:32,801] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,801] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:32,802] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0, ReportTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,803] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(ReportTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,803] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:32,968] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition ReportTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:32,969] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:33,057] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:33,057] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:33,117] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:33,117] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:33,181] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition ReportTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:33,181] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:33,181] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition ReportTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:33,182] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:33,271] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition ReportTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:33,271] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:34,788] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(2 -> ArrayBuffer(1, 2, 0), 1 -> ArrayBuffer(2, 0, 1), 0 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2020-04-18 13:02:36,425] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,425] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,426] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,430] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:36,431] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:36,431] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:36,432] INFO Created log for partition AlarmTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:36,433] INFO [Partition AlarmTopic-2 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:02:36,433] INFO [Partition AlarmTopic-2 broker=1] Log loaded for partition AlarmTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,433] INFO [Partition AlarmTopic-2 broker=1] AlarmTopic-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:36,434] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2020-04-18 13:02:36,436] INFO Created log for partition AlarmTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:36,436] INFO [Partition AlarmTopic-1 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:02:36,436] INFO [Partition AlarmTopic-1 broker=2] Log loaded for partition AlarmTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,436] INFO [Partition AlarmTopic-1 broker=2] AlarmTopic-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:36,437] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:36,437] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:36,439] INFO Created log for partition AlarmTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:36,439] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,439] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,439] INFO [Partition AlarmTopic-0 broker=0] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:36,778] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:36,779] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:36,779] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:36,779] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:36,779] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:36,779] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:36,780] INFO Created log for partition AlarmTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:36,780] INFO Created log for partition AlarmTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:36,780] INFO [Partition AlarmTopic-2 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:02:36,780] INFO [Partition AlarmTopic-1 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:02:36,780] INFO [Partition AlarmTopic-2 broker=2] Log loaded for partition AlarmTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,780] INFO [Partition AlarmTopic-1 broker=1] Log loaded for partition AlarmTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,780] INFO Created log for partition AlarmTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:36,781] INFO [Partition AlarmTopic-1 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:02:36,781] INFO [Partition AlarmTopic-1 broker=0] Log loaded for partition AlarmTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,784] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:36,784] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:36,784] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:36,784] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:36,784] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:36,784] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:36,785] INFO Created log for partition AlarmTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:36,785] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,785] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,785] INFO Created log for partition AlarmTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:36,785] INFO [Partition AlarmTopic-2 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:02:36,785] INFO [Partition AlarmTopic-2 broker=0] Log loaded for partition AlarmTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,785] INFO Created log for partition AlarmTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:36,785] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0, AlarmTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,785] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,785] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-2, AlarmTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,785] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:36,786] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0, AlarmTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,786] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(AlarmTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,786] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(AlarmTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,786] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,786] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(AlarmTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,786] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(AlarmTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,787] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:36,797] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:36,798] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:37,005] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:37,006] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:37,095] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:37,096] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:37,146] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:37,146] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:37,212] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:37,213] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:02:37,213] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:37,213] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:02:38,478] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(1), 32 -> ArrayBuffer(1), 41 -> ArrayBuffer(1), 17 -> ArrayBuffer(1), 8 -> ArrayBuffer(1), 35 -> ArrayBuffer(1), 44 -> ArrayBuffer(1), 26 -> ArrayBuffer(1), 11 -> ArrayBuffer(1), 29 -> ArrayBuffer(1), 38 -> ArrayBuffer(1), 47 -> ArrayBuffer(1), 20 -> ArrayBuffer(1), 2 -> ArrayBuffer(1), 5 -> ArrayBuffer(1), 14 -> ArrayBuffer(1), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(2), 27 -> ArrayBuffer(2), 36 -> ArrayBuffer(2), 18 -> ArrayBuffer(2), 9 -> ArrayBuffer(2), 21 -> ArrayBuffer(2), 48 -> ArrayBuffer(2), 3 -> ArrayBuffer(2), 12 -> ArrayBuffer(2), 30 -> ArrayBuffer(2), 39 -> ArrayBuffer(2), 15 -> ArrayBuffer(2), 42 -> ArrayBuffer(2), 24 -> ArrayBuffer(2), 6 -> ArrayBuffer(2), 33 -> ArrayBuffer(2), 0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[2020-04-18 13:02:38,480] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(1), 32 -> ArrayBuffer(1), 41 -> ArrayBuffer(1), 17 -> ArrayBuffer(1), 8 -> ArrayBuffer(1), 35 -> ArrayBuffer(1), 44 -> ArrayBuffer(1), 26 -> ArrayBuffer(1), 11 -> ArrayBuffer(1), 29 -> ArrayBuffer(1), 38 -> ArrayBuffer(1), 47 -> ArrayBuffer(1), 20 -> ArrayBuffer(1), 2 -> ArrayBuffer(1), 5 -> ArrayBuffer(1), 14 -> ArrayBuffer(1), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(2), 27 -> ArrayBuffer(2), 36 -> ArrayBuffer(2), 18 -> ArrayBuffer(2), 9 -> ArrayBuffer(2), 21 -> ArrayBuffer(2), 48 -> ArrayBuffer(2), 3 -> ArrayBuffer(2), 12 -> ArrayBuffer(2), 30 -> ArrayBuffer(2), 39 -> ArrayBuffer(2), 15 -> ArrayBuffer(2), 42 -> ArrayBuffer(2), 24 -> ArrayBuffer(2), 6 -> ArrayBuffer(2), 33 -> ArrayBuffer(2), 0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[2020-04-18 13:02:38,490] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(2), 32 -> ArrayBuffer(2), 41 -> ArrayBuffer(2), 17 -> ArrayBuffer(2), 8 -> ArrayBuffer(2), 35 -> ArrayBuffer(2), 44 -> ArrayBuffer(2), 26 -> ArrayBuffer(2), 11 -> ArrayBuffer(2), 29 -> ArrayBuffer(2), 38 -> ArrayBuffer(2), 47 -> ArrayBuffer(2), 20 -> ArrayBuffer(2), 2 -> ArrayBuffer(2), 5 -> ArrayBuffer(2), 14 -> ArrayBuffer(2), 46 -> ArrayBuffer(1), 49 -> ArrayBuffer(1), 40 -> ArrayBuffer(1), 13 -> ArrayBuffer(1), 4 -> ArrayBuffer(1), 22 -> ArrayBuffer(1), 31 -> ArrayBuffer(1), 16 -> ArrayBuffer(1), 7 -> ArrayBuffer(1), 43 -> ArrayBuffer(1), 25 -> ArrayBuffer(1), 34 -> ArrayBuffer(1), 10 -> ArrayBuffer(1), 37 -> ArrayBuffer(1), 1 -> ArrayBuffer(1), 19 -> ArrayBuffer(1), 28 -> ArrayBuffer(1), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-04-18 13:02:38,924] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(2), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(2), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(2), 22 -> ArrayBuffer(2), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(2), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(2), 10 -> ArrayBuffer(2), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(2), 45 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-04-18 13:02:38,932] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(2), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(2), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(2), 22 -> ArrayBuffer(2), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(2), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(2), 10 -> ArrayBuffer(2), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(2), 45 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-04-18 13:02:38,935] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(2), 32 -> ArrayBuffer(2), 41 -> ArrayBuffer(2), 17 -> ArrayBuffer(2), 8 -> ArrayBuffer(2), 35 -> ArrayBuffer(2), 44 -> ArrayBuffer(2), 26 -> ArrayBuffer(2), 11 -> ArrayBuffer(2), 29 -> ArrayBuffer(2), 38 -> ArrayBuffer(2), 47 -> ArrayBuffer(2), 20 -> ArrayBuffer(2), 2 -> ArrayBuffer(2), 5 -> ArrayBuffer(2), 14 -> ArrayBuffer(2), 46 -> ArrayBuffer(1), 49 -> ArrayBuffer(1), 40 -> ArrayBuffer(1), 13 -> ArrayBuffer(1), 4 -> ArrayBuffer(1), 22 -> ArrayBuffer(1), 31 -> ArrayBuffer(1), 16 -> ArrayBuffer(1), 7 -> ArrayBuffer(1), 43 -> ArrayBuffer(1), 25 -> ArrayBuffer(1), 34 -> ArrayBuffer(1), 10 -> ArrayBuffer(1), 37 -> ArrayBuffer(1), 1 -> ArrayBuffer(1), 19 -> ArrayBuffer(1), 28 -> ArrayBuffer(1), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-04-18 13:02:38,983] INFO [KafkaApi-2] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-04-18 13:02:41,502] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:41,527] INFO [Log partition=__consumer_offsets-29, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:41,527] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:41,528] INFO [Log partition=__consumer_offsets-29, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-18 13:02:41,529] INFO Created log for partition __consumer_offsets-29 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:41,530] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-04-18 13:02:41,530] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:41,530] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:41,531] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:02:41,535] INFO [Log partition=__consumer_offsets-10, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:41,536] INFO [Log partition=__consumer_offsets-10, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-18 13:02:41,537] INFO Created log for partition __consumer_offsets-10 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:41,538] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-04-18 13:02:41,538] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:41,539] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:41,548] INFO [Log partition=__consumer_offsets-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:41,548] INFO [Log partition=__consumer_offsets-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-18 13:02:41,549] INFO Created log for partition __consumer_offsets-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:41,550] INFO [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-04-18 13:02:41,550] INFO [Partition __consumer_offsets-0 broker=2] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:41,550] INFO [Partition __consumer_offsets-0 broker=2] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:41,583] INFO [Log partition=__consumer_offsets-26, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:41,583] INFO [Log partition=__consumer_offsets-26, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:41,589] INFO Created log for partition __consumer_offsets-26 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:41,589] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-04-18 13:02:41,589] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:41,589] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:41,812] INFO [Log partition=__consumer_offsets-48, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:41,812] INFO [Log partition=__consumer_offsets-48, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:41,812] INFO [Log partition=__consumer_offsets-7, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:41,813] INFO [Log partition=__consumer_offsets-7, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:41,813] INFO Created log for partition __consumer_offsets-48 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:41,814] INFO [Partition __consumer_offsets-48 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-04-18 13:02:41,814] INFO Created log for partition __consumer_offsets-7 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:41,814] INFO [Partition __consumer_offsets-48 broker=2] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:41,814] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-04-18 13:02:41,814] INFO [Partition __consumer_offsets-48 broker=2] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:41,814] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:41,814] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:41,941] INFO [Log partition=__consumer_offsets-23, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:41,942] INFO [Log partition=__consumer_offsets-23, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:41,943] INFO Created log for partition __consumer_offsets-23 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:41,943] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-04-18 13:02:41,943] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:41,943] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:42,108] INFO [Log partition=__consumer_offsets-4, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:42,108] INFO [Log partition=__consumer_offsets-4, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:42,109] INFO Created log for partition __consumer_offsets-4 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:42,110] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-04-18 13:02:42,110] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:42,110] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:42,113] INFO [Log partition=__consumer_offsets-45, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:42,113] INFO [Log partition=__consumer_offsets-45, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:42,115] INFO Created log for partition __consumer_offsets-45 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:42,115] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-04-18 13:02:42,115] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:42,115] INFO [Partition __consumer_offsets-45 broker=2] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:42,286] INFO [Log partition=__consumer_offsets-20, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:42,287] INFO [Log partition=__consumer_offsets-20, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:42,288] INFO Created log for partition __consumer_offsets-20 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:42,288] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-04-18 13:02:42,288] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:42,288] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:42,439] INFO [Log partition=__consumer_offsets-42, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:42,439] INFO [Log partition=__consumer_offsets-42, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:42,440] INFO [Log partition=__consumer_offsets-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:42,440] INFO Created log for partition __consumer_offsets-42 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:42,440] INFO [Partition __consumer_offsets-42 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-04-18 13:02:42,440] INFO [Log partition=__consumer_offsets-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:42,440] INFO [Partition __consumer_offsets-42 broker=2] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:42,440] INFO [Partition __consumer_offsets-42 broker=2] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:42,441] INFO Created log for partition __consumer_offsets-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:42,441] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-04-18 13:02:42,441] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:42,441] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:42,660] INFO [Log partition=__consumer_offsets-17, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:42,660] INFO [Log partition=__consumer_offsets-17, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:42,662] INFO Created log for partition __consumer_offsets-17 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:42,662] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-04-18 13:02:42,662] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:42,662] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:42,967] INFO [Log partition=__consumer_offsets-39, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:42,967] INFO [Log partition=__consumer_offsets-49, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:42,967] INFO [Log partition=__consumer_offsets-39, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:42,967] INFO [Log partition=__consumer_offsets-49, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:42,968] INFO Created log for partition __consumer_offsets-39 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:42,968] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-04-18 13:02:42,968] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:42,968] INFO [Partition __consumer_offsets-39 broker=2] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:42,968] INFO Created log for partition __consumer_offsets-49 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:42,968] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-04-18 13:02:42,968] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:42,969] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:42,992] INFO [Log partition=__consumer_offsets-14, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:42,992] INFO [Log partition=__consumer_offsets-14, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:42,993] INFO Created log for partition __consumer_offsets-14 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:42,993] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-04-18 13:02:42,993] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:42,993] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,043] INFO [Log partition=__consumer_offsets-46, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,044] INFO [Log partition=__consumer_offsets-46, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:43,044] INFO [Log partition=__consumer_offsets-36, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,044] INFO [Log partition=__consumer_offsets-36, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:43,045] INFO Created log for partition __consumer_offsets-46 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,045] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-04-18 13:02:43,045] INFO Created log for partition __consumer_offsets-36 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,045] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,045] INFO [Partition __consumer_offsets-36 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-04-18 13:02:43,045] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,045] INFO [Partition __consumer_offsets-36 broker=2] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,045] INFO [Partition __consumer_offsets-36 broker=2] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,095] INFO [Log partition=__consumer_offsets-11, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,095] INFO [Log partition=__consumer_offsets-11, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:43,096] INFO Created log for partition __consumer_offsets-11 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,096] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-04-18 13:02:43,096] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,096] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,160] INFO [Log partition=__consumer_offsets-33, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,160] INFO [Log partition=__consumer_offsets-33, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:43,160] INFO [Log partition=__consumer_offsets-43, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,161] INFO [Log partition=__consumer_offsets-43, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:43,162] INFO Created log for partition __consumer_offsets-33 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,162] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-04-18 13:02:43,162] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,162] INFO Created log for partition __consumer_offsets-43 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,162] INFO [Partition __consumer_offsets-33 broker=2] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,162] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-04-18 13:02:43,162] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,162] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,229] INFO [Log partition=__consumer_offsets-8, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,229] INFO [Log partition=__consumer_offsets-8, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:43,230] INFO Created log for partition __consumer_offsets-8 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,230] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-04-18 13:02:43,230] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,230] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,309] INFO [Log partition=__consumer_offsets-40, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,309] INFO [Log partition=__consumer_offsets-40, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:43,310] INFO [Log partition=__consumer_offsets-30, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,310] INFO [Log partition=__consumer_offsets-30, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:43,311] INFO Created log for partition __consumer_offsets-30 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,312] INFO [Partition __consumer_offsets-30 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-04-18 13:02:43,312] INFO [Partition __consumer_offsets-30 broker=2] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,312] INFO [Partition __consumer_offsets-30 broker=2] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,312] INFO Created log for partition __consumer_offsets-40 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,312] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-04-18 13:02:43,312] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,312] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,428] INFO [Log partition=__consumer_offsets-5, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,429] INFO [Log partition=__consumer_offsets-5, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:43,430] INFO Created log for partition __consumer_offsets-5 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,430] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-04-18 13:02:43,430] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,430] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,633] INFO [Log partition=__consumer_offsets-27, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,633] INFO [Log partition=__consumer_offsets-37, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,633] INFO [Log partition=__consumer_offsets-27, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:43,633] INFO [Log partition=__consumer_offsets-37, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:43,633] INFO Created log for partition __consumer_offsets-27 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,634] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-04-18 13:02:43,634] INFO Created log for partition __consumer_offsets-37 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,634] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,634] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-04-18 13:02:43,634] INFO [Partition __consumer_offsets-27 broker=2] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,634] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,634] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:43,873] INFO [Log partition=__consumer_offsets-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:43,873] INFO [Log partition=__consumer_offsets-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:43,874] INFO Created log for partition __consumer_offsets-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:43,874] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-04-18 13:02:43,875] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:43,875] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:44,061] INFO [Log partition=__consumer_offsets-24, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:44,062] INFO [Log partition=__consumer_offsets-34, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:44,062] INFO [Log partition=__consumer_offsets-24, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:44,062] INFO [Log partition=__consumer_offsets-34, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:44,063] INFO Created log for partition __consumer_offsets-24 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:44,063] INFO [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-04-18 13:02:44,063] INFO [Partition __consumer_offsets-24 broker=2] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:44,063] INFO [Partition __consumer_offsets-24 broker=2] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:44,063] INFO Created log for partition __consumer_offsets-34 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:44,063] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-04-18 13:02:44,063] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:44,063] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:44,212] INFO [Log partition=__consumer_offsets-47, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:44,212] INFO [Log partition=__consumer_offsets-47, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:44,213] INFO Created log for partition __consumer_offsets-47 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:44,213] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-04-18 13:02:44,214] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:44,214] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:44,386] INFO [Log partition=__consumer_offsets-21, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:44,386] INFO [Log partition=__consumer_offsets-31, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:44,386] INFO [Log partition=__consumer_offsets-21, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:44,386] INFO [Log partition=__consumer_offsets-31, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:44,387] INFO Created log for partition __consumer_offsets-31 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:44,387] INFO Created log for partition __consumer_offsets-21 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:44,387] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-04-18 13:02:44,387] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-04-18 13:02:44,387] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:44,387] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:44,387] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:44,387] INFO [Partition __consumer_offsets-21 broker=2] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:44,525] INFO [Log partition=__consumer_offsets-38, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:44,525] INFO [Log partition=__consumer_offsets-38, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:44,526] INFO Created log for partition __consumer_offsets-38 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:44,526] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-04-18 13:02:44,526] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:44,526] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:44,843] INFO [Log partition=__consumer_offsets-18, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:44,843] INFO [Log partition=__consumer_offsets-18, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:44,844] INFO Created log for partition __consumer_offsets-18 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:44,844] INFO [Partition __consumer_offsets-18 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-04-18 13:02:44,844] INFO [Partition __consumer_offsets-18 broker=2] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:44,844] INFO [Partition __consumer_offsets-18 broker=2] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:44,857] INFO [Log partition=__consumer_offsets-19, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:44,857] INFO [Log partition=__consumer_offsets-19, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:44,858] INFO Created log for partition __consumer_offsets-19 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:44,858] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-04-18 13:02:44,858] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:44,858] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:44,876] INFO [Log partition=__consumer_offsets-35, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:44,876] INFO [Log partition=__consumer_offsets-35, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:44,877] INFO Created log for partition __consumer_offsets-35 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:44,877] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-04-18 13:02:44,877] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:44,877] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:44,976] INFO [Log partition=__consumer_offsets-28, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:44,976] INFO [Log partition=__consumer_offsets-15, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:44,977] INFO [Log partition=__consumer_offsets-28, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:44,977] INFO [Log partition=__consumer_offsets-15, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:44,978] INFO Created log for partition __consumer_offsets-28 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:44,978] INFO Created log for partition __consumer_offsets-15 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:44,978] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-04-18 13:02:44,978] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:44,978] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-04-18 13:02:44,978] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:44,978] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:44,978] INFO [Partition __consumer_offsets-15 broker=2] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,063] INFO [Log partition=__consumer_offsets-44, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:45,063] INFO [Log partition=__consumer_offsets-44, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:45,064] INFO Created log for partition __consumer_offsets-44 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:45,064] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-04-18 13:02:45,064] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:45,065] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,136] INFO [Log partition=__consumer_offsets-16, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:45,136] INFO [Log partition=__consumer_offsets-16, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:45,137] INFO Created log for partition __consumer_offsets-16 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:45,137] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-04-18 13:02:45,137] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:45,137] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,140] INFO [Log partition=__consumer_offsets-12, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:45,140] INFO [Log partition=__consumer_offsets-12, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:02:45,141] INFO Created log for partition __consumer_offsets-12 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:45,142] INFO [Partition __consumer_offsets-12 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-04-18 13:02:45,142] INFO [Partition __consumer_offsets-12 broker=2] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:45,142] INFO [Partition __consumer_offsets-12 broker=2] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,355] INFO [Log partition=__consumer_offsets-32, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:45,355] INFO [Log partition=__consumer_offsets-32, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:45,356] INFO Created log for partition __consumer_offsets-32 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:45,365] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-04-18 13:02:45,365] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:45,365] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,369] INFO [Log partition=__consumer_offsets-9, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:45,370] INFO [Log partition=__consumer_offsets-9, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:45,371] INFO Created log for partition __consumer_offsets-9 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:45,371] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-04-18 13:02:45,371] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:45,371] INFO [Partition __consumer_offsets-9 broker=2] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,374] INFO [Log partition=__consumer_offsets-25, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:45,375] INFO [Log partition=__consumer_offsets-25, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:45,376] INFO Created log for partition __consumer_offsets-25 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:45,376] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-04-18 13:02:45,376] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:45,376] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,475] INFO [Log partition=__consumer_offsets-41, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:45,475] INFO [Log partition=__consumer_offsets-41, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:45,476] INFO Created log for partition __consumer_offsets-41 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:45,476] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-04-18 13:02:45,476] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:45,476] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,559] INFO [Log partition=__consumer_offsets-6, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:45,559] INFO [Log partition=__consumer_offsets-6, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:45,560] INFO Created log for partition __consumer_offsets-6 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:45,561] INFO [Partition __consumer_offsets-6 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-04-18 13:02:45,561] INFO [Partition __consumer_offsets-6 broker=2] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:45,561] INFO [Partition __consumer_offsets-6 broker=2] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,564] INFO [Log partition=__consumer_offsets-22, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:45,564] INFO [Log partition=__consumer_offsets-22, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:45,565] INFO Created log for partition __consumer_offsets-22 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:45,566] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-04-18 13:02:45,566] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:45,566] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,694] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,694] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,744] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 49 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,753] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,753] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,753] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,753] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,753] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,754] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,754] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,754] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,754] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,754] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,754] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,755] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,755] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,755] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,756] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,817] INFO [Log partition=__consumer_offsets-13, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:45,818] INFO [Log partition=__consumer_offsets-13, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:02:45,818] INFO [Log partition=__consumer_offsets-3, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:02:45,819] INFO [Log partition=__consumer_offsets-3, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:02:45,820] INFO Created log for partition __consumer_offsets-3 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:45,821] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-04-18 13:02:45,821] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:45,821] INFO [Partition __consumer_offsets-3 broker=2] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,821] INFO Created log for partition __consumer_offsets-13 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:02:45,822] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-04-18 13:02:45,822] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:02:45,822] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:02:45,880] INFO [GroupCoordinator 1]: Preparing to rebalance group BatchTopicGroup in state PreparingRebalance with old generation 0 (__consumer_offsets-38) (reason: Adding new member consumer-BatchTopicGroup-3-4da6f871-6c0e-46fe-a299-09e4eb4c898e with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:45,921] INFO [GroupCoordinator 1]: Stabilized group BatchTopicGroup generation 1 (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:45,932] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,934] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,934] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,939] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,940] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,940] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,950] INFO [GroupCoordinator 1]: Assignment received from leader for group BatchTopicGroup for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:45,947] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,955] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,955] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,957] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,957] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,957] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,957] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,957] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:45,957] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,076] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,076] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,077] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,077] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,077] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,077] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,085] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,085] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,085] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,085] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,086] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,086] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,086] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,086] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,086] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,086] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,086] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,084] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,090] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,091] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,091] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,092] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,092] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,092] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,092] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,104] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,106] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,106] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,121] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,121] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,122] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,122] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,122] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,123] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:02:46,153] INFO [GroupCoordinator 1]: Preparing to rebalance group BatchTopicGroup in state PreparingRebalance with old generation 1 (__consumer_offsets-38) (reason: Adding new member consumer-BatchTopicGroup-1-feb21495-fa92-4ff6-8f25-a7d9d1a4a7f1 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:46,170] INFO [GroupCoordinator 0]: Preparing to rebalance group ReportTopicGroup in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member consumer-ReportTopicGroup-2-bec8fa50-1069-4aa5-bdd0-64de2d327cdd with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:46,171] INFO [GroupCoordinator 0]: Preparing to rebalance group AlarmTopicGroup in state PreparingRebalance with old generation 0 (__consumer_offsets-7) (reason: Adding new member consumer-AlarmTopicGroup-3-db6c111c-899d-4a1e-84c6-ac0de4cfe957 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:46,198] INFO [GroupCoordinator 0]: Stabilized group ReportTopicGroup generation 1 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:46,227] INFO [GroupCoordinator 0]: Assignment received from leader for group ReportTopicGroup for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:46,228] INFO [GroupCoordinator 0]: Stabilized group AlarmTopicGroup generation 1 (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:46,259] INFO [GroupCoordinator 0]: Preparing to rebalance group AlarmTopicGroup in state PreparingRebalance with old generation 1 (__consumer_offsets-7) (reason: Adding new member consumer-AlarmTopicGroup-2-ef1f9ad0-990a-4351-94a5-7951d064c144 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:46,279] INFO [GroupCoordinator 0]: Stabilized group AlarmTopicGroup generation 2 (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:46,284] INFO [GroupCoordinator 0]: Assignment received from leader for group AlarmTopicGroup for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:46,331] INFO [GroupCoordinator 0]: Preparing to rebalance group ReportTopicGroup in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: Adding new member consumer-ReportTopicGroup-1-31050a40-f1da-414c-bded-fd6dcdf16047 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:49,036] INFO [GroupCoordinator 1]: Stabilized group BatchTopicGroup generation 2 (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:49,040] INFO [GroupCoordinator 1]: Assignment received from leader for group BatchTopicGroup for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:49,423] INFO [GroupCoordinator 0]: Stabilized group ReportTopicGroup generation 2 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:02:49,425] INFO [GroupCoordinator 0]: Assignment received from leader for group ReportTopicGroup for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:03:14,326] INFO [GroupCoordinator 0]: Member consumer-AlarmTopicGroup-3-db6c111c-899d-4a1e-84c6-ac0de4cfe957 in group AlarmTopicGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:03:14,328] INFO [GroupCoordinator 0]: Preparing to rebalance group AlarmTopicGroup in state PreparingRebalance with old generation 2 (__consumer_offsets-7) (reason: removing member consumer-AlarmTopicGroup-3-db6c111c-899d-4a1e-84c6-ac0de4cfe957 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:03:14,329] INFO [GroupCoordinator 0]: Member consumer-AlarmTopicGroup-2-ef1f9ad0-990a-4351-94a5-7951d064c144 in group AlarmTopicGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:03:14,348] INFO [GroupCoordinator 0]: Member consumer-AlarmTopicGroup-1-674e09a4-03bc-4211-96cb-7594751e56a6 in group AlarmTopicGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:03:14,349] INFO [GroupCoordinator 0]: Group AlarmTopicGroup with generation 3 is now empty (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:03:20,428] INFO [GroupCoordinator 0]: Member consumer-ReportTopicGroup-2-bec8fa50-1069-4aa5-bdd0-64de2d327cdd in group ReportTopicGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:03:20,428] INFO [GroupCoordinator 0]: Preparing to rebalance group ReportTopicGroup in state PreparingRebalance with old generation 2 (__consumer_offsets-34) (reason: removing member consumer-ReportTopicGroup-2-bec8fa50-1069-4aa5-bdd0-64de2d327cdd on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:03:20,429] INFO [GroupCoordinator 0]: Member consumer-ReportTopicGroup-3-368d8849-eff0-407c-91be-a077779b7ccd in group ReportTopicGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:03:20,430] INFO [GroupCoordinator 0]: Member consumer-ReportTopicGroup-1-31050a40-f1da-414c-bded-fd6dcdf16047 in group ReportTopicGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:03:20,430] INFO [GroupCoordinator 0]: Group ReportTopicGroup with generation 3 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:00,330] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-18 13:04:00,353] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:04:00,355] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:04:00,356] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:04:00,361] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:04:00,362] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:04:00,364] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-18 13:04:00,364] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-18 13:04:00,364] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-18 13:04:00,364] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-18 13:04:00,366] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-18 13:04:00,388] INFO Reading configuration from: configs/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:04:00,388] WARN configs/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:04:00,388] WARN configs/zookeeper is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:04:00,388] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:04:00,388] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-18 13:04:00,388] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-18 13:04:00,390] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-18 13:04:00,391] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-18 13:04:00,410] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,410] INFO Server environment:host.name=fp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,410] INFO Server environment:java.version=1.8.0_242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,410] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,410] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,410] INFO Server environment:java.class.path=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,412] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,412] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,412] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,412] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,412] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,412] INFO Server environment:os.version=4.19.108-1-MANJARO (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,412] INFO Server environment:user.name=fp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,412] INFO Server environment:user.home=/home/fp (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,412] INFO Server environment:user.dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,412] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,412] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,413] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,415] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,415] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,416] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir configs/zookeeper/version-2 snapdir configs/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-18 13:04:00,430] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-18 13:04:00,433] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-18 13:04:00,436] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-18 13:04:00,438] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-18 13:04:00,468] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-18 13:04:00,473] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-18 13:04:00,476] INFO Snapshotting: 0x0 to configs/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-18 13:04:00,507] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-18 13:04:00,996] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-18 13:04:00,997] INFO starting (kafka.server.KafkaServer)
[2020-04-18 13:04:00,998] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-18 13:04:01,020] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-18 13:04:01,020] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:04:01,021] INFO starting (kafka.server.KafkaServer)
[2020-04-18 13:04:01,023] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-18 13:04:01,032] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,032] INFO Client environment:host.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,032] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,032] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,032] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,032] INFO Client environment:java.class.path=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,033] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,033] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,034] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,034] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,034] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,034] INFO Client environment:os.version=4.19.108-1-MANJARO (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,034] INFO Client environment:user.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,034] INFO Client environment:user.home=/home/fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,034] INFO Client environment:user.dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,034] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,034] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,040] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,044] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3d51f06e (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,051] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-18 13:04:01,058] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-18 13:04:01,066] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,070] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:04:01,071] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:04:01,083] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,083] INFO Client environment:host.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,083] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,083] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,083] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,084] INFO Client environment:java.class.path=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,085] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,085] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,085] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,085] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,085] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,085] INFO Client environment:os.version=4.19.108-1-MANJARO (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,085] INFO Client environment:user.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,085] INFO Client environment:user.home=/home/fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,085] INFO Client environment:user.dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,085] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,085] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,086] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,088] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,089] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3d51f06e (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,096] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59438, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,098] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-18 13:04:01,101] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-04-18 13:04:01,102] INFO starting (kafka.server.KafkaServer)
[2020-04-18 13:04:01,104] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-18 13:04:01,104] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-18 13:04:01,109] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-18 13:04:01,117] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,121] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:04:01,123] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,127] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:04:01,129] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59440, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,132] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,132] INFO Client environment:host.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,132] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,132] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,132] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk/jre (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,132] INFO Client environment:java.class.path=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/activation-1.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/aopalliance-repackaged-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/argparse4j-0.7.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/audience-annotations-0.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-cli-1.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/commons-lang3-3.8.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-api-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-file-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-json-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-mirror-client-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-runtime-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/connect-transforms-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/guava-20.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-api-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-locator-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/hk2-utils-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-core-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-databind-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-paranamer-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.annotation-api-1.3.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.inject-2.5.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javassist-3.22.0-CR2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jaxb-api-2.3.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-client-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-common-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-container-servlet-core-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-hk2-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-media-jaxb-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jersey-server-2.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-client-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-http-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-io-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-security-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-server-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jetty-util-9.4.20.v20190813.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/jopt-simple-5.0.4.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka_2.12-2.4.1-sources.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-clients-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-log4j-appender-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-examples-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/kafka-tools-2.4.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/log4j-1.2.17.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/lz4-java-1.6.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/maven-artifact-3.6.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/metrics-core-2.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-buffer-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-codec-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-handler-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-resolver-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/paranamer-2.8.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/plexus-utils-3.2.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/reflections-0.9.11.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/rocksdbjni-5.18.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-library-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-logging_2.12-3.9.2.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/scala-reflect-2.12.10.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-api-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/slf4j-log4j12-1.7.28.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/snappy-java-1.1.7.3.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/validation-api-2.0.1.Final.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zookeeper-jute-3.5.7.jar:/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/../../kafka_2.12-2.4.1/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,133] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,133] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,133] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,133] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,133] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,133] INFO Client environment:os.version=4.19.108-1-MANJARO (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,133] INFO Client environment:user.name=fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,134] INFO Client environment:user.home=/home/fp (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,134] INFO Client environment:user.dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,134] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,134] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,134] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,136] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3d51f06e (org.apache.zookeeper.ZooKeeper)
[2020-04-18 13:04:01,139] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-18 13:04:01,143] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-18 13:04:01,148] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,150] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:04:01,152] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,155] INFO Socket connection established, initiating session, client: /127.0.0.1:33170, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,195] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100008a0f490000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,206] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:04:01,216] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100008a0f490002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,216] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100008a0f490001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-18 13:04:01,229] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:04:01,240] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-18 13:04:01,973] INFO Cluster ID = 0jxtxWQXTzqULewIkgKs7w (kafka.server.KafkaServer)
[2020-04-18 13:04:01,978] WARN No meta.properties file under dir /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-18 13:04:02,008] INFO Cluster ID = 0jxtxWQXTzqULewIkgKs7w (kafka.server.KafkaServer)
[2020-04-18 13:04:02,012] WARN No meta.properties file under dir /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-18 13:04:02,015] INFO Cluster ID = 0jxtxWQXTzqULewIkgKs7w (kafka.server.KafkaServer)
[2020-04-18 13:04:02,020] WARN No meta.properties file under dir /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-04-18 13:04:02,050] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:04:02,063] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:04:02,086] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:04:02,096] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:04:02,100] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:04:02,100] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:04:02,113] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:04:02,113] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = configs/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-18 13:04:02,115] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:04:02,130] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:04:02,130] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:04:02,134] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:04:02,140] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:04:02,141] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:04:02,141] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-18 13:04:02,146] INFO Log directory /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2020-04-18 13:04:02,158] INFO Loading logs. (kafka.log.LogManager)
[2020-04-18 13:04:02,161] INFO Log directory /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2020-04-18 13:04:02,166] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[2020-04-18 13:04:02,168] INFO Loading logs. (kafka.log.LogManager)
[2020-04-18 13:04:02,172] INFO Log directory /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2020-04-18 13:04:02,177] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-04-18 13:04:02,181] INFO Loading logs. (kafka.log.LogManager)
[2020-04-18 13:04:02,182] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-18 13:04:02,186] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-18 13:04:02,197] INFO Logs loading complete in 16 ms. (kafka.log.LogManager)
[2020-04-18 13:04:02,199] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-18 13:04:02,213] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-18 13:04:02,223] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-18 13:04:02,234] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-18 13:04:02,671] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-18 13:04:02,710] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-18 13:04:02,761] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-18 13:04:02,763] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-18 13:04:02,773] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-18 13:04:02,783] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-18 13:04:02,786] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-18 13:04:02,793] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,794] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,795] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,795] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,810] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-18 13:04:02,811] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-18 13:04:02,814] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,814] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,815] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,815] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,828] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-18 13:04:02,838] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,843] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-18 13:04:02,844] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,845] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,850] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:02,865] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-18 13:04:02,882] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-18 13:04:02,889] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-18 13:04:02,916] INFO Stat of the created znode at /brokers/ids/0 is: 70,70,1587211442885,1587211442885,1,0,0,72058186999857153,174,0,70
 (kafka.zk.KafkaZkClient)
[2020-04-18 13:04:02,916] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(fp,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 70 (kafka.zk.KafkaZkClient)
[2020-04-18 13:04:02,925] INFO Stat of the created znode at /brokers/ids/2 is: 71,71,1587211442895,1587211442895,1,0,0,72058186999857152,174,0,71
 (kafka.zk.KafkaZkClient)
[2020-04-18 13:04:02,926] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(fp,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 71 (kafka.zk.KafkaZkClient)
[2020-04-18 13:04:02,962] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-18 13:04:03,008] INFO Stat of the created znode at /brokers/ids/1 is: 72,72,1587211442972,1587211442972,1,0,0,72058186999857154,174,0,72
 (kafka.zk.KafkaZkClient)
[2020-04-18 13:04:03,009] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(fp,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 72 (kafka.zk.KafkaZkClient)
[2020-04-18 13:04:03,024] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,031] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,032] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,044] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,051] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,051] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,234] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-04-18 13:04:03,255] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:03,256] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:03,260] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:03,261] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:03,263] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:03,268] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:03,269] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,272] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,273] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,314] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:03,315] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:03,319] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:03,343] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-18 13:04:03,371] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:04:03,380] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-18 13:04:03,381] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-18 13:04:03,381] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:04:03,410] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-18 13:04:03,418] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:04:03,419] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,433] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:04:03,441] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:04:03,444] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-18 13:04:03,454] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-18 13:04:03,454] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-18 13:04:03,473] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-18 13:04:03,487] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,505] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-18 13:04:03,506] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-18 13:04:03,508] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:04:03,509] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:04:03,509] INFO Kafka startTimeMs: 1587211443505 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:04:03,511] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-18 13:04:03,573] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-18 13:04:03,613] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-18 13:04:03,627] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-18 13:04:03,633] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:04:03,633] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:04:03,633] INFO Kafka startTimeMs: 1587211443628 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:04:03,635] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-18 13:04:03,655] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-18 13:04:03,671] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:04:03,672] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:04:03,672] INFO Kafka startTimeMs: 1587211443655 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-18 13:04:03,674] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-18 13:04:03,866] INFO Creating topic BatchTopic with configuration {} and initial partition assignment Map(2 -> ArrayBuffer(2, 1, 0), 1 -> ArrayBuffer(0, 2, 1), 0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-18 13:04:04,027] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,040] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,043] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,135] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:04,143] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2020-04-18 13:04:04,145] INFO Created log for partition BatchTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:04,147] INFO [Partition BatchTopic-1 broker=0] No checkpointed highwatermark is found for partition BatchTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:04:04,147] INFO [Partition BatchTopic-1 broker=0] Log loaded for partition BatchTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,148] INFO [Partition BatchTopic-1 broker=0] BatchTopic-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:04,182] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:04,192] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 74 ms (kafka.log.Log)
[2020-04-18 13:04:04,196] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:04,202] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:04,203] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:04,204] INFO Created log for partition BatchTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:04,204] INFO [Partition BatchTopic-2 broker=0] No checkpointed highwatermark is found for partition BatchTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:04:04,205] INFO [Partition BatchTopic-2 broker=0] Log loaded for partition BatchTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,209] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:04,209] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:04,210] INFO Created log for partition BatchTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:04,215] INFO [Partition BatchTopic-0 broker=0] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,216] INFO [Partition BatchTopic-0 broker=0] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,216] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(BatchTopic-0, BatchTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,226] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 123 ms (kafka.log.Log)
[2020-04-18 13:04:04,228] INFO Created log for partition BatchTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:04,229] INFO [Partition BatchTopic-2 broker=2] No checkpointed highwatermark is found for partition BatchTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:04:04,230] INFO [Partition BatchTopic-2 broker=2] Log loaded for partition BatchTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,231] INFO [Partition BatchTopic-2 broker=2] BatchTopic-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:04,244] INFO Created log for partition BatchTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:04,249] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:04,251] INFO [Partition BatchTopic-0 broker=1] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,251] INFO [Partition BatchTopic-0 broker=1] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,254] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(BatchTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,259] INFO [Partition BatchTopic-0 broker=1] BatchTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:04,263] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:04,263] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,266] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:04,268] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:04,309] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition BatchTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-18 13:04:04,350] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:04,351] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:04,352] INFO Created log for partition BatchTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:04,352] INFO [Partition BatchTopic-1 broker=2] No checkpointed highwatermark is found for partition BatchTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:04:04,352] INFO [Partition BatchTopic-1 broker=2] Log loaded for partition BatchTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,356] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:04,356] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:04,357] INFO Created log for partition BatchTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/BatchTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:04,357] INFO [Partition BatchTopic-0 broker=2] No checkpointed highwatermark is found for partition BatchTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,357] INFO [Partition BatchTopic-0 broker=2] Log loaded for partition BatchTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,358] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(BatchTopic-0, BatchTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,388] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:04,389] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:04,390] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:04,391] INFO Created log for partition BatchTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:04,391] INFO [Partition BatchTopic-1 broker=1] No checkpointed highwatermark is found for partition BatchTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:04:04,391] INFO [Partition BatchTopic-1 broker=1] Log loaded for partition BatchTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,396] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(BatchTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,424] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:04,424] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:04,425] INFO Created log for partition BatchTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/BatchTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:04,426] INFO [Partition BatchTopic-2 broker=1] No checkpointed highwatermark is found for partition BatchTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:04:04,426] INFO [Partition BatchTopic-2 broker=1] Log loaded for partition BatchTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:04,427] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(BatchTopic-2, BatchTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,428] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(BatchTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,434] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:04,437] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition BatchTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:04,442] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:04,471] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(BatchTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,483] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:04,483] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(BatchTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:04,484] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:04,488] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition BatchTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:04,495] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition BatchTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:04,500] INFO [Log partition=BatchTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:04,514] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:05,257] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition BatchTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:05,257] INFO [Log partition=BatchTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:05,398] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition BatchTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:05,399] INFO [Log partition=BatchTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:06,312] INFO Creating topic ReportTopic with configuration {} and initial partition assignment Map(2 -> ArrayBuffer(2, 1, 0), 1 -> ArrayBuffer(0, 2, 1), 0 -> ArrayBuffer(1, 0, 2)) (kafka.zk.AdminZkClient)
[2020-04-18 13:04:07,958] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:07,959] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:07,960] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:07,962] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:07,963] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:07,964] INFO Created log for partition ReportTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:07,964] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:07,964] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:07,965] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:07,965] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:07,966] INFO Created log for partition ReportTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:07,966] INFO [Partition ReportTopic-1 broker=0] No checkpointed highwatermark is found for partition ReportTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:04:07,965] INFO [Partition ReportTopic-2 broker=2] No checkpointed highwatermark is found for partition ReportTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:04:07,966] INFO [Partition ReportTopic-1 broker=0] Log loaded for partition ReportTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:07,966] INFO [Partition ReportTopic-2 broker=2] Log loaded for partition ReportTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:07,966] INFO [Partition ReportTopic-2 broker=2] ReportTopic-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:07,966] INFO [Partition ReportTopic-1 broker=0] ReportTopic-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:07,966] INFO Created log for partition ReportTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:07,967] INFO [Partition ReportTopic-0 broker=1] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:04:07,968] INFO [Partition ReportTopic-0 broker=1] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:07,968] INFO [Partition ReportTopic-0 broker=1] ReportTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:08,348] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:08,348] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:08,348] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:08,348] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:08,348] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:08,348] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:08,349] INFO Created log for partition ReportTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:08,349] INFO [Partition ReportTopic-0 broker=2] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:04:08,349] INFO Created log for partition ReportTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:08,349] INFO [Partition ReportTopic-0 broker=2] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:08,349] INFO [Partition ReportTopic-2 broker=0] No checkpointed highwatermark is found for partition ReportTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:04:08,349] INFO Created log for partition ReportTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:08,350] INFO [Partition ReportTopic-2 broker=0] Log loaded for partition ReportTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:08,350] INFO [Partition ReportTopic-2 broker=1] No checkpointed highwatermark is found for partition ReportTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:04:08,350] INFO [Partition ReportTopic-2 broker=1] Log loaded for partition ReportTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:08,357] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:08,357] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:08,357] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:08,357] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:08,357] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:08,358] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:08,358] INFO Created log for partition ReportTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/ReportTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:08,359] INFO [Partition ReportTopic-1 broker=1] No checkpointed highwatermark is found for partition ReportTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:04:08,359] INFO [Partition ReportTopic-1 broker=1] Log loaded for partition ReportTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:08,359] INFO Created log for partition ReportTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/ReportTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:08,359] INFO [Partition ReportTopic-1 broker=2] No checkpointed highwatermark is found for partition ReportTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:04:08,359] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ReportTopic-2, ReportTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:08,359] INFO [Partition ReportTopic-1 broker=2] Log loaded for partition ReportTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:08,359] INFO Created log for partition ReportTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/ReportTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:08,360] INFO [Partition ReportTopic-0 broker=0] No checkpointed highwatermark is found for partition ReportTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:04:08,360] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(ReportTopic-0, ReportTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:08,360] INFO [Partition ReportTopic-0 broker=0] Log loaded for partition ReportTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:08,360] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ReportTopic-0, ReportTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:08,360] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(ReportTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:08,360] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(ReportTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:08,361] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:08,361] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(ReportTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:08,361] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(ReportTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:08,361] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(ReportTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:08,382] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:08,383] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:08,421] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition ReportTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:08,422] INFO [Log partition=ReportTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:08,545] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition ReportTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:08,545] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:08,553] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition ReportTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:08,554] INFO [Log partition=ReportTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:08,609] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition ReportTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:08,609] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:08,785] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition ReportTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:08,786] INFO [Log partition=ReportTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:10,294] INFO Creating topic AlarmTopic with configuration {} and initial partition assignment Map(2 -> ArrayBuffer(1, 2, 0), 1 -> ArrayBuffer(2, 0, 1), 0 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2020-04-18 13:04:11,384] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-0) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,384] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,385] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,389] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:11,389] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:11,389] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:11,390] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:11,390] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:11,390] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:11,391] INFO Created log for partition AlarmTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:11,391] INFO Created log for partition AlarmTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:11,391] INFO Created log for partition AlarmTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:11,391] INFO [Partition AlarmTopic-1 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:04:11,392] INFO [Partition AlarmTopic-1 broker=2] Log loaded for partition AlarmTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,392] INFO [Partition AlarmTopic-2 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:04:11,392] INFO [Partition AlarmTopic-1 broker=2] AlarmTopic-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:11,392] INFO [Partition AlarmTopic-2 broker=1] Log loaded for partition AlarmTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,392] INFO [Partition AlarmTopic-0 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,392] INFO [Partition AlarmTopic-2 broker=1] AlarmTopic-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:11,392] INFO [Partition AlarmTopic-0 broker=0] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,392] INFO [Partition AlarmTopic-0 broker=0] AlarmTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:11,433] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:11,433] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:11,433] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:11,434] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:11,434] INFO Created log for partition AlarmTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:11,434] INFO [Partition AlarmTopic-2 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:04:11,435] INFO [Partition AlarmTopic-2 broker=2] Log loaded for partition AlarmTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,435] INFO Created log for partition AlarmTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:11,435] INFO [Partition AlarmTopic-1 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:04:11,435] INFO [Partition AlarmTopic-1 broker=1] Log loaded for partition AlarmTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,438] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:11,439] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:11,440] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:11,440] INFO Created log for partition AlarmTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:11,440] INFO [Partition AlarmTopic-0 broker=2] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,440] INFO [Partition AlarmTopic-0 broker=2] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,440] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:11,440] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(AlarmTopic-0, AlarmTopic-2) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,441] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(AlarmTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,441] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,441] INFO Created log for partition AlarmTopic-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/AlarmTopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:11,441] INFO [Partition AlarmTopic-0 broker=1] No checkpointed highwatermark is found for partition AlarmTopic-0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,441] INFO [Partition AlarmTopic-0 broker=1] Log loaded for partition AlarmTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,442] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(AlarmTopic-0, AlarmTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,443] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(AlarmTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,443] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=fp:9092) for partitions Map(AlarmTopic-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,443] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:11,444] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:11,569] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:11,570] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:11,574] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition AlarmTopic-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:11,575] INFO [Log partition=AlarmTopic-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:11,628] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:11,628] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:11,636] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:11,636] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:11,637] INFO Created log for partition AlarmTopic-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:11,637] INFO [Partition AlarmTopic-1 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-1 (kafka.cluster.Partition)
[2020-04-18 13:04:11,637] INFO [Partition AlarmTopic-1 broker=0] Log loaded for partition AlarmTopic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,639] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:11,640] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:11,641] INFO Created log for partition AlarmTopic-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/AlarmTopic-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:11,641] INFO [Partition AlarmTopic-2 broker=0] No checkpointed highwatermark is found for partition AlarmTopic-2 (kafka.cluster.Partition)
[2020-04-18 13:04:11,641] INFO [Partition AlarmTopic-2 broker=0] Log loaded for partition AlarmTopic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:11,641] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(AlarmTopic-2, AlarmTopic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,642] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=fp:9094) for partitions Map(AlarmTopic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,642] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=fp:9093) for partitions Map(AlarmTopic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:11,805] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition AlarmTopic-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:11,806] INFO [Log partition=AlarmTopic-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:11,906] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition AlarmTopic-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-18 13:04:11,906] INFO [Log partition=AlarmTopic-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-18 13:04:11,950] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition AlarmTopic-2 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-18 13:04:12,075] ERROR [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error for partition AlarmTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-18 13:04:12,081] ERROR [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error for partition AlarmTopic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-18 13:04:13,307] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(2), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(2), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(2), 22 -> ArrayBuffer(2), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(2), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(2), 10 -> ArrayBuffer(2), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(2), 45 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-04-18 13:04:13,308] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(2), 32 -> ArrayBuffer(2), 41 -> ArrayBuffer(2), 17 -> ArrayBuffer(2), 8 -> ArrayBuffer(2), 35 -> ArrayBuffer(2), 44 -> ArrayBuffer(2), 26 -> ArrayBuffer(2), 11 -> ArrayBuffer(2), 29 -> ArrayBuffer(2), 38 -> ArrayBuffer(2), 47 -> ArrayBuffer(2), 20 -> ArrayBuffer(2), 2 -> ArrayBuffer(2), 5 -> ArrayBuffer(2), 14 -> ArrayBuffer(2), 46 -> ArrayBuffer(1), 49 -> ArrayBuffer(1), 40 -> ArrayBuffer(1), 13 -> ArrayBuffer(1), 4 -> ArrayBuffer(1), 22 -> ArrayBuffer(1), 31 -> ArrayBuffer(1), 16 -> ArrayBuffer(1), 7 -> ArrayBuffer(1), 43 -> ArrayBuffer(1), 25 -> ArrayBuffer(1), 34 -> ArrayBuffer(1), 10 -> ArrayBuffer(1), 37 -> ArrayBuffer(1), 1 -> ArrayBuffer(1), 19 -> ArrayBuffer(1), 28 -> ArrayBuffer(1), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-04-18 13:04:13,381] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(2), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(2), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(2), 22 -> ArrayBuffer(2), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(2), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(2), 10 -> ArrayBuffer(2), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(2), 45 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-04-18 13:04:13,395] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-04-18 13:04:14,018] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:14,024] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:14,029] INFO [Log partition=__consumer_offsets-10, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,029] INFO [Log partition=__consumer_offsets-10, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:14,033] INFO [Log partition=__consumer_offsets-29, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,033] INFO [Log partition=__consumer_offsets-29, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-04-18 13:04:14,035] INFO Created log for partition __consumer_offsets-29 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,041] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2020-04-18 13:04:14,043] INFO Created log for partition __consumer_offsets-10 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,044] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-04-18 13:04:14,044] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,044] INFO [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,046] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-04-18 13:04:14,049] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,051] INFO [Partition __consumer_offsets-29 broker=2] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,054] INFO [Log partition=__consumer_offsets-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,055] INFO [Log partition=__consumer_offsets-0, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-04-18 13:04:14,057] INFO Created log for partition __consumer_offsets-0 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,058] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,058] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,058] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,080] INFO [Log partition=__consumer_offsets-7, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,081] INFO [Log partition=__consumer_offsets-7, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:14,081] INFO Created log for partition __consumer_offsets-7 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,082] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-04-18 13:04:14,082] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,082] INFO [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,110] INFO [Log partition=__consumer_offsets-48, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,111] INFO [Log partition=__consumer_offsets-48, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:14,112] INFO Created log for partition __consumer_offsets-48 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,112] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-04-18 13:04:14,112] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,112] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,118] INFO [Log partition=__consumer_offsets-26, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,118] INFO [Log partition=__consumer_offsets-26, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:14,119] INFO Created log for partition __consumer_offsets-26 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,119] INFO [Partition __consumer_offsets-26 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-04-18 13:04:14,119] INFO [Partition __consumer_offsets-26 broker=2] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,119] INFO [Partition __consumer_offsets-26 broker=2] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,282] INFO [Log partition=__consumer_offsets-4, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,282] INFO [Log partition=__consumer_offsets-4, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:14,284] INFO Created log for partition __consumer_offsets-4 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,284] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-04-18 13:04:14,284] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,284] INFO [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,308] INFO [Log partition=__consumer_offsets-23, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,308] INFO [Log partition=__consumer_offsets-23, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:14,309] INFO Created log for partition __consumer_offsets-23 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,309] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-04-18 13:04:14,309] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,309] INFO [Partition __consumer_offsets-23 broker=2] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,310] INFO [Log partition=__consumer_offsets-45, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,310] INFO [Log partition=__consumer_offsets-45, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:14,316] INFO Created log for partition __consumer_offsets-45 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,316] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-04-18 13:04:14,316] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,316] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,354] INFO [Log partition=__consumer_offsets-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,355] INFO [Log partition=__consumer_offsets-1, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:14,355] INFO Created log for partition __consumer_offsets-1 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,355] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-04-18 13:04:14,355] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,355] INFO [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,415] INFO [Log partition=__consumer_offsets-42, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,416] INFO [Log partition=__consumer_offsets-42, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:14,417] INFO Created log for partition __consumer_offsets-42 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,417] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-04-18 13:04:14,417] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,417] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,421] INFO [Log partition=__consumer_offsets-20, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,422] INFO [Log partition=__consumer_offsets-20, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-04-18 13:04:14,423] INFO Created log for partition __consumer_offsets-20 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,423] INFO [Partition __consumer_offsets-20 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-04-18 13:04:14,423] INFO [Partition __consumer_offsets-20 broker=2] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,423] INFO [Partition __consumer_offsets-20 broker=2] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,646] INFO [Log partition=__consumer_offsets-49, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,646] INFO [Log partition=__consumer_offsets-49, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:14,647] INFO Created log for partition __consumer_offsets-49 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,647] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-04-18 13:04:14,647] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,647] INFO [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,669] INFO [Log partition=__consumer_offsets-39, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,670] INFO [Log partition=__consumer_offsets-39, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:14,670] INFO [Log partition=__consumer_offsets-17, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,670] INFO [Log partition=__consumer_offsets-17, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:14,671] INFO Created log for partition __consumer_offsets-39 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,671] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-04-18 13:04:14,671] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,671] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,671] INFO Created log for partition __consumer_offsets-17 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,671] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-04-18 13:04:14,671] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,671] INFO [Partition __consumer_offsets-17 broker=2] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,740] INFO [Log partition=__consumer_offsets-46, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,741] INFO [Log partition=__consumer_offsets-46, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:14,742] INFO Created log for partition __consumer_offsets-46 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,742] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-04-18 13:04:14,742] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,742] INFO [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,894] INFO [Log partition=__consumer_offsets-14, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,895] INFO [Log partition=__consumer_offsets-14, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:14,896] INFO Created log for partition __consumer_offsets-14 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,896] INFO [Partition __consumer_offsets-14 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-04-18 13:04:14,896] INFO [Partition __consumer_offsets-14 broker=2] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,896] INFO [Partition __consumer_offsets-14 broker=2] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:14,897] INFO [Log partition=__consumer_offsets-36, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:14,898] INFO [Log partition=__consumer_offsets-36, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:14,899] INFO Created log for partition __consumer_offsets-36 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:14,899] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-04-18 13:04:14,899] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:14,899] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,004] INFO [Log partition=__consumer_offsets-43, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,004] INFO [Log partition=__consumer_offsets-43, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:15,005] INFO Created log for partition __consumer_offsets-43 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,005] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-04-18 13:04:15,005] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,005] INFO [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,180] INFO [Log partition=__consumer_offsets-33, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,180] INFO [Log partition=__consumer_offsets-11, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,180] INFO [Log partition=__consumer_offsets-33, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:15,180] INFO [Log partition=__consumer_offsets-11, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:15,181] INFO Created log for partition __consumer_offsets-33 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,181] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-04-18 13:04:15,181] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,181] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,181] INFO Created log for partition __consumer_offsets-11 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,181] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-04-18 13:04:15,181] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,181] INFO [Partition __consumer_offsets-11 broker=2] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,208] INFO [Log partition=__consumer_offsets-40, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,208] INFO [Log partition=__consumer_offsets-40, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:15,209] INFO Created log for partition __consumer_offsets-40 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,209] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-04-18 13:04:15,209] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,209] INFO [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,404] INFO [Log partition=__consumer_offsets-30, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,404] INFO [Log partition=__consumer_offsets-30, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:15,405] INFO Created log for partition __consumer_offsets-30 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,405] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-04-18 13:04:15,405] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,405] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,407] INFO [Log partition=__consumer_offsets-8, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,407] INFO [Log partition=__consumer_offsets-8, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:15,408] INFO Created log for partition __consumer_offsets-8 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,408] INFO [Partition __consumer_offsets-8 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-04-18 13:04:15,408] INFO [Partition __consumer_offsets-8 broker=2] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,408] INFO [Partition __consumer_offsets-8 broker=2] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,430] INFO [Log partition=__consumer_offsets-37, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,430] INFO [Log partition=__consumer_offsets-37, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:15,431] INFO Created log for partition __consumer_offsets-37 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,431] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-04-18 13:04:15,432] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,432] INFO [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,476] INFO [Log partition=__consumer_offsets-27, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,476] INFO [Log partition=__consumer_offsets-5, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,476] INFO [Log partition=__consumer_offsets-5, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:15,476] INFO [Log partition=__consumer_offsets-27, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:15,477] INFO Created log for partition __consumer_offsets-5 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,477] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-04-18 13:04:15,477] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,477] INFO [Partition __consumer_offsets-5 broker=2] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,477] INFO Created log for partition __consumer_offsets-27 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,477] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-04-18 13:04:15,477] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,477] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,619] INFO [Log partition=__consumer_offsets-34, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,620] INFO [Log partition=__consumer_offsets-34, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:15,620] INFO Created log for partition __consumer_offsets-34 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,620] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-04-18 13:04:15,621] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,621] INFO [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,796] INFO [Log partition=__consumer_offsets-24, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,796] INFO [Log partition=__consumer_offsets-24, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:15,797] INFO Created log for partition __consumer_offsets-24 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,797] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-04-18 13:04:15,797] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,797] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,798] INFO [Log partition=__consumer_offsets-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,799] INFO [Log partition=__consumer_offsets-2, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:15,799] INFO Created log for partition __consumer_offsets-2 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,800] INFO [Partition __consumer_offsets-2 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-04-18 13:04:15,800] INFO [Partition __consumer_offsets-2 broker=2] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,800] INFO [Partition __consumer_offsets-2 broker=2] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,820] INFO [Log partition=__consumer_offsets-31, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,821] INFO [Log partition=__consumer_offsets-31, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:15,822] INFO Created log for partition __consumer_offsets-31 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,822] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-04-18 13:04:15,822] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,822] INFO [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,994] INFO [Log partition=__consumer_offsets-21, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,995] INFO [Log partition=__consumer_offsets-47, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:15,995] INFO [Log partition=__consumer_offsets-21, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:15,995] INFO [Log partition=__consumer_offsets-47, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:15,995] INFO Created log for partition __consumer_offsets-21 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,996] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-04-18 13:04:15,996] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,996] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:15,996] INFO Created log for partition __consumer_offsets-47 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:15,996] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-04-18 13:04:15,996] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:15,996] INFO [Partition __consumer_offsets-47 broker=2] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,029] INFO [Log partition=__consumer_offsets-19, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,029] INFO [Log partition=__consumer_offsets-19, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:16,030] INFO Created log for partition __consumer_offsets-19 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,030] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-04-18 13:04:16,030] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,030] INFO [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,209] INFO [Log partition=__consumer_offsets-38, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,210] INFO [Log partition=__consumer_offsets-38, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:16,210] INFO [Log partition=__consumer_offsets-18, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,210] INFO Created log for partition __consumer_offsets-38 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,210] INFO [Partition __consumer_offsets-38 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-04-18 13:04:16,210] INFO [Partition __consumer_offsets-38 broker=2] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,210] INFO [Partition __consumer_offsets-38 broker=2] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,210] INFO [Log partition=__consumer_offsets-18, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:16,211] INFO Created log for partition __consumer_offsets-18 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,211] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-04-18 13:04:16,211] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,211] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,389] INFO [Log partition=__consumer_offsets-28, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,389] INFO [Log partition=__consumer_offsets-28, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:16,390] INFO Created log for partition __consumer_offsets-28 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,390] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-04-18 13:04:16,390] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,390] INFO [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,415] INFO [Log partition=__consumer_offsets-35, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,415] INFO [Log partition=__consumer_offsets-15, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,415] INFO [Log partition=__consumer_offsets-35, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:16,416] INFO [Log partition=__consumer_offsets-15, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:16,416] INFO Created log for partition __consumer_offsets-35 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,416] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-04-18 13:04:16,416] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,416] INFO [Partition __consumer_offsets-35 broker=2] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,417] INFO Created log for partition __consumer_offsets-15 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,417] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-04-18 13:04:16,417] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,417] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,595] INFO [Log partition=__consumer_offsets-16, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,595] INFO [Log partition=__consumer_offsets-16, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-04-18 13:04:16,596] INFO Created log for partition __consumer_offsets-16 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,596] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-04-18 13:04:16,596] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,596] INFO [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,632] INFO [Log partition=__consumer_offsets-12, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,632] INFO [Log partition=__consumer_offsets-44, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,632] INFO [Log partition=__consumer_offsets-44, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:16,632] INFO [Log partition=__consumer_offsets-12, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:16,633] INFO Created log for partition __consumer_offsets-12 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,633] INFO Created log for partition __consumer_offsets-44 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,633] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-04-18 13:04:16,633] INFO [Partition __consumer_offsets-44 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-04-18 13:04:16,633] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,633] INFO [Partition __consumer_offsets-44 broker=2] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,633] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,633] INFO [Partition __consumer_offsets-44 broker=2] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,867] INFO [Log partition=__consumer_offsets-25, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,868] INFO [Log partition=__consumer_offsets-25, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:16,868] INFO Created log for partition __consumer_offsets-25 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,869] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-04-18 13:04:16,869] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,869] INFO [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,913] INFO [Log partition=__consumer_offsets-9, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,914] INFO [Log partition=__consumer_offsets-32, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:16,914] INFO [Log partition=__consumer_offsets-9, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:16,914] INFO [Log partition=__consumer_offsets-32, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:16,915] INFO Created log for partition __consumer_offsets-9 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,916] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-04-18 13:04:16,916] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,916] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:16,916] INFO Created log for partition __consumer_offsets-32 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:16,916] INFO [Partition __consumer_offsets-32 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-04-18 13:04:16,916] INFO [Partition __consumer_offsets-32 broker=2] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:16,916] INFO [Partition __consumer_offsets-32 broker=2] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:17,132] INFO [Log partition=__consumer_offsets-22, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:17,133] INFO [Log partition=__consumer_offsets-22, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-04-18 13:04:17,134] INFO Created log for partition __consumer_offsets-22 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:17,134] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-04-18 13:04:17,135] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:17,135] INFO [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:17,405] INFO [Log partition=__consumer_offsets-6, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:17,405] INFO [Log partition=__consumer_offsets-41, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:17,405] INFO [Log partition=__consumer_offsets-6, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:17,406] INFO [Log partition=__consumer_offsets-41, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-04-18 13:04:17,406] INFO Created log for partition __consumer_offsets-6 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:17,406] INFO Created log for partition __consumer_offsets-41 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-3/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:17,406] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-04-18 13:04:17,406] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-04-18 13:04:17,406] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:17,406] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:17,406] INFO [Partition __consumer_offsets-41 broker=2] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:17,406] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:17,671] INFO [Log partition=__consumer_offsets-13, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:17,671] INFO [Log partition=__consumer_offsets-13, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-04-18 13:04:17,672] INFO Created log for partition __consumer_offsets-13 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-2/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:17,672] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-04-18 13:04:17,672] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:17,673] INFO [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:17,894] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,895] INFO [Log partition=__consumer_offsets-3, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-18 13:04:17,896] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,896] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,896] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,896] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,896] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,896] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,896] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,896] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,897] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,897] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,897] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,897] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,897] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,897] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,897] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,899] INFO [Log partition=__consumer_offsets-3, dir=/home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-04-18 13:04:17,900] INFO Created log for partition __consumer_offsets-3 in /home/fp/Desktop/4A2S/AS/P/AS-ProjectsRepository/Project2-VehicleSupervising/PA2_T1G07/src/scripts/configs/kafka-logs-1/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-04-18 13:04:17,900] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-04-18 13:04:17,900] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-18 13:04:17,900] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-04-18 13:04:17,904] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,906] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,906] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,907] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,907] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,908] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,908] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,908] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,909] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,909] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,909] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,910] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,910] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,910] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,911] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,911] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,967] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,968] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,968] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,968] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,968] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,968] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,968] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,969] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,969] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,969] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,969] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,969] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,969] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,969] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,969] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,969] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,969] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,973] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,975] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,975] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,975] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,976] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,976] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,976] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,977] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,977] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,977] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,977] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,978] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,978] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,978] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,979] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,979] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,979] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:17,989] INFO [GroupCoordinator 2]: Preparing to rebalance group BatchTopicGroup in state PreparingRebalance with old generation 0 (__consumer_offsets-38) (reason: Adding new member consumer-BatchTopicGroup-3-268f729f-c834-46d6-a7cd-eb001b5a6f22 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:18,028] INFO [GroupCoordinator 1]: Preparing to rebalance group AlarmTopicGroup in state PreparingRebalance with old generation 0 (__consumer_offsets-7) (reason: Adding new member consumer-AlarmTopicGroup-2-804b9746-96de-45be-8b32-0233577b443e with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:18,030] INFO [GroupCoordinator 1]: Preparing to rebalance group ReportTopicGroup in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member consumer-ReportTopicGroup-2-4774d4f4-d7f5-42e9-95b5-0c7818e5d9a6 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:18,040] INFO [GroupCoordinator 2]: Stabilized group BatchTopicGroup generation 1 (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:18,050] INFO [GroupCoordinator 1]: Stabilized group ReportTopicGroup generation 1 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:18,054] INFO [GroupCoordinator 1]: Stabilized group AlarmTopicGroup generation 1 (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:18,061] INFO [GroupCoordinator 2]: Assignment received from leader for group BatchTopicGroup for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:18,073] INFO [GroupCoordinator 1]: Assignment received from leader for group ReportTopicGroup for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:18,077] INFO [GroupCoordinator 1]: Assignment received from leader for group AlarmTopicGroup for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:18,148] INFO [GroupCoordinator 2]: Preparing to rebalance group BatchTopicGroup in state PreparingRebalance with old generation 1 (__consumer_offsets-38) (reason: Adding new member consumer-BatchTopicGroup-2-637a44a0-da70-4c1e-88cf-ea16a3c82b97 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:18,177] INFO [GroupCoordinator 1]: Preparing to rebalance group ReportTopicGroup in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: Adding new member consumer-ReportTopicGroup-3-56b69452-fb1b-46a9-a3df-1f5a892643b9 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:18,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,196] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,196] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,196] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,196] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,196] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,196] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,196] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,196] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,200] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,206] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,208] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,209] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,210] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,210] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,211] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,212] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,212] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,212] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,212] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,213] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,213] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,213] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,213] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,213] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,213] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-18 13:04:18,271] INFO [GroupCoordinator 1]: Preparing to rebalance group AlarmTopicGroup in state PreparingRebalance with old generation 1 (__consumer_offsets-7) (reason: Adding new member consumer-AlarmTopicGroup-1-b64654c2-7b3c-487d-8d2e-b7c743289183 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:21,174] INFO [GroupCoordinator 2]: Stabilized group BatchTopicGroup generation 2 (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:21,181] INFO [GroupCoordinator 2]: Assignment received from leader for group BatchTopicGroup for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:21,204] INFO [GroupCoordinator 1]: Stabilized group AlarmTopicGroup generation 2 (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:21,204] INFO [GroupCoordinator 1]: Stabilized group ReportTopicGroup generation 2 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:21,208] INFO [GroupCoordinator 1]: Assignment received from leader for group AlarmTopicGroup for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-04-18 13:04:21,208] INFO [GroupCoordinator 1]: Assignment received from leader for group ReportTopicGroup for generation 2 (kafka.coordinator.group.GroupCoordinator)
